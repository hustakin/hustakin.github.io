{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Frankie Fan's Memos User or Organization. Note This is intended to be more of my own memos. Helpful Links MkDocs Material for MkDocs Material for MkDocs Extensions Markdown Cheatsheet","title":"Home"},{"location":"#welcome-to-frankie-fans-memos","text":"User or Organization. Note This is intended to be more of my own memos. Helpful Links MkDocs Material for MkDocs Material for MkDocs Extensions Markdown Cheatsheet","title":"Welcome to Frankie Fan's Memos"},{"location":"bestpractice/adding-beautiful-badges-into-the-markdown/","text":"Adding beautiful badges into the Github README file is important to make your open source code more professional, for example: Shields format The format of the badge image is as bellow: [ < img src = \"https://img.shields.io/badge/LABEL-MESSAGE-COLOR.svg?logo=LOGO\" > ]( < LINK > ) We could use Shields to generate whatever icon we'd like to. Shields example Take the bellow badge as an example, the LABEL is 'dockerhub', the MESSAGE is 'images', the COLOR is 'important' Shields colors We can find popular colors as bellow in the Shields website and we can directly specify the color value: SVG logos The LOGO uses simple SVG icon name which can be found in SimpleIcons , we use Docker in the above example as we find the Docker SVG icon: Base64 icon data We could customize own icon by using the Base64 icon data. [ < img src = \"https://img.shields.io/badge/LABEL-MESSAGE-COLOR.svg?logo=data:image/png;base64,DATA\" > ]( < LINK > ) Icon generate ways The Favicon.cc can be used to generate favicon icon The Favicon Generator can be used to generate icons for all platforms The Base64 Image can be used to convert images to base64 Badge integration with third-party Travis-CI: Copy the badge icon markdown code from the platform. The icon displays the realtime build status All-contributors bot : Display current contributors. Adding a contributor by commenting in a Github Issue (@all-contributors please add USERNAME for design)","title":"Adding beautiful badges into the markdown"},{"location":"bestpractice/adding-beautiful-badges-into-the-markdown/#shields-format","text":"The format of the badge image is as bellow: [ < img src = \"https://img.shields.io/badge/LABEL-MESSAGE-COLOR.svg?logo=LOGO\" > ]( < LINK > ) We could use Shields to generate whatever icon we'd like to.","title":"Shields format"},{"location":"bestpractice/adding-beautiful-badges-into-the-markdown/#shields-example","text":"Take the bellow badge as an example, the LABEL is 'dockerhub', the MESSAGE is 'images', the COLOR is 'important'","title":"Shields example"},{"location":"bestpractice/adding-beautiful-badges-into-the-markdown/#shields-colors","text":"We can find popular colors as bellow in the Shields website and we can directly specify the color value:","title":"Shields colors"},{"location":"bestpractice/adding-beautiful-badges-into-the-markdown/#svg-logos","text":"The LOGO uses simple SVG icon name which can be found in SimpleIcons , we use Docker in the above example as we find the Docker SVG icon:","title":"SVG logos"},{"location":"bestpractice/adding-beautiful-badges-into-the-markdown/#base64-icon-data","text":"We could customize own icon by using the Base64 icon data. [ < img src = \"https://img.shields.io/badge/LABEL-MESSAGE-COLOR.svg?logo=data:image/png;base64,DATA\" > ]( < LINK > )","title":"Base64 icon data"},{"location":"bestpractice/adding-beautiful-badges-into-the-markdown/#icon-generate-ways","text":"The Favicon.cc can be used to generate favicon icon The Favicon Generator can be used to generate icons for all platforms The Base64 Image can be used to convert images to base64","title":"Icon generate ways"},{"location":"bestpractice/adding-beautiful-badges-into-the-markdown/#badge-integration-with-third-party","text":"Travis-CI: Copy the badge icon markdown code from the platform. The icon displays the realtime build status All-contributors bot : Display current contributors. Adding a contributor by commenting in a Github Issue (@all-contributors please add USERNAME for design)","title":"Badge integration with third-party"},{"location":"bestpractice/auto-generate-flutter-imgs/","text":"Add flutter_driver, test, screenshots in the dev_dependencies part of pubspec.yaml, and flutter pub get. dev_dependencies : flutter_driver : sdk : flutter test : any screenshots : ^2.1. Install screenshots plugin to make the screenshots command works. pub global activate screenshots screenshots If the command cannot be found, please add the plugins folder into your system path. export PATH = \"/Users/Frankie/Tools/flutter/bin/cache/dart-sdk/bin/: $PATH \" export PATH = \"/Users/Frankie/.pub-cache/bin/: $PATH \" Create test_driver folder and write app.dart and app_test.dart to run the app and tap widgets and take screenshots. /* * Copyright (c) 2020. Frankie Fan. * All rights reserved. */ // app.dart import 'package:flutter_driver/driver_extension.dart' ; import 'package:geofencing/main.dart' as app ; void main () { // This line enables the extension. enableFlutterDriverExtension (); // Call the `main()` function of the app, or call `runApp` with // any widget you are interested in testing. app . main (); } /* * Copyright (c) 2020. Frankie Fan. * All rights reserved. */ // app_test.dart import 'package:flutter_driver/flutter_driver.dart' ; import 'package:screenshots/screenshots.dart' ; import 'package:test/test.dart' ; void main () { group ( 'GeoFencing App' , () { final locatingBtnFinder = find . byValueKey ( 'locatingBtn' ); final drawerFinder = find . byTooltip ( 'Open navigation menu' ); FlutterDriver driver ; Config config ; // Connect to the Flutter driver before running any tests. setUpAll (() async { driver = await FlutterDriver . connect (); config = Config (); }); // Close the connection to the driver after the tests have completed. tearDownAll (() async { if ( driver != null ) { driver . close (); } }); test ( 'take screenshots' , () async { await driver . waitFor ( locatingBtnFinder ); await driver . tap ( locatingBtnFinder ); await Future . delayed ( Duration ( seconds: 5 )); await screenshot ( driver , config , 'screenshot-map' ); await driver . waitFor ( drawerFinder ); await driver . tap ( drawerFinder ); await screenshot ( driver , config , 'screenshot-drawer' ); }); }); } Add screenshots.yaml into the project to configure devices for testing. # A list of screen capture tests tests : # Note: flutter driver expects a pair of files eg, main1.dart and main1_test.dart - test_driver/app.dart # Interim location of screenshots from tests staging : screenshots # A list of locales supported by the app locales : - en-US # A map of devices to emulate devices : ios : iPhone 8 Plus : iPhone 11 Pro Max : iPad Pro (12.9-inch) (3rd generation) : orientation : LandscapeRight android : Nexus 5X : Nexus 9 : orientation : LandscapeRight # Frame screenshots frame : true Run the screenshots command to test app and get screenshots for devices one by one. Please remember to specify only one device in the above yaml and comment other devices then start relevant simulator and run screenshots. screenshots If met the following issues, please see if you've opened the relevant simulator already. For iOS you could also try Erase all Contents and Settings for the simulator and try again. If still met issues could try flutter clean or restart the IDE. You can find screenshots under ios/Android folders.","title":"Generate required flutter app screenshots for different devices"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/","text":"In this article, we are going to build a Ceph and Kubernetes based distributed file storage system and integrate into our java platform. Install Download rook Download the rook ceph GitHub code. git clone --single-branch --branch release-1.2 https://github.com/rook/rook.git Copy yaml Copy the common.yaml, operator.yaml and toolbox.yaml files from ./rook/cluster/examples/kubernetes/ceph/. cp ../rook/cluster/examples/kubernetes/ceph/common.yaml ../rook/cluster/examples/kubernetes/ceph/operator.yaml ../rook/cluster/examples/kubernetes/ceph/toolbox.yaml . Create rook containers Create the rook ceph containers, and wait the operator to be running status. kubectl apply -f common.yaml kubectl apply -f operator.yaml kubectl get pod -n rook-ceph Create volumes Create 3 20G volumes and attach to 3 linux instances. Format the disks. Mkdir /mnt/ceph-storage and mount them all. sudo fdisk -l sudo mkfs.ext4 /dev/vdc sudo mount /dev/vdb /mnt/ceph-storage -t auto df -h Filesystem Size Used Avail Use% Mounted on /dev/vda1 30G 19G 11G 65% / devtmpfs 2.9G 0 2.9G 0% /dev tmpfs 2.9G 12K 2.9G 1% /dev/shm tmpfs 2.9G 298M 2.6G 11% /run tmpfs 2.9G 0 2.9G 0% /sys/fs/cgroup tmpfs 581M 0 581M 0% /run/user/1000 /dev/vdb 20G 45M 19G 1% /mnt/ceph-storage Create Ceph cluster Create cluster by the cluster.yaml. Notice the selected nodes have the disks attached. Each nodes/name field should match their kubernetes.io/hostname label. Notice the dashboard should be disabled first. apiVersion : ceph.rook.io/v1 kind : CephCluster metadata : name : rook-ceph namespace : rook-ceph spec : dataDirHostPath : /var/lib/rook mon : count : 3 cephVersion : image : ceph/ceph:v14.2.4-20190917 allowUnsupported : false dashboard : enabled : false network : hostNetwork : false storage : useAllNodes : false useAllDevices : false config : metadataDevice : databaseSizeMB : \"1024\" # this value can be removed for environments with normal sized disks (100 GB or larger) journalSizeMB : \"1024\" # this value can be removed for environments with normal sized disks (20 GB or larger) nodes : - name : \"slave.novalocal\" directories : # specific directories to use for storage can be specified for each node - path : \"/mnt/ceph-storage\" - name : \"static.novalocal\" directories : # specific directories to use for storage can be specified for each node - path : \"/mnt/ceph-storage\" - name : \"db.novalocal\" directories : # specific directories to use for storage can be specified for each node - path : \"/mnt/ceph-storage\" kubectl apply -f cluster.yaml kubectl get pod -n rook-ceph --watch Re-create operator and check osd If error happens, remember to delete the folder dataDirHostPath on all nodes and delete the operator, then try again to create the cluster. Attach the operator pod to see the logs. When 3 mon and 3 osd pods are running it means the cluster is successfully created. sudo rm -rf /var/lib/rook kubectl delete -f operator.yaml kubectl logs -f rook-ceph-operator-6b79d99f5c-9564s -n rook-ceph kubectl get pod -n rook-ceph NAME READY STATUS RESTARTS AGE csi-cephfsplugin-265lj 3/3 Running 0 37m csi-cephfsplugin-2b47v 3/3 Running 0 37m csi-cephfsplugin-2dw6z 3/3 Running 0 37m csi-cephfsplugin-2xgns 3/3 Running 0 37m csi-cephfsplugin-54hd5 3/3 Running 0 37m csi-cephfsplugin-9rgr8 3/3 Running 0 37m csi-cephfsplugin-provisioner-5d999b68d6-8vc2k 4/4 Running 0 37m csi-cephfsplugin-provisioner-5d999b68d6-xjg4z 4/4 Running 0 37m csi-cephfsplugin-sp289 3/3 Running 0 37m csi-rbdplugin-7gk9s 3/3 Running 0 37m csi-rbdplugin-9sbwh 3/3 Running 0 37m csi-rbdplugin-jwvxx 3/3 Running 0 37m csi-rbdplugin-n9tcd 3/3 Running 0 37m csi-rbdplugin-provisioner-69b7d7887-4l9l9 5/5 Running 0 37m csi-rbdplugin-provisioner-69b7d7887-g48rb 5/5 Running 0 37m csi-rbdplugin-q9q5b 3/3 Running 0 37m csi-rbdplugin-snhqj 3/3 Running 0 37m csi-rbdplugin-v6jb8 3/3 Running 0 37m rook-ceph-crashcollector-db.novalocal-fd7dcc457-qd7tx 1/1 Running 0 11m rook-ceph-crashcollector-deamon.novalocal-7789457f5-v6vnc 1/1 Running 0 11m rook-ceph-crashcollector-slave.novalocal-5d698c7d7b-hgbnw 1/1 Running 0 9m59s rook-ceph-crashcollector-static.novalocal-58f769ccc-lsf5b 1/1 Running 0 9m54s rook-ceph-crashcollector-test.novalocal-6fdc8dbc4f-ksk75 1/1 Running 0 10m rook-ceph-mgr-a-7898b59757-84tbd 1/1 Running 0 10m rook-ceph-mon-a-7676f96769-5mhc6 1/1 Running 0 12m rook-ceph-mon-b-79c9c9b59d-g82sc 1/1 Running 0 11m rook-ceph-mon-c-7b679d7497-x2hjg 1/1 Running 0 11m rook-ceph-operator-6b79d99f5c-9564s 1/1 Running 0 14m rook-ceph-osd-0-5b59576bb4-rgsx8 1/1 Running 0 9m57s rook-ceph-osd-1-74ff9d79c6-hpkc2 1/1 Running 0 9m55s rook-ceph-osd-2-57748ff6bf-vf8jl 1/1 Running 0 9m59s rook-ceph-osd-prepare-db.novalocal-jf84v 0/1 Completed 0 10m rook-ceph-osd-prepare-slave.novalocal-j457l 0/1 Completed 0 10m rook-ceph-osd-prepare-static.novalocal-jt4vj 0/1 Completed 0 10m rook-discover-hwffd 1/1 Running 0 13m rook-discover-jh8j5 1/1 Running 0 13m rook-discover-mcdjn 1/1 Running 0 13m rook-discover-mmzcb 1/1 Running 0 13m rook-discover-mppgh 1/1 Running 0 13m rook-discover-tz5gm 1/1 Running 0 13m rook-discover-vj7tg 1/1 Running 0 13m Create toolbox and test Create toolbox pods by toolbox.yaml, and we can attach the pod then test the ceph status. kubectl apply -f toolbox.yaml kubectl -n rook-ceph exec -it $( kubectl -n rook-ceph get pod -l \"app=rook-ceph-tools\" -o jsonpath = '{.items[0].metadata.name}' ) bash ceph status ceph osd status ceph df rados df [ root @ rook - ceph - tools - 787 dc6b944 - spsjh / ] # ceph status cluster : id : 2095 eaca - 93 b3 - 4365 - a5c8 - 9 b05269821a9 health : HEALTH_OK services : mon : 3 daemons , quorum a , b , c ( age 26 m ) mgr : a ( active , since 26 m ) osd : 3 osds : 3 up ( since 25 m ), 3 in ( since 25 m ) data : pools : 0 pools , 0 pgs objects : 0 objects , 0 B usage : 6.4 GiB used , 52 GiB / 59 GiB avail pgs : Enable dashboard Modify the cluster.yaml to enable dashboard and apply to create the dashboard service. vim cluster.yaml kubectl apply -f cluster.yaml kubectl get svc -n rook-ceph | grep mgr-dashboard rook-ceph-mgr-dashboard ClusterIP 10.36.19.173 <none> 7000/TCP 66s Create dashboard ingress Now the dashboard service is ClusterIP mode which means we can only visit it in the cluster. Create dashboard Traefik yaml file dashboard-ingress.yaml to visit publicly. apiVersion : extensions/v1beta1 kind : Ingress metadata : name : ceph-dashboard-ingress namespace : rook-ceph spec : rules : - host : dashboard.*.* http : paths : - path : / backend : serviceName : rook-ceph-mgr-dashboard servicePort : 7000 kubectl apply -f dashboard-ingress.yaml Inspect dashboard password Inspect the dashboard secret. The username is admin. kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath = \"{['data']['password']}\" | base64 --decode && echo Create object gateway Create object gateway by the object.yaml. apiVersion : ceph.rook.io/v1 kind : CephObjectStore metadata : name : my-store namespace : rook-ceph spec : metadataPool : failureDomain : host replicated : size : 3 dataPool : failureDomain : host replicated : size : 3 preservePoolsOnDelete : false gateway : type : s3 sslCertificateRef : port : 80 securePort : instances : 1 placement : annotations : resources : kubectl apply -f object.yaml kubectl -n rook-ceph get pod -l app = rook-ceph-rgw Create radosgw user Create a radosgw user in the toolbox. kubectl -n rook-ceph exec -it $( kubectl -n rook-ceph get pod -l \"app=rook-ceph-tools\" -o jsonpath = '{.items[0].metadata.name}' ) bash radosgw-admin user create --uid = myuser --display-name = test-user --system ceph dashboard set-rgw-api-user-id myuser ceph dashboard set-rgw-api-access-key 32APIT3RA29JCO6OCR8P ceph dashboard set-rgw-api-secret-key 2ioxTu6iBFkYP8UKiycS90A2DFwRBklSI8Bp3iPQ { \"user_id\": \"myuser\", \"display_name\": \"test-user\", \"email\": \"\", \"suspended\": 0, \"max_buckets\": 1000, \"subusers\": [], \"keys\": [ { \"user\": \"myuser\", \"access_key\": \"32APIT3RA29JCO6OCR8P\", \"secret_key\": \"2ioxTu6iBFkYP8UKiycS90A2DFwRBklSI8Bp3iPQ\" } ], \"swift_keys\": [], \"caps\": [], \"op_mask\": \"read, write, delete\", \"system\": \"true\", \"default_placement\": \"\", \"default_storage_class\": \"\", \"placement_tags\": [], \"bucket_quota\": { \"enabled\": false, \"check_on_raw\": false, \"max_size\": -1, \"max_size_kb\": 0, \"max_objects\": -1 }, \"user_quota\": { \"enabled\": false, \"check_on_raw\": false, \"max_size\": -1, \"max_size_kb\": 0, \"max_objects\": -1 }, \"temp_url_keys\": [], \"type\": \"rgw\", \"mfa_ids\": [] } Test S3 service in cluster Connect the toolbox and test the object storage inside the cluster. kubectl -n rook-ceph exec -it $( kubectl -n rook-ceph get pod -l \"app=rook-ceph-tools\" -o jsonpath = '{.items[0].metadata.name}' ) bash yum --assumeyes install s3cmd # The content is as bellow. The host is where the rgw service is listening. Run kubectl -n rook-ceph get svc rook-ceph-rgw-my-store, then combine the clusterIP and the port. vi .s3cfg s3cmd mb s3://test-bucket s3cmd ls [default] access_key = Y14QX4KYOBCdvwMU6E5R secret_key = AbeWMQPzpGhZPCMOq9IEkZSxLIgtooQsdvx4Cb4v host_base = 10.100.191.33 host_bucket = 10.100.191.33/%(bucket) use_https = False Create S3 external service Create the external service for the object store by using NodePort in the rgw-external.yaml. Cannot use Traefik here because it automatically redirect http to https which is not allowed in s3cmd. apiVersion : v1 kind : Service metadata : name : rook-ceph-rgw-my-store-external namespace : rook-ceph labels : app : rook-ceph-rgw rook_cluster : rook-ceph rook_object_store : my-store spec : ports : - name : rgw port : 80 protocol : TCP targetPort : 80 selector : app : rook-ceph-rgw rook_cluster : rook-ceph rook_object_store : my-store sessionAffinity : None type : NodePort kubectl apply -f rgw-external.yaml Test S3 service outside cluster Test the object storage outside the cluster. Remember to replace the credentials and endpoint. # For windows we can download the s3cmd code from github and then \"python s3cmd --configure\" to save the configuration and then edit it with the below content. # Run kubectl -n rook-ceph get service rook-ceph-rgw-my-store-external, then combine the node public ip and the external port as the host bellow. # Run python s3cmd ls to test on Windows [default] access_key = Y14QX4KYOBC83Vsev6E5R secret_key = AbeWMQPzpGhZPCMOq9IEkZSLIsetooQcUfx4Cb4v host_base = *:* host_bucket = *:*/%(bucket) use_https = False Test S3 service in Java Test the object storage with java code. Remember to replace the credentials and endpoint. The code works for both Amazon S3 and Ceph S3 except the conn part. //The conn here is for Ceph S3 AWSCredentials credentials = new BasicAWSCredentials ( \"***\" , \"***\" ); ClientConfiguration clientConfig = new ClientConfiguration (); clientConfig . setProtocol ( Protocol . HTTP ); AmazonS3 conn = AmazonS3Client . builder () . withCredentials ( new AWSStaticCredentialsProvider ( credentials )) . withClientConfiguration ( clientConfig ) //Important for Ceph . withEndpointConfiguration ( new AwsClientBuilder . EndpointConfiguration ( \"*:*\" , null )) //Important for Ceph . enablePathStyleAccess () //Important for Ceph . build (); //The conn here is for Amazon S3 //AWSCredentials credentials = new BasicAWSCredentials(\"***\", \"***\"); //AmazonS3 conn = AmazonS3Client.builder() // .withRegion(\"ap-northeast-1\") //Important for Amazon // .withCredentials(new AWSStaticCredentialsProvider(credentials)) // .build(); File file = new File ( \"C:\\\\Users\\\\fanf\\\\Pictures\\\\test.jpg\" ); FileInputStream bais = new FileInputStream ( file ); ObjectMetadata metadata = new ObjectMetadata (); metadata . setContentLength ( file . length ()); metadata . setContentType ( \"image/jpg\" ); conn . putObject ( \"test-bucket\" , \"test.jpg\" , bais , metadata ); conn . setObjectAcl ( \"test-bucket\" , \"test.jpg\" , CannedAccessControlList . PublicRead ); ListObjectsRequest listObjectsRequest = new ListObjectsRequest (). withBucketName ( \"test-bucket\" ). withDelimiter ( \"test-bucket/\" ); ObjectListing objects2 = conn . listObjects ( listObjectsRequest ); Helper . println ( objects2 ); conn . setBucketPolicy ( \"test-bucket\" , \"public-read-write\" ); Bucket bucket2 = conn . createBucket ( \"new-bucket\" ); ByteArrayInputStream input = new ByteArrayInputStream ( \"Hello World!\" . getBytes ()); conn . putObject ( bucket2 . getName (), \"hello.txt\" , input , new ObjectMetadata ()); conn . setObjectAcl ( bucket2 . getName (), \"hello.txt\" , CannedAccessControlList . PublicRead ); List < Bucket > buckets = conn . listBuckets (); for ( Bucket bucket : buckets ) { Helper . println ( bucket . getName () + \"\\t\" + StringUtils . fromDate ( bucket . getCreationDate ())); ObjectListing objects = conn . listObjects ( bucket . getName ()); do { for ( S3ObjectSummary objectSummary : objects . getObjectSummaries ()) { Helper . println ( objectSummary . getKey () + \"\\t\" + objectSummary . getSize () + \"\\t\" + StringUtils . fromDate ( objectSummary . getLastModified ())); } objects = conn . listNextBatchOfObjects ( objects ); } while ( objects . isTruncated ()); }","title":"Build Ceph and Kubernetes based distributed file storage system"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#install","text":"","title":"Install"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#download-rook","text":"Download the rook ceph GitHub code. git clone --single-branch --branch release-1.2 https://github.com/rook/rook.git","title":"Download rook"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#copy-yaml","text":"Copy the common.yaml, operator.yaml and toolbox.yaml files from ./rook/cluster/examples/kubernetes/ceph/. cp ../rook/cluster/examples/kubernetes/ceph/common.yaml ../rook/cluster/examples/kubernetes/ceph/operator.yaml ../rook/cluster/examples/kubernetes/ceph/toolbox.yaml .","title":"Copy yaml"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#create-rook-containers","text":"Create the rook ceph containers, and wait the operator to be running status. kubectl apply -f common.yaml kubectl apply -f operator.yaml kubectl get pod -n rook-ceph","title":"Create rook containers"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#create-volumes","text":"Create 3 20G volumes and attach to 3 linux instances. Format the disks. Mkdir /mnt/ceph-storage and mount them all. sudo fdisk -l sudo mkfs.ext4 /dev/vdc sudo mount /dev/vdb /mnt/ceph-storage -t auto df -h Filesystem Size Used Avail Use% Mounted on /dev/vda1 30G 19G 11G 65% / devtmpfs 2.9G 0 2.9G 0% /dev tmpfs 2.9G 12K 2.9G 1% /dev/shm tmpfs 2.9G 298M 2.6G 11% /run tmpfs 2.9G 0 2.9G 0% /sys/fs/cgroup tmpfs 581M 0 581M 0% /run/user/1000 /dev/vdb 20G 45M 19G 1% /mnt/ceph-storage","title":"Create volumes"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#create-ceph-cluster","text":"Create cluster by the cluster.yaml. Notice the selected nodes have the disks attached. Each nodes/name field should match their kubernetes.io/hostname label. Notice the dashboard should be disabled first. apiVersion : ceph.rook.io/v1 kind : CephCluster metadata : name : rook-ceph namespace : rook-ceph spec : dataDirHostPath : /var/lib/rook mon : count : 3 cephVersion : image : ceph/ceph:v14.2.4-20190917 allowUnsupported : false dashboard : enabled : false network : hostNetwork : false storage : useAllNodes : false useAllDevices : false config : metadataDevice : databaseSizeMB : \"1024\" # this value can be removed for environments with normal sized disks (100 GB or larger) journalSizeMB : \"1024\" # this value can be removed for environments with normal sized disks (20 GB or larger) nodes : - name : \"slave.novalocal\" directories : # specific directories to use for storage can be specified for each node - path : \"/mnt/ceph-storage\" - name : \"static.novalocal\" directories : # specific directories to use for storage can be specified for each node - path : \"/mnt/ceph-storage\" - name : \"db.novalocal\" directories : # specific directories to use for storage can be specified for each node - path : \"/mnt/ceph-storage\" kubectl apply -f cluster.yaml kubectl get pod -n rook-ceph --watch","title":"Create Ceph cluster"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#re-create-operator-and-check-osd","text":"If error happens, remember to delete the folder dataDirHostPath on all nodes and delete the operator, then try again to create the cluster. Attach the operator pod to see the logs. When 3 mon and 3 osd pods are running it means the cluster is successfully created. sudo rm -rf /var/lib/rook kubectl delete -f operator.yaml kubectl logs -f rook-ceph-operator-6b79d99f5c-9564s -n rook-ceph kubectl get pod -n rook-ceph NAME READY STATUS RESTARTS AGE csi-cephfsplugin-265lj 3/3 Running 0 37m csi-cephfsplugin-2b47v 3/3 Running 0 37m csi-cephfsplugin-2dw6z 3/3 Running 0 37m csi-cephfsplugin-2xgns 3/3 Running 0 37m csi-cephfsplugin-54hd5 3/3 Running 0 37m csi-cephfsplugin-9rgr8 3/3 Running 0 37m csi-cephfsplugin-provisioner-5d999b68d6-8vc2k 4/4 Running 0 37m csi-cephfsplugin-provisioner-5d999b68d6-xjg4z 4/4 Running 0 37m csi-cephfsplugin-sp289 3/3 Running 0 37m csi-rbdplugin-7gk9s 3/3 Running 0 37m csi-rbdplugin-9sbwh 3/3 Running 0 37m csi-rbdplugin-jwvxx 3/3 Running 0 37m csi-rbdplugin-n9tcd 3/3 Running 0 37m csi-rbdplugin-provisioner-69b7d7887-4l9l9 5/5 Running 0 37m csi-rbdplugin-provisioner-69b7d7887-g48rb 5/5 Running 0 37m csi-rbdplugin-q9q5b 3/3 Running 0 37m csi-rbdplugin-snhqj 3/3 Running 0 37m csi-rbdplugin-v6jb8 3/3 Running 0 37m rook-ceph-crashcollector-db.novalocal-fd7dcc457-qd7tx 1/1 Running 0 11m rook-ceph-crashcollector-deamon.novalocal-7789457f5-v6vnc 1/1 Running 0 11m rook-ceph-crashcollector-slave.novalocal-5d698c7d7b-hgbnw 1/1 Running 0 9m59s rook-ceph-crashcollector-static.novalocal-58f769ccc-lsf5b 1/1 Running 0 9m54s rook-ceph-crashcollector-test.novalocal-6fdc8dbc4f-ksk75 1/1 Running 0 10m rook-ceph-mgr-a-7898b59757-84tbd 1/1 Running 0 10m rook-ceph-mon-a-7676f96769-5mhc6 1/1 Running 0 12m rook-ceph-mon-b-79c9c9b59d-g82sc 1/1 Running 0 11m rook-ceph-mon-c-7b679d7497-x2hjg 1/1 Running 0 11m rook-ceph-operator-6b79d99f5c-9564s 1/1 Running 0 14m rook-ceph-osd-0-5b59576bb4-rgsx8 1/1 Running 0 9m57s rook-ceph-osd-1-74ff9d79c6-hpkc2 1/1 Running 0 9m55s rook-ceph-osd-2-57748ff6bf-vf8jl 1/1 Running 0 9m59s rook-ceph-osd-prepare-db.novalocal-jf84v 0/1 Completed 0 10m rook-ceph-osd-prepare-slave.novalocal-j457l 0/1 Completed 0 10m rook-ceph-osd-prepare-static.novalocal-jt4vj 0/1 Completed 0 10m rook-discover-hwffd 1/1 Running 0 13m rook-discover-jh8j5 1/1 Running 0 13m rook-discover-mcdjn 1/1 Running 0 13m rook-discover-mmzcb 1/1 Running 0 13m rook-discover-mppgh 1/1 Running 0 13m rook-discover-tz5gm 1/1 Running 0 13m rook-discover-vj7tg 1/1 Running 0 13m","title":"Re-create operator and check osd"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#create-toolbox-and-test","text":"Create toolbox pods by toolbox.yaml, and we can attach the pod then test the ceph status. kubectl apply -f toolbox.yaml kubectl -n rook-ceph exec -it $( kubectl -n rook-ceph get pod -l \"app=rook-ceph-tools\" -o jsonpath = '{.items[0].metadata.name}' ) bash ceph status ceph osd status ceph df rados df [ root @ rook - ceph - tools - 787 dc6b944 - spsjh / ] # ceph status cluster : id : 2095 eaca - 93 b3 - 4365 - a5c8 - 9 b05269821a9 health : HEALTH_OK services : mon : 3 daemons , quorum a , b , c ( age 26 m ) mgr : a ( active , since 26 m ) osd : 3 osds : 3 up ( since 25 m ), 3 in ( since 25 m ) data : pools : 0 pools , 0 pgs objects : 0 objects , 0 B usage : 6.4 GiB used , 52 GiB / 59 GiB avail pgs :","title":"Create toolbox and test"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#enable-dashboard","text":"Modify the cluster.yaml to enable dashboard and apply to create the dashboard service. vim cluster.yaml kubectl apply -f cluster.yaml kubectl get svc -n rook-ceph | grep mgr-dashboard rook-ceph-mgr-dashboard ClusterIP 10.36.19.173 <none> 7000/TCP 66s","title":"Enable dashboard"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#create-dashboard-ingress","text":"Now the dashboard service is ClusterIP mode which means we can only visit it in the cluster. Create dashboard Traefik yaml file dashboard-ingress.yaml to visit publicly. apiVersion : extensions/v1beta1 kind : Ingress metadata : name : ceph-dashboard-ingress namespace : rook-ceph spec : rules : - host : dashboard.*.* http : paths : - path : / backend : serviceName : rook-ceph-mgr-dashboard servicePort : 7000 kubectl apply -f dashboard-ingress.yaml","title":"Create dashboard ingress"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#inspect-dashboard-password","text":"Inspect the dashboard secret. The username is admin. kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath = \"{['data']['password']}\" | base64 --decode && echo","title":"Inspect dashboard password"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#create-object-gateway","text":"Create object gateway by the object.yaml. apiVersion : ceph.rook.io/v1 kind : CephObjectStore metadata : name : my-store namespace : rook-ceph spec : metadataPool : failureDomain : host replicated : size : 3 dataPool : failureDomain : host replicated : size : 3 preservePoolsOnDelete : false gateway : type : s3 sslCertificateRef : port : 80 securePort : instances : 1 placement : annotations : resources : kubectl apply -f object.yaml kubectl -n rook-ceph get pod -l app = rook-ceph-rgw","title":"Create object gateway"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#create-radosgw-user","text":"Create a radosgw user in the toolbox. kubectl -n rook-ceph exec -it $( kubectl -n rook-ceph get pod -l \"app=rook-ceph-tools\" -o jsonpath = '{.items[0].metadata.name}' ) bash radosgw-admin user create --uid = myuser --display-name = test-user --system ceph dashboard set-rgw-api-user-id myuser ceph dashboard set-rgw-api-access-key 32APIT3RA29JCO6OCR8P ceph dashboard set-rgw-api-secret-key 2ioxTu6iBFkYP8UKiycS90A2DFwRBklSI8Bp3iPQ { \"user_id\": \"myuser\", \"display_name\": \"test-user\", \"email\": \"\", \"suspended\": 0, \"max_buckets\": 1000, \"subusers\": [], \"keys\": [ { \"user\": \"myuser\", \"access_key\": \"32APIT3RA29JCO6OCR8P\", \"secret_key\": \"2ioxTu6iBFkYP8UKiycS90A2DFwRBklSI8Bp3iPQ\" } ], \"swift_keys\": [], \"caps\": [], \"op_mask\": \"read, write, delete\", \"system\": \"true\", \"default_placement\": \"\", \"default_storage_class\": \"\", \"placement_tags\": [], \"bucket_quota\": { \"enabled\": false, \"check_on_raw\": false, \"max_size\": -1, \"max_size_kb\": 0, \"max_objects\": -1 }, \"user_quota\": { \"enabled\": false, \"check_on_raw\": false, \"max_size\": -1, \"max_size_kb\": 0, \"max_objects\": -1 }, \"temp_url_keys\": [], \"type\": \"rgw\", \"mfa_ids\": [] }","title":"Create radosgw user"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#test-s3-service-in-cluster","text":"Connect the toolbox and test the object storage inside the cluster. kubectl -n rook-ceph exec -it $( kubectl -n rook-ceph get pod -l \"app=rook-ceph-tools\" -o jsonpath = '{.items[0].metadata.name}' ) bash yum --assumeyes install s3cmd # The content is as bellow. The host is where the rgw service is listening. Run kubectl -n rook-ceph get svc rook-ceph-rgw-my-store, then combine the clusterIP and the port. vi .s3cfg s3cmd mb s3://test-bucket s3cmd ls [default] access_key = Y14QX4KYOBCdvwMU6E5R secret_key = AbeWMQPzpGhZPCMOq9IEkZSxLIgtooQsdvx4Cb4v host_base = 10.100.191.33 host_bucket = 10.100.191.33/%(bucket) use_https = False","title":"Test S3 service in cluster"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#create-s3-external-service","text":"Create the external service for the object store by using NodePort in the rgw-external.yaml. Cannot use Traefik here because it automatically redirect http to https which is not allowed in s3cmd. apiVersion : v1 kind : Service metadata : name : rook-ceph-rgw-my-store-external namespace : rook-ceph labels : app : rook-ceph-rgw rook_cluster : rook-ceph rook_object_store : my-store spec : ports : - name : rgw port : 80 protocol : TCP targetPort : 80 selector : app : rook-ceph-rgw rook_cluster : rook-ceph rook_object_store : my-store sessionAffinity : None type : NodePort kubectl apply -f rgw-external.yaml","title":"Create S3 external service"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#test-s3-service-outside-cluster","text":"Test the object storage outside the cluster. Remember to replace the credentials and endpoint. # For windows we can download the s3cmd code from github and then \"python s3cmd --configure\" to save the configuration and then edit it with the below content. # Run kubectl -n rook-ceph get service rook-ceph-rgw-my-store-external, then combine the node public ip and the external port as the host bellow. # Run python s3cmd ls to test on Windows [default] access_key = Y14QX4KYOBC83Vsev6E5R secret_key = AbeWMQPzpGhZPCMOq9IEkZSLIsetooQcUfx4Cb4v host_base = *:* host_bucket = *:*/%(bucket) use_https = False","title":"Test S3 service outside cluster"},{"location":"bestpractice/build-ceph-and-k8s-based-distributed-file-storage-system/#test-s3-service-in-java","text":"Test the object storage with java code. Remember to replace the credentials and endpoint. The code works for both Amazon S3 and Ceph S3 except the conn part. //The conn here is for Ceph S3 AWSCredentials credentials = new BasicAWSCredentials ( \"***\" , \"***\" ); ClientConfiguration clientConfig = new ClientConfiguration (); clientConfig . setProtocol ( Protocol . HTTP ); AmazonS3 conn = AmazonS3Client . builder () . withCredentials ( new AWSStaticCredentialsProvider ( credentials )) . withClientConfiguration ( clientConfig ) //Important for Ceph . withEndpointConfiguration ( new AwsClientBuilder . EndpointConfiguration ( \"*:*\" , null )) //Important for Ceph . enablePathStyleAccess () //Important for Ceph . build (); //The conn here is for Amazon S3 //AWSCredentials credentials = new BasicAWSCredentials(\"***\", \"***\"); //AmazonS3 conn = AmazonS3Client.builder() // .withRegion(\"ap-northeast-1\") //Important for Amazon // .withCredentials(new AWSStaticCredentialsProvider(credentials)) // .build(); File file = new File ( \"C:\\\\Users\\\\fanf\\\\Pictures\\\\test.jpg\" ); FileInputStream bais = new FileInputStream ( file ); ObjectMetadata metadata = new ObjectMetadata (); metadata . setContentLength ( file . length ()); metadata . setContentType ( \"image/jpg\" ); conn . putObject ( \"test-bucket\" , \"test.jpg\" , bais , metadata ); conn . setObjectAcl ( \"test-bucket\" , \"test.jpg\" , CannedAccessControlList . PublicRead ); ListObjectsRequest listObjectsRequest = new ListObjectsRequest (). withBucketName ( \"test-bucket\" ). withDelimiter ( \"test-bucket/\" ); ObjectListing objects2 = conn . listObjects ( listObjectsRequest ); Helper . println ( objects2 ); conn . setBucketPolicy ( \"test-bucket\" , \"public-read-write\" ); Bucket bucket2 = conn . createBucket ( \"new-bucket\" ); ByteArrayInputStream input = new ByteArrayInputStream ( \"Hello World!\" . getBytes ()); conn . putObject ( bucket2 . getName (), \"hello.txt\" , input , new ObjectMetadata ()); conn . setObjectAcl ( bucket2 . getName (), \"hello.txt\" , CannedAccessControlList . PublicRead ); List < Bucket > buckets = conn . listBuckets (); for ( Bucket bucket : buckets ) { Helper . println ( bucket . getName () + \"\\t\" + StringUtils . fromDate ( bucket . getCreationDate ())); ObjectListing objects = conn . listObjects ( bucket . getName ()); do { for ( S3ObjectSummary objectSummary : objects . getObjectSummaries ()) { Helper . println ( objectSummary . getKey () + \"\\t\" + objectSummary . getSize () + \"\\t\" + StringUtils . fromDate ( objectSummary . getLastModified ())); } objects = conn . listNextBatchOfObjects ( objects ); } while ( objects . isTruncated ()); }","title":"Test S3 service in Java"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/","text":"As Jenkins is one of the most popular CI tools on the market with over a thousand plugins, in this article, we are going to set up a CI pipeline for a SpringBoot application. Install Install docker Start the docker service and login the docker hub. sudo curl -sSL https://get.docker.com/ | sh sudo service docker start sudo docker login Install docker-compose sudo -i curl -L https://github.com/docker/compose/releases/download/1.16.0-rc2/docker-compose- ` uname -s ` - ` uname -m ` > /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose Create jenkins container Start Jenkins container and configure the user. sudo docker run --name jenkins -p 8080 :8080 -p 50000 :50000 -v /var/jenkins_home jenkins Deploy SSH key Use nsenter to attach the Jenkins container, and run commands in Jenkins container to generate ssh key, then the Jenkins server will have .ssh folder generated under ~, under the .ssh folder there are id_rsa (private key) and id_rsa.pub (public key). Copy the content in id_rsa.pub, and go back to the remote server on which jenkins will SSH and execute shell scripts and deploy the application, and paste the content in ~/authorized_keys. sudo docker run -v /usr/local/bin:/target jpetazzo/nsenter PID = $( sudo docker inspect --format {{ .State.Pid }} jenkins ) sudo nsenter --target $PID --mount --uts --ipc --net --pid ssh-keygen -t rsa #Copy key Restart the SSH service Restart the ssh service in remote server, and create a folder to put scripts into it and modify the permission of it. For example: ~/agriculture-platform. service sshd restart sudo mkdir ~/agriculture-platform/ sudo chmod 777 ~/agriculture-platform/ Jenkins configuration Publish over SSH plugin Install the plugin \"Publish over SSH\" in Jenkins, and configure it, then test the connection. Generate API token Login your jenkins with admin user and click the user on the right hand side, then select configure and generate a token here. Create maven project Create a maven project in Jenkins, configure the git URL and credentials for it. Enable build trigger Enable the remote build trigger token which is the above generated API token. Build maven commands Configure the build step with maven build commands. After build steps Configure the after build step to SSH and copy the jar file to the remote server. Here we execute a shell script to deploy the SpringBoot application. Create webhook in Github Login the Bitbucket or Github and enter your SpringBoot project, enter the Webhooks page, add new a webhook with Jenkins server info and your job name and the above generated API token. The webhook will be invoked when you push any code to the master branch. The related jenkins project will receive this webhook request and execute the build job immediately. Try push code If we try to push the code to Bitbucket now, we will find a webhook request error in Webhooks page. Configure global security We should login the Jenkins and configure the Global Security and enable the webhook in order to fix the above issue. Deploy configuration Shell scripts Now Jenkins is configured to transfer the SpringBoot jar to \"~/agriculture-platform\" folder and run the shell script \"~/agriculture-platform/rebuild.sh\". Login the remote server, we create \"agriculture-platform\" folder under ~, and create Dockerfile and rebuild.sh under it. SpringBoot Dockerfile The Dockerfile content is as bellow, it creates a docker image and copy the jar into it, then run the jar. FROM hustakin/java8 MAINTAINER Frankie Fan \"hustakin@gmail.com\" VOLUME /tmp ADD agriculture-platform.jar agriculture-platform.jar ENTRYPOINT [ \"java\" , \"-Djava.security.egd=file:/dev/./urandom\" , \"-Dspring.profiles.active=docker\" , \"-jar\" , \"/agriculture-platform.jar\" ] EXPOSE 8001 8002 Build scripts The rebuild.sh content is as bellow, it creates a docker image and copy the jar into it, then run the jar. #!/bin/bash cd ~/docker/agriculture-platform/ sudo docker stop agriculture sudo docker rm agriculture sudo docker build --no-cache -t = \"hustakin/test\" . sudo docker run -p 80 :80 -p 443 :443 -v /data/log/dev:/logs --name agriculture --restart = always -d hustakin/test --param = hello Push code After all the above configurations, now we completely finish the CI process. When we push the code to Bitbucket or Github, the Jenkins will start to maven build the code and transfer the jar to the remote server, then the remote server will rebuild the SpringBoot docker image and recreate the docker container.","title":"Continuous Integration with Jenkins and Docker"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#install","text":"","title":"Install"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#install-docker","text":"Start the docker service and login the docker hub. sudo curl -sSL https://get.docker.com/ | sh sudo service docker start sudo docker login","title":"Install docker"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#install-docker-compose","text":"sudo -i curl -L https://github.com/docker/compose/releases/download/1.16.0-rc2/docker-compose- ` uname -s ` - ` uname -m ` > /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose","title":"Install docker-compose"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#create-jenkins-container","text":"Start Jenkins container and configure the user. sudo docker run --name jenkins -p 8080 :8080 -p 50000 :50000 -v /var/jenkins_home jenkins","title":"Create jenkins container"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#deploy-ssh-key","text":"Use nsenter to attach the Jenkins container, and run commands in Jenkins container to generate ssh key, then the Jenkins server will have .ssh folder generated under ~, under the .ssh folder there are id_rsa (private key) and id_rsa.pub (public key). Copy the content in id_rsa.pub, and go back to the remote server on which jenkins will SSH and execute shell scripts and deploy the application, and paste the content in ~/authorized_keys. sudo docker run -v /usr/local/bin:/target jpetazzo/nsenter PID = $( sudo docker inspect --format {{ .State.Pid }} jenkins ) sudo nsenter --target $PID --mount --uts --ipc --net --pid ssh-keygen -t rsa #Copy key","title":"Deploy SSH key"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#restart-the-ssh-service","text":"Restart the ssh service in remote server, and create a folder to put scripts into it and modify the permission of it. For example: ~/agriculture-platform. service sshd restart sudo mkdir ~/agriculture-platform/ sudo chmod 777 ~/agriculture-platform/","title":"Restart the SSH service"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#jenkins-configuration","text":"","title":"Jenkins configuration"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#publish-over-ssh-plugin","text":"Install the plugin \"Publish over SSH\" in Jenkins, and configure it, then test the connection.","title":"Publish over SSH plugin"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#generate-api-token","text":"Login your jenkins with admin user and click the user on the right hand side, then select configure and generate a token here.","title":"Generate API token"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#create-maven-project","text":"Create a maven project in Jenkins, configure the git URL and credentials for it.","title":"Create maven project"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#enable-build-trigger","text":"Enable the remote build trigger token which is the above generated API token.","title":"Enable build trigger"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#build-maven-commands","text":"Configure the build step with maven build commands.","title":"Build maven commands"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#after-build-steps","text":"Configure the after build step to SSH and copy the jar file to the remote server. Here we execute a shell script to deploy the SpringBoot application.","title":"After build steps"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#create-webhook-in-github","text":"Login the Bitbucket or Github and enter your SpringBoot project, enter the Webhooks page, add new a webhook with Jenkins server info and your job name and the above generated API token. The webhook will be invoked when you push any code to the master branch. The related jenkins project will receive this webhook request and execute the build job immediately.","title":"Create webhook in Github"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#try-push-code","text":"If we try to push the code to Bitbucket now, we will find a webhook request error in Webhooks page.","title":"Try push code"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#configure-global-security","text":"We should login the Jenkins and configure the Global Security and enable the webhook in order to fix the above issue.","title":"Configure global security"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#deploy-configuration","text":"","title":"Deploy configuration"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#shell-scripts","text":"Now Jenkins is configured to transfer the SpringBoot jar to \"~/agriculture-platform\" folder and run the shell script \"~/agriculture-platform/rebuild.sh\". Login the remote server, we create \"agriculture-platform\" folder under ~, and create Dockerfile and rebuild.sh under it.","title":"Shell scripts"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#springboot-dockerfile","text":"The Dockerfile content is as bellow, it creates a docker image and copy the jar into it, then run the jar. FROM hustakin/java8 MAINTAINER Frankie Fan \"hustakin@gmail.com\" VOLUME /tmp ADD agriculture-platform.jar agriculture-platform.jar ENTRYPOINT [ \"java\" , \"-Djava.security.egd=file:/dev/./urandom\" , \"-Dspring.profiles.active=docker\" , \"-jar\" , \"/agriculture-platform.jar\" ] EXPOSE 8001 8002","title":"SpringBoot Dockerfile"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#build-scripts","text":"The rebuild.sh content is as bellow, it creates a docker image and copy the jar into it, then run the jar. #!/bin/bash cd ~/docker/agriculture-platform/ sudo docker stop agriculture sudo docker rm agriculture sudo docker build --no-cache -t = \"hustakin/test\" . sudo docker run -p 80 :80 -p 443 :443 -v /data/log/dev:/logs --name agriculture --restart = always -d hustakin/test --param = hello","title":"Build scripts"},{"location":"bestpractice/continuous-integration-with-jenkins-and-docker/#push-code","text":"After all the above configurations, now we completely finish the CI process. When we push the code to Bitbucket or Github, the Jenkins will start to maven build the code and transfer the jar to the remote server, then the remote server will rebuild the SpringBoot docker image and recreate the docker container.","title":"Push code"},{"location":"bestpractice/create--app-icon-launch-screen-for-flutter/","text":"Use Canva to create a icon design and download the png file. Please be noted you should open the image file and export an image with no alpha channel because iOS's restriction. Install the flutter_launch_icons plugin. Please be noted you'd better install it into dev_dependencies rather than dependencies. #pubspec.yaml dev_dependencies : flutter_test : sdk : flutter flutter_launcher_icons : ^0.7.5 flutter_icons : android : true ios : true image_path : \"dev_assets/icon.png\" adaptive_icon_background : \"#ED7F61\" adaptive_icon_foreground : \"dev_assets/icon.png\" Copy the icon to the dev_assets of the project, and open the icon image to get the background color and put into the adaptive_icon_backgound. Run the following command to generate all relevant icons. flutter pub run flutter_launcher_icons:main Add the following content into the launch_background.xml of the Android part. <item> <color android:color= \"@color/ic_launcher_background\" /> </item> <item> <bitmap android:gravity= \"center\" android:src= \"@drawable/ic_launcher_foreground\" /> </item> Install the app into the Android simulator and see the result. Please be noted the Android app name could be specified in the AndroidManifest.xml file. Please be noted the iOS app name could be specified in the Info.plist file. Open the ios project by Xcode and drag the logo into the LaunchImage part. Change the icon background color for iOS. Now you should run the following command to build iOS app rather than build it in Xcode. flutter build ios Install the app into the iOS simulator and see the result. For Google Play feature graphic image, you could easily use this website to generate a simple one.","title":"How to create an app icon and launch screen for flutter"},{"location":"bestpractice/developing-based-on-geoserver-restful-api/","text":"GeoServer provides a RESTful interface through which clients can retrieve information about an instance and make configuration changes. Using the REST interface's simple HTTP calls, clients can configure GeoServer without needing to use the Web administration interface. REST is an acronym for \"REpresentational State Transfer\". REST adopts a fixed set of operations on named resources, where the representation of each resource is the same for retrieving and setting information. In other words, you can retrieve (read) data in an XML format and also send data back to the server in similar XML format in order to set (write) changes to the system. Operations on resources are implemented with the standard primitives of HTTP: GET to read; and PUT, POST, and DELETE to write changes. Each resource is represented as a URL, such as http://GEOSERVER_HOME/rest/workspaces/topp. Steps to configure authentication We want to developing based on GeoServer restful api, the first thing would be configuring GeoServer to accept authentication information passed by HTTP header attribute(s). Rest properties file The REST process has its own security configuration that needs to be setup in addition to the web interface user. These are different configurations and are setup in different spots. The REST configuration does use that same users you have configured in the web interface it just doesn't use the access rules that you would have set up. To know about the permissions you need to view a file in the directory [Geoserver_data}/security called rest.properties. Rest properties From the properties file content, we can see all the rest api will need admin user authentication. Users, groups and roles From the GeoServer web ui, we can define users, groups and roles. Rest test If we try to test any GeoServer rest api without any configuration, we will meet a 401 error because of no authentication. Authentication filters Click the Authentication link located under the Security section of the navigation sidebar. Scroll down to the Authentication Filters panel and click the Add new link. Add authentication filter Click the HTTP Header link and set \"Name\" to anything you'd like, Set Request header attribute to to a random token other than \"user\" or \"admin\". It's a obscure header attribute name which is a shared secret between the proxy and GeoServer. Set Role source to \"User group service\" and name of the user group service to \"default\". Authentication filter chains Go back to the Authentication link and scroll down to the Filter Chains panel. Notice the rest filter chain here and click into it. Configure rest filter chain Scroll down to the Chain filters panel. Drag the newly added authentication filter to the selected part and position it before all other filters. Rest test successful Try the rest api again with specified header which is the Request header attribute we just set and with the value of \"admin\". Restful APIs The full restful api list can be found here . List workspaces GET http://<url>/geoserver/rest/workspaces List layers in a workspace GET http://<url>/geoserver/rest/workspaces/<workspaceName>/layers List coverage stores which describe the raster data source GET http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores List styles in a workspace GET http://<url>/geoserver/rest/workspaces/<workspaceName>/styles List styles under a layer GET http://<url>/geoserver/rest/layers/<layerName>/styles List styles GET http://<url>/geoserver/rest/styles Get a workspace GET http://<url>/geoserver/rest/workspaces/<workspaceName> Get a layer in a workspace GET http://<url>/geoserver/rest/workspaces/<workspaceName>/layers/<layerName> Get a coverage store in a workspace GET http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores/<storeName> Get a sld style in a workspace GET http://<url>/geoserver/rest/workspaces/<workspaceName>/styles/<styleName>.sld Get the info of a layer in a workspace GET http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores/<storeName>>/coverages/<layerName>.json Create a workspace POST http://<url>/geoserver/rest/workspaces Create a coverage store in a workspace POST http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores?configure=all Create a layer in a workspace POST http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores/<storeName>/coverages?configure=all&recalculate=nativebbox,latlonbbox Create a layer with default style in a workspace POST http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores/<storeName>/coverages?configure=all&recalculate=nativebbox,latlonbbox Create a sld style POST http://<url>/geoserver/rest/styles?name=<styleName> Specify the default style for a layer PUT http://<url>/geoserver/rest/layers/<workspaceName>:<layerName> Modify a sld style content PUT http://<url>/geoserver/rest/styles/<styleName>.xml?name=<styleName> Delete a workspace DELETE http://<url>/geoserver/rest/workspaces/<workspaceName>?recurse=true Delete a coverage store in a workspace DELETE http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores/<storeName>.geotiff Delete a layer DELETE http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores/<storeName>/coverages/<layerName>?recurse=true Delete a style DELETE http://<url>/geoserver/rest/styles/<styleName> Other Service APIs After you have served your raster layer on the GeoServer, you are able to get some information by WMS/WMTS protocol and so on. WMS GetFeatureInfo GET http://<url>/geoserver/gwc/service/wms?REQUEST=GetFeatureInfo&SERVICE=WMS&SRS=<SRS>&STYLES=&TRANSPARENT=&VERSION=1.0.0&FORMAT=image/png&BBOX=<BBOX>&HEIGHT=<HEIGHT>&WIDTH=<WIDTH>&LAYERS=<workspaceName>:<layerName>&QUERY_LAYERS=<workspaceName>:<layerName>&INFO_FORMAT=application/json&X=<X>&Y=<Y> WMS GetLegendGraphic GET http://<url>/geoserver/gwc/service/wms?SERVICE=WMS&VERSION=1.0.0&REQUEST=GetLegendGraphic&FORMAT=image/png&WIDTH=20&HEIGHT=20&layer=<workspaceName>:<layerName>[&style=<styleName> or &sld_body=<sldContent>] WMS GetMap GET http://<url>/geoserver/gwc/service/wms?SERVICE=WMS&VERSION=1.1.1&REQUEST=GetMap&FORMAT=image/png&TRANSPARENT=true&LAYERS=<workspaceName>:<layerName>&STYLES=<styleName>&FORMAT_OPTIONS=layout:style-editor-legend;fontAntiAliasing:true&LEGEND_OPTIONS=forceLabels:on;fontAntiAliasing:true&EXCEPTIONS=application/vnd.ogc.se_inimage&CRS=<CRS>&WIDTH=688&HEIGHT=768&BBOX=<BBOX>","title":"Developing based on GeoServer restful api"},{"location":"bestpractice/developing-based-on-geoserver-restful-api/#steps-to-configure-authentication","text":"We want to developing based on GeoServer restful api, the first thing would be configuring GeoServer to accept authentication information passed by HTTP header attribute(s).","title":"Steps to configure authentication"},{"location":"bestpractice/developing-based-on-geoserver-restful-api/#rest-properties-file","text":"The REST process has its own security configuration that needs to be setup in addition to the web interface user. These are different configurations and are setup in different spots. The REST configuration does use that same users you have configured in the web interface it just doesn't use the access rules that you would have set up. To know about the permissions you need to view a file in the directory [Geoserver_data}/security called rest.properties.","title":"Rest properties file"},{"location":"bestpractice/developing-based-on-geoserver-restful-api/#rest-properties","text":"From the properties file content, we can see all the rest api will need admin user authentication.","title":"Rest properties"},{"location":"bestpractice/developing-based-on-geoserver-restful-api/#users-groups-and-roles","text":"From the GeoServer web ui, we can define users, groups and roles.","title":"Users, groups and roles"},{"location":"bestpractice/developing-based-on-geoserver-restful-api/#rest-test","text":"If we try to test any GeoServer rest api without any configuration, we will meet a 401 error because of no authentication.","title":"Rest test"},{"location":"bestpractice/developing-based-on-geoserver-restful-api/#authentication-filters","text":"Click the Authentication link located under the Security section of the navigation sidebar. Scroll down to the Authentication Filters panel and click the Add new link.","title":"Authentication filters"},{"location":"bestpractice/developing-based-on-geoserver-restful-api/#add-authentication-filter","text":"Click the HTTP Header link and set \"Name\" to anything you'd like, Set Request header attribute to to a random token other than \"user\" or \"admin\". It's a obscure header attribute name which is a shared secret between the proxy and GeoServer. Set Role source to \"User group service\" and name of the user group service to \"default\".","title":"Add authentication filter"},{"location":"bestpractice/developing-based-on-geoserver-restful-api/#authentication-filter-chains","text":"Go back to the Authentication link and scroll down to the Filter Chains panel. Notice the rest filter chain here and click into it.","title":"Authentication filter chains"},{"location":"bestpractice/developing-based-on-geoserver-restful-api/#configure-rest-filter-chain","text":"Scroll down to the Chain filters panel. Drag the newly added authentication filter to the selected part and position it before all other filters.","title":"Configure rest filter chain"},{"location":"bestpractice/developing-based-on-geoserver-restful-api/#rest-test-successful","text":"Try the rest api again with specified header which is the Request header attribute we just set and with the value of \"admin\".","title":"Rest test successful"},{"location":"bestpractice/developing-based-on-geoserver-restful-api/#restful-apis","text":"The full restful api list can be found here . List workspaces GET http://<url>/geoserver/rest/workspaces List layers in a workspace GET http://<url>/geoserver/rest/workspaces/<workspaceName>/layers List coverage stores which describe the raster data source GET http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores List styles in a workspace GET http://<url>/geoserver/rest/workspaces/<workspaceName>/styles List styles under a layer GET http://<url>/geoserver/rest/layers/<layerName>/styles List styles GET http://<url>/geoserver/rest/styles Get a workspace GET http://<url>/geoserver/rest/workspaces/<workspaceName> Get a layer in a workspace GET http://<url>/geoserver/rest/workspaces/<workspaceName>/layers/<layerName> Get a coverage store in a workspace GET http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores/<storeName> Get a sld style in a workspace GET http://<url>/geoserver/rest/workspaces/<workspaceName>/styles/<styleName>.sld Get the info of a layer in a workspace GET http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores/<storeName>>/coverages/<layerName>.json Create a workspace POST http://<url>/geoserver/rest/workspaces Create a coverage store in a workspace POST http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores?configure=all Create a layer in a workspace POST http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores/<storeName>/coverages?configure=all&recalculate=nativebbox,latlonbbox Create a layer with default style in a workspace POST http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores/<storeName>/coverages?configure=all&recalculate=nativebbox,latlonbbox Create a sld style POST http://<url>/geoserver/rest/styles?name=<styleName> Specify the default style for a layer PUT http://<url>/geoserver/rest/layers/<workspaceName>:<layerName> Modify a sld style content PUT http://<url>/geoserver/rest/styles/<styleName>.xml?name=<styleName> Delete a workspace DELETE http://<url>/geoserver/rest/workspaces/<workspaceName>?recurse=true Delete a coverage store in a workspace DELETE http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores/<storeName>.geotiff Delete a layer DELETE http://<url>/geoserver/rest/workspaces/<workspaceName>/coveragestores/<storeName>/coverages/<layerName>?recurse=true Delete a style DELETE http://<url>/geoserver/rest/styles/<styleName>","title":"Restful APIs"},{"location":"bestpractice/developing-based-on-geoserver-restful-api/#other-service-apis","text":"After you have served your raster layer on the GeoServer, you are able to get some information by WMS/WMTS protocol and so on. WMS GetFeatureInfo GET http://<url>/geoserver/gwc/service/wms?REQUEST=GetFeatureInfo&SERVICE=WMS&SRS=<SRS>&STYLES=&TRANSPARENT=&VERSION=1.0.0&FORMAT=image/png&BBOX=<BBOX>&HEIGHT=<HEIGHT>&WIDTH=<WIDTH>&LAYERS=<workspaceName>:<layerName>&QUERY_LAYERS=<workspaceName>:<layerName>&INFO_FORMAT=application/json&X=<X>&Y=<Y> WMS GetLegendGraphic GET http://<url>/geoserver/gwc/service/wms?SERVICE=WMS&VERSION=1.0.0&REQUEST=GetLegendGraphic&FORMAT=image/png&WIDTH=20&HEIGHT=20&layer=<workspaceName>:<layerName>[&style=<styleName> or &sld_body=<sldContent>] WMS GetMap GET http://<url>/geoserver/gwc/service/wms?SERVICE=WMS&VERSION=1.1.1&REQUEST=GetMap&FORMAT=image/png&TRANSPARENT=true&LAYERS=<workspaceName>:<layerName>&STYLES=<styleName>&FORMAT_OPTIONS=layout:style-editor-legend;fontAntiAliasing:true&LEGEND_OPTIONS=forceLabels:on;fontAntiAliasing:true&EXCEPTIONS=application/vnd.ogc.se_inimage&CRS=<CRS>&WIDTH=688&HEIGHT=768&BBOX=<BBOX>","title":"Other Service APIs"},{"location":"bestpractice/flutter-app-distribution-for-testing/","text":"Create a keystore for the app. keytool -genkey -v -keystore ~/key.jks -keyalg RSA -keysize 2048 -validity 10000 -alias key Create the key properties for Android to read the keystore. Please be noted you'd better ignore this key.properties file in .gitignore to not push it onto GitHub. storePassword=* keyPassword=* keyAlias=key storeFile=/Users/Frankie/geofencing-key.jks Go to Flutter docs here to configure signing in gradle for Android. Update the version section in the \"pubspec.yaml\" if needed. Build the release apk package for Android. # APK flutter build apk --release # App bundle (preferred) flutter build appbundle --release Build the release app package for iOS, then open xcode -> Product -> Archive -> Distribute App -> Ad Hoc -> Export to get actual .ipa file. (Remember to update the xcode-Runner-General-Version first) flutter build ios --release Go to App Distribution in Firebase and drag Android apk file/iOS ipa file into related apps. Add testers' email and notes and submit. Testers will receive the app install email. Make sure you have an App ID registered with your app bundler id in your apple developer settings for this apple Create an App in your Apple Connect . Now you will have a lot of information to input for the iOS app. For Android you should also create an App in Google Play Console . We may probably need to configure the SH1 of the app in google cloud console if we use cloud services like google map services. Please be noted there is 1 SH1 for iOS app, and for Android app there is 1 debug SH1 and 1 release SH1 as well as 1 SH1 in Google Play Console. #Check the release keystore (For iOS and Android release app) keytool -list -v -keystore ~/geofencing-key.jks #Check the debug keystore (For Android debug app) keytool -exportcert -alias androiddebugkey -keystore ~/.android/debug.keystore -list -v","title":"How to make flutter app distribution  for testing in Firebase"},{"location":"bestpractice/integrate-google-analytics-with-web-app/","text":"Goto the Google Analytics website. Create an account for the application Select the \"Apps and web\" if having both website and app. Set up a data stream for the website Copy the created data stream gtag code into the header part of website. Feel free to goto the Home or Realtime page to see the analytics.","title":"Integrate Google Analytics with a web application"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/","text":"Quickly responding to new, reactivated, and otherwise important exceptions is a critical part of adopting continuous delivery and other DevOps best practices. Rollbar provides code version-specific dashboards and a live feed for proactively monitoring for exceptions during a deploy, but for those exceptions that happen when you aren't actively watching Rollbar, our Slack integration is the most popular way to get real-time alerts. Connect Rollbar with Github Log in Rollbar with the \"Log in with GitHub\" button, and enables the GitHub integration settings for all your projects. Get started by going to your account settings. Navigate to the \"Connected Accounts\" and Connect with GitHub. Create a project Click the \"create new project\" on the top dropdown list in Rollbar. Create the project from a Github repo directly or specify the new project information to create. Integrate a notifier Select the platform your project is based on. Here I use Java and continue. Wait the data Now we can see the tutorial for your platform and the status for it is waiting. Integrate source control Click the 3rd step to connect source control and select Github, then input the information for your project. Project integration Follow the tutorial on the 1st step page. Add the Rollbar related maven dependencies into your project. Here I add logback dependency into it as well because I'll use logback to send exceptions to Rollbar. <!-- Rollbar --> <dependency> <groupId> com.rollbar </groupId> <version> [1.0,) </version> <artifactId> rollbar-java </artifactId> </dependency> <dependency> <groupId> com.rollbar </groupId> <artifactId> rollbar-logback </artifactId> <version> 1.3.1 </version> </dependency> Logback configuration Here is the configuration of logback file. Please fill in the access token of your Rollbar into the appender and specify your environment name. Use filter in the appender is because we want to log the exception stack into both the file and Rollbar. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <configuration scan= \"true\" scanPeriod= \"60 seconds\" debug= \"false\" > <contextName> logback </contextName> <appender name= \"ROLLBAR\" class= \"com.rollbar.logback.RollbarAppender\" > <accessToken> ec6e37c277c940dcb5d4bcf879fa425c </accessToken> <environment> Dev </environment> <filter class= \"ch.qos.logback.classic.filter.ThresholdFilter\" > <level> warn </level> </filter> </appender> <appender name= \"console\" class= \"ch.qos.logback.core.ConsoleAppender\" > <encoder> <pattern> %date %level [%thread] %-5level %logger{36} [%file:%line] - %msg%n </pattern> </encoder> </appender> <appender name= \"file\" class= \"ch.qos.logback.core.rolling.RollingFileAppender\" > <rollingPolicy class= \"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\" > <fileNamePattern> logs/agriculture.%d{yyyy-MM-dd}.log </fileNamePattern> <maxHistory> 1 </maxHistory> <totalSizeCap> 1GB </totalSizeCap> </rollingPolicy> <encoder> <pattern> %date %level [%thread] %-5level %logger{36} [%file:%line] - %msg%n </pattern> </encoder> </appender> <root level= \"info\" > <appender-ref ref= \"console\" /> <appender-ref ref= \"file\" /> <appender-ref ref= \"ROLLBAR\" /> </root> <shutdownHook class= \"ch.qos.logback.core.hook.DelayingShutdownHook\" /> </configuration> The access token can be copied from the the settings of the Rollbar project. Test integration with Rollbar Write a unit test and run to see the integration status. org . slf4j . Logger logger = LoggerFactory . getLogger ( Test . class ); try { throw new IllegalArgumentException ( \"This is a test for Rollbar.\" ); } catch ( IllegalArgumentException e ) { logger . error ( \"error\" , e ); } Check dashboard status Wait on the Integrate a Notifier step page or click the Dashboard link on the top bar. You will see the new error coming after the unit test is executed. Until now we've integrated exceptions alert into the Rollbar, the next step will be integrated Rollbar with Slack. Integrate Rollbar notification with Slack Go to the Settings of the Rollbar project and click the Notifications menuitem. Find the Slack app in the available channels Add Rollbar app in Slack Go to your Slack workspace and add Rollbar app. Enable Slack integration Click the Slack app in the available channels and select your access token and enable the Slack integration. Slack channel selection Select the channel you will notify exceptions in your Slack workspace. The dropdown here will list all the channels in your Slack workspace. Configure Slack app rules You can configure the rules of the Slack notifications as your need. For example, I add the every occurrence rule here in order to notify every error to the Slack. Test integration with Slack Run the unit test again to see the integration status with Slack. Go into the channel you configured in Rollbar and you will see the coming error notification. Slack channel settings Remember to join the channel in order to get notified. Then configure the notification preferences to include mobile. You can install the Slack app in your mobile and login your workspace. Run the unit test again and you will see notifications on your mobile as soon as exceptions happen.","title":"Introduce Rollbar and Slack for realtime exception alerts"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#connect-rollbar-with-github","text":"Log in Rollbar with the \"Log in with GitHub\" button, and enables the GitHub integration settings for all your projects. Get started by going to your account settings. Navigate to the \"Connected Accounts\" and Connect with GitHub.","title":"Connect Rollbar with Github"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#create-a-project","text":"Click the \"create new project\" on the top dropdown list in Rollbar. Create the project from a Github repo directly or specify the new project information to create.","title":"Create a project"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#integrate-a-notifier","text":"Select the platform your project is based on. Here I use Java and continue.","title":"Integrate a notifier"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#wait-the-data","text":"Now we can see the tutorial for your platform and the status for it is waiting.","title":"Wait the data"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#integrate-source-control","text":"Click the 3rd step to connect source control and select Github, then input the information for your project.","title":"Integrate source control"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#project-integration","text":"Follow the tutorial on the 1st step page. Add the Rollbar related maven dependencies into your project. Here I add logback dependency into it as well because I'll use logback to send exceptions to Rollbar. <!-- Rollbar --> <dependency> <groupId> com.rollbar </groupId> <version> [1.0,) </version> <artifactId> rollbar-java </artifactId> </dependency> <dependency> <groupId> com.rollbar </groupId> <artifactId> rollbar-logback </artifactId> <version> 1.3.1 </version> </dependency>","title":"Project integration"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#logback-configuration","text":"Here is the configuration of logback file. Please fill in the access token of your Rollbar into the appender and specify your environment name. Use filter in the appender is because we want to log the exception stack into both the file and Rollbar. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <configuration scan= \"true\" scanPeriod= \"60 seconds\" debug= \"false\" > <contextName> logback </contextName> <appender name= \"ROLLBAR\" class= \"com.rollbar.logback.RollbarAppender\" > <accessToken> ec6e37c277c940dcb5d4bcf879fa425c </accessToken> <environment> Dev </environment> <filter class= \"ch.qos.logback.classic.filter.ThresholdFilter\" > <level> warn </level> </filter> </appender> <appender name= \"console\" class= \"ch.qos.logback.core.ConsoleAppender\" > <encoder> <pattern> %date %level [%thread] %-5level %logger{36} [%file:%line] - %msg%n </pattern> </encoder> </appender> <appender name= \"file\" class= \"ch.qos.logback.core.rolling.RollingFileAppender\" > <rollingPolicy class= \"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\" > <fileNamePattern> logs/agriculture.%d{yyyy-MM-dd}.log </fileNamePattern> <maxHistory> 1 </maxHistory> <totalSizeCap> 1GB </totalSizeCap> </rollingPolicy> <encoder> <pattern> %date %level [%thread] %-5level %logger{36} [%file:%line] - %msg%n </pattern> </encoder> </appender> <root level= \"info\" > <appender-ref ref= \"console\" /> <appender-ref ref= \"file\" /> <appender-ref ref= \"ROLLBAR\" /> </root> <shutdownHook class= \"ch.qos.logback.core.hook.DelayingShutdownHook\" /> </configuration> The access token can be copied from the the settings of the Rollbar project.","title":"Logback configuration"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#test-integration-with-rollbar","text":"Write a unit test and run to see the integration status. org . slf4j . Logger logger = LoggerFactory . getLogger ( Test . class ); try { throw new IllegalArgumentException ( \"This is a test for Rollbar.\" ); } catch ( IllegalArgumentException e ) { logger . error ( \"error\" , e ); }","title":"Test integration with Rollbar"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#check-dashboard-status","text":"Wait on the Integrate a Notifier step page or click the Dashboard link on the top bar. You will see the new error coming after the unit test is executed. Until now we've integrated exceptions alert into the Rollbar, the next step will be integrated Rollbar with Slack.","title":"Check dashboard status"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#integrate-rollbar-notification-with-slack","text":"Go to the Settings of the Rollbar project and click the Notifications menuitem. Find the Slack app in the available channels","title":"Integrate Rollbar notification with Slack"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#add-rollbar-app-in-slack","text":"Go to your Slack workspace and add Rollbar app.","title":"Add Rollbar app in Slack"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#enable-slack-integration","text":"Click the Slack app in the available channels and select your access token and enable the Slack integration.","title":"Enable Slack integration"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#slack-channel-selection","text":"Select the channel you will notify exceptions in your Slack workspace. The dropdown here will list all the channels in your Slack workspace.","title":"Slack channel selection"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#configure-slack-app-rules","text":"You can configure the rules of the Slack notifications as your need. For example, I add the every occurrence rule here in order to notify every error to the Slack.","title":"Configure Slack app rules"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#test-integration-with-slack","text":"Run the unit test again to see the integration status with Slack. Go into the channel you configured in Rollbar and you will see the coming error notification.","title":"Test integration with Slack"},{"location":"bestpractice/introduce-rollbar-and-slack-for-realtime-exception-alerts/#slack-channel-settings","text":"Remember to join the channel in order to get notified. Then configure the notification preferences to include mobile. You can install the Slack app in your mobile and login your workspace. Run the unit test again and you will see notifications on your mobile as soon as exceptions happen.","title":"Slack channel settings"},{"location":"bestpractice/keycloak-traefik-k8s/","text":"A DevOps team may be accessing multiple applications and tools in a single product environment in support of their DevOps processes such as CI/CD server, Centralized log, Kubernetes dashboard, Monitoring software, Artifact repositories, Admin tools, etc. All of these tools will require authentication mechanisms for security purposes, and for a user to maintain and remember their authentication credentials on so many softwares can quickly become cumbersome. And in the event of lost credentials, it can be a tedious process for both user and admins to recover the required credentials. Instead of having individual authentication on various tools, a more effective strategy is to use single sign-on for all tools, i.e. a centralized authentication mechanism that can allow or reject access to a set of tools based on a single set of credentials per user. Additionally some tools may not have authentication built into them at all, and may be reliant on an external authentication server in any case. An external authentication server with single sign-on capability can therefore prove to be the way to go in such a situation. Single Sign-On Single Sign-On (SSO) allows users to log in using a single set of credentials, e.g. username and password, so they can easily access a set of applications. SSO. SSO saves time and energy for users because they do not have to repeatedly log into multiple applications. This provides a smooth user experience, and makes it less likely to have access problems because of lost or forgotten credentials, locked out accounts, etc. Keycloak Keycloak is an Open Source Identity and Access Management solution. It provides an easy way to add authentication including Single Sign-on to applications and services with minimum effort. Keycloak handles persistence and user authentication all out of the box. Instead of having to login to individual applications, users authenticate with Keycloak rather than individual applications. This means that the individual applications don't have to implement their own login forms, authentication, and storage of users and sessions. Once logged-in to Keycloak, users don't have to login again to access a different application. And similarly once logged-out from Keycloak, users don't have to log out of individual applications. Enabling login with social networks is also easy. The configuration for these can be added via Keycloak's admin console. No code or changes are required to individual application Keycloak supports OpenID Connect and SAML protocols. OpenID Connect (OIDC) is an extension of the OAuth 2 authentication protocol. While OAuth 2.0 is a framework for building authorization protocols, and OIDC is the full implementation of a authentication and authorization protocol. SAML 2.0 is similar to OIDC but a lot older and consequently more mature. It has its roots in SOAP and works by exchanging XML documents between the authentication server and the application, so it tends to be a bit more verbose than OIDC. In most cases OIDC is recommended by Keycloak. Keycloak Gatekeeper Keycloak Gatekeeper is an adapter which integrates with the Keycloak authentication service. We deploy it on a per-application instance basis. So usually this will be a sidecar container deployed with the application container on the kubernetes pod. We configure the kubernetes service of the application so that it points to the gatekeeper rather than the application itself, so that the gatekeeper can act as a proxy for incoming requests. The gatekeeper then verifies from the Keycloak server if an active authenticated session exists or not. If not, it redirects the client to the Keycloak login page. If the session exists, it allows the incoming request to pass through to the application container. Using the Keycloak Gatekeeper allows us to have zero authentication configuration within the application itself. The session verification, redirection to Keycloak in case of an invalid session, and pass through to the application in case of a valid session, are all handled by the gatekeeper. Stakater Proxy Injector Deploying a sidecar container for Keycloak Gatekeeper with all our applications can be a hassle. So we want to automatically inject a keycloak gatekeeper container in a pod, for any deployment that requires to connect to keycloak, instead of manually adding a sidecar container with each deployment. This Proxy Injector controller will continuously watch deployments in specific or all namespaces, and automatically add a sidecar container for keycloak gatekeeper. Configuration for the keycloak gatekeeper is done through annotations of the respective deployment or with ConfigMap of the ProxyInjector. Steps in Kubernetes cluster with Traefik Keycloak chart Install Keycloak chart by helm helm repo add codecentric https://codecentric.github.io/helm-charts helm install --name keycloak codecentric/keycloak # helm list # helm delete <name> (delete the chart) Remember the username and password from the result. Traefik ingress Create the keycloak ingress yaml to expose the keycloak web, and specify the sub-domain for it apiVersion : extensions/v1beta1 kind : Ingress metadata : name : keycloak-ingress namespace : jx spec : rules : - host : <sub-domain> http : paths : - path : / backend : serviceName : keycloak-http servicePort : 80 Open the exposed url Enter the administration console and use the previous username and password to login. Create a user and specify the username and reset the password to set the user password to the new one you specified. Create a client which is the application you want to inject authentication in front of. Modify the access type to the confidential and save. Create a client scope. Click the Mappers and create a mapper with the Audience type. Enter the new client and click the Client Scopes, move the available new scope to selected. You can add a realm other than Master Realm at any time.","title":"Play around with Keycloak in k8s"},{"location":"bestpractice/keycloak-traefik-k8s/#single-sign-on","text":"Single Sign-On (SSO) allows users to log in using a single set of credentials, e.g. username and password, so they can easily access a set of applications. SSO. SSO saves time and energy for users because they do not have to repeatedly log into multiple applications. This provides a smooth user experience, and makes it less likely to have access problems because of lost or forgotten credentials, locked out accounts, etc.","title":"Single Sign-On"},{"location":"bestpractice/keycloak-traefik-k8s/#keycloak","text":"Keycloak is an Open Source Identity and Access Management solution. It provides an easy way to add authentication including Single Sign-on to applications and services with minimum effort. Keycloak handles persistence and user authentication all out of the box. Instead of having to login to individual applications, users authenticate with Keycloak rather than individual applications. This means that the individual applications don't have to implement their own login forms, authentication, and storage of users and sessions. Once logged-in to Keycloak, users don't have to login again to access a different application. And similarly once logged-out from Keycloak, users don't have to log out of individual applications. Enabling login with social networks is also easy. The configuration for these can be added via Keycloak's admin console. No code or changes are required to individual application Keycloak supports OpenID Connect and SAML protocols. OpenID Connect (OIDC) is an extension of the OAuth 2 authentication protocol. While OAuth 2.0 is a framework for building authorization protocols, and OIDC is the full implementation of a authentication and authorization protocol. SAML 2.0 is similar to OIDC but a lot older and consequently more mature. It has its roots in SOAP and works by exchanging XML documents between the authentication server and the application, so it tends to be a bit more verbose than OIDC. In most cases OIDC is recommended by Keycloak.","title":"Keycloak"},{"location":"bestpractice/keycloak-traefik-k8s/#keycloak-gatekeeper","text":"Keycloak Gatekeeper is an adapter which integrates with the Keycloak authentication service. We deploy it on a per-application instance basis. So usually this will be a sidecar container deployed with the application container on the kubernetes pod. We configure the kubernetes service of the application so that it points to the gatekeeper rather than the application itself, so that the gatekeeper can act as a proxy for incoming requests. The gatekeeper then verifies from the Keycloak server if an active authenticated session exists or not. If not, it redirects the client to the Keycloak login page. If the session exists, it allows the incoming request to pass through to the application container. Using the Keycloak Gatekeeper allows us to have zero authentication configuration within the application itself. The session verification, redirection to Keycloak in case of an invalid session, and pass through to the application in case of a valid session, are all handled by the gatekeeper.","title":"Keycloak Gatekeeper"},{"location":"bestpractice/keycloak-traefik-k8s/#stakater-proxy-injector","text":"Deploying a sidecar container for Keycloak Gatekeeper with all our applications can be a hassle. So we want to automatically inject a keycloak gatekeeper container in a pod, for any deployment that requires to connect to keycloak, instead of manually adding a sidecar container with each deployment. This Proxy Injector controller will continuously watch deployments in specific or all namespaces, and automatically add a sidecar container for keycloak gatekeeper. Configuration for the keycloak gatekeeper is done through annotations of the respective deployment or with ConfigMap of the ProxyInjector.","title":"Stakater Proxy Injector"},{"location":"bestpractice/keycloak-traefik-k8s/#steps-in-kubernetes-cluster-with-traefik","text":"","title":"Steps in Kubernetes cluster with Traefik"},{"location":"bestpractice/keycloak-traefik-k8s/#keycloak-chart","text":"Install Keycloak chart by helm helm repo add codecentric https://codecentric.github.io/helm-charts helm install --name keycloak codecentric/keycloak # helm list # helm delete <name> (delete the chart) Remember the username and password from the result.","title":"Keycloak chart"},{"location":"bestpractice/keycloak-traefik-k8s/#traefik-ingress","text":"Create the keycloak ingress yaml to expose the keycloak web, and specify the sub-domain for it apiVersion : extensions/v1beta1 kind : Ingress metadata : name : keycloak-ingress namespace : jx spec : rules : - host : <sub-domain> http : paths : - path : / backend : serviceName : keycloak-http servicePort : 80 Open the exposed url Enter the administration console and use the previous username and password to login. Create a user and specify the username and reset the password to set the user password to the new one you specified. Create a client which is the application you want to inject authentication in front of. Modify the access type to the confidential and save. Create a client scope. Click the Mappers and create a mapper with the Audience type. Enter the new client and click the Client Scopes, move the available new scope to selected. You can add a realm other than Master Realm at any time.","title":"Traefik ingress"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/","text":"GeoServer is an open source server for sharing geospatial data. Designed for interoperability, it publishes data from any major spatial data source using open standards. Steps to handle raster data Download Download GeoServer and install, or create by a docker container Login Login the GeoServer by admin user, the default username/password is admin/geoserver. Create a raster workspace Select a store datasource Here we select GeoTIFF Create a raster store Here we specify a *.tif file Create a layer Create the layer under new created store and the format is : , and then publish it Publish review Have a review of all the information it reads including the band definitions, and save it Layer preview Go the the layer preview and find the layer, and try to view it by OpenLayers Layer preview result The geotiff file successfully being processed if we can see the layer Compressed raster layer with only grey band The geotiff file failed being processed for unknown reason Exception stack trace 1 Caused by: java.lang.NullPointerException at javax.media.jai.PlanarImage.getData(PlanarImage.java:2110) ...... <a href=\"#exception\" style=\"font-weight:bold\">View the full exception stack trace<sup>1</sup></a> Exception stack trace 2 Caused by: javax.imageio.IIOException: Illegal value for Predictor in TIFF file at it.geosolutions.imageioimpl.plugins.tiff.TIFFLZWDecompressor.<init>(TIFFLZWDecompressor.java:118) at it.geosolutions.imageioimpl.plugins.tiff.TIFFImageReader.read(TIFFImageReader.java:1856) at com.sun.media.jai.imageioimpl.ImageReadOpImage.computeTile(ImageReadOpImage.java:697) ... 166 more QGIS layer preview Drag the geotiff file into the QGIS for preview QGIS geotiff layer export Display the current layer, Select the menu item \"Layer-Save as...\" and export the geotiff with 4326 crs GeoServer layer preview Modify the store in GeoServer to connect to the new geotiff file, and preview the layer again. It works with no color scheme Cause analysis The error raster geotiff only has one grey band, and the QGIS exported geotiff file is nearly twice the size of the original one. It is a compressed one, and that's why QGIS produces a bigger size when we save it as another. QGIS does not compress it, hence the new image is bigger. GeoServer doesn't accept compressed geotiff data. Regarding the GeoServer color problem, It's because that the style in GeoServer is not well defined. Define style in GeoServer Create style in QGIS Open QGIS, drag the geotiff file into the QGIS. Right click on the data layer and select 'Properties', then select 'Style' on the left side. Change the render type to 'Singleband pseudocolor' and change the style by specifying the color ranges. Export style in QGIS Apply the change to see the new layer. Save the style using the 'Save Style' button on the bottom and save as .qml file. Copy the .qml content Open the .qml file with notepad and review the colorrampshader part. Generate the style template in GeoServer Go to the GeoServer admin page and click on 'Styles' and add a new style. Name the style and select the workspace, then choose 'Copy from existing style', select 'dem' and press 'copy...' Specify the style content Change the name, title and abstract. Translate the .qml content into the GeoServer style content here. Notice the 'value'/'label'/'color' values in .qml match the 'quantity'/'label'/'color' in GeoServer. If the opacity is 0.0, it means that the color will not be visible, so it will be white. Press 'Validate' to check if it works. If there are no errors, then 'submit'. Generate .sld in QGIS Comparing with exporting the .qml style in QGIS, we can directly generate .sld in QGIS and copy the content to create a style in GeoServer. Create style in Geoserver from .sld file From the .sld file we exported from QGIS, we can easily create a style in GeoServer. Edit layer basic info Go to 'Layers' and select the layer we just created. Make sure 'Enabled' and 'Advertised' are turned on and check if the 'Coverage Band Details' are set correctly, if not adjust them. Edit WMS Settings Select the 'Publishing' tab. With the 'WMS Settings' select 'Default Style' and change it to the style we just created. 'Save' the layer again. Preview layer View the layer again with the 'Layer preview' and 'Open Layers'. Now the layer should be displayed correctly. Preview layer when editing style We could also edit the style and preview the result as soon as we apply in the style editing page. Add additional styles Edit the layer again and with the 'WMS Settings' select additional styles and save. Remember to add the newly added style into it as well otherwise the restful api cannot list this style info under the layer. Preview layer with additional styles Preview the layer again and we could switch the style to any available one and see the result. Enable CORS for GeoServer Clone repository Clone the github repository docker-geoserver . Create web.xml The contents of resources/overlays will be copied to the image file system during the build. For example, to include a static web xml with CORS support web.xml , create the file at resources/overlays/usr/local/tomcat/conf/web.xml . Enable CORS Add CORS enabled content into the web.xml as bellow. The full content of the web.xml can be found here . <filter> <filter-name> CorsFilter </filter-name> <filter-class> org.apache.catalina.filters.CorsFilter </filter-class> <init-param> <param-name> cors.allowed.origins </param-name> <param-value> * </param-value> </init-param> <init-param> <param-name> cors.allowed.methods </param-name> <param-value> GET,POST,HEAD,OPTIONS,PUT </param-value> </init-param> <init-param> <param-name> cors.allowed.headers </param-name> <param-value> Content-Type,X-Requested-With,accept,Origin,Access-Control-Request-Method,Access-Control-Request-Headers </param-value> </init-param> <init-param> <param-name> cors.exposed.headers </param-name> <param-value> Access-Control-Allow-Origin,Access-Control-Allow-Credentials </param-value> </init-param> <init-param> <param-name> cors.preflight.maxage </param-name> <param-value> 10 </param-value> </init-param> </filter> <filter-mapping> <filter-name> CorsFilter </filter-name> <url-pattern> /* </url-pattern> </filter-mapping> Docker hub modification Modify the build.sh script to own hub repository. Build and push Build the docker image and push to own docker hub. Now the CORS enabled GeoServer docker image is ready to use. ./build.sh docker pull hustakin/geoserver Tomcat error log Sometimes the GeoServer container will met 404 issue. That's because the tomcat failed to start because of your modification. We could attach to the GeoServer container and inspect the tomcat error log to find the reason. Client http Please be noted the client HTTP should not use the credentials for CORS requests. For example, here I get feature information for raster data in angular6 client by clicking on the layer. Renderer the raster layer in the web Leaflet layer using WMS let wmsLayer = L . tileLayer . wms ( 'http://localhost:9999/geoserver/raster/wms?' , { layers : 'raster:demo' , version : '1.1.1' , styles : '' , //Use the default style, we can also specify additional styles format : 'image/png' , transparent : true , maxZoom : 25 , tiled : true }); let map = L . map ( 'map' , { zoom : 0 , maxZoom : 25 , maxNativeZoom : 18 , layers : [ wmsLayer ], }); Leaflet layer using WMTS Please be noted that we should use EPSG:900913 other than EPSG:4326 here which for historical reasons is what GeoServer calls Web Mercator. let wmtsLayer = new L . TileLayer . WMTS ( 'http://localhost:9999/geoserver/gwc/service/wmts' , { layer : 'raster:demo' , style : \"\" , tilematrixSet : \"EPSG:900913\" , //Important!! It should be EPSG:900913 other than EPSG:4326 format : \"image/png\" , maxZoom : 25 , attribution : \"<a href='https://github.com/mylen/leaflet.TileLayer.WMTS'>GitHub</a>&copy; <a href='http://www.ign.fr'>IGN</a>\" }); let map = L . map ( 'map' , { zoom : 0 , maxZoom : 25 , maxNativeZoom : 18 , layers : [ wmtsLayer ], }); OpenLayers layer using WMTS let gridNames = [ 'EPSG:4326:0' , 'EPSG:4326:1' , 'EPSG:4326:2' , 'EPSG:4326:3' , 'EPSG:4326:4' , 'EPSG:4326:5' , 'EPSG:4326:6' , 'EPSG:4326:7' , 'EPSG:4326:8' , 'EPSG:4326:9' , 'EPSG:4326:10' , 'EPSG:4326:11' , 'EPSG:4326:12' , 'EPSG:4326:13' , 'EPSG:4326:14' , 'EPSG:4326:15' , 'EPSG:4326:16' , 'EPSG:4326:17' , 'EPSG:4326:18' , 'EPSG:4326:19' , 'EPSG:4326:20' , 'EPSG:4326:21' ]; let baseParams = [ 'VERSION' , 'LAYER' , 'STYLE' , 'TILEMATRIX' , 'TILEMATRIXSET' , 'SERVICE' , 'FORMAT' ]; let params = { VERSION : '1.0.0' , LAYER : 'raster:demo' , STYLE : '' , //Use the default style, we can also specify additional styles TILEMATRIX : gridNames , TILEMATRIXSET : 'EPSG:4326' , SERVICE : 'WMTS' , FORMAT : 'image/png' }; let projection = new Projection ({ code : 'EPSG:4326' , units : 'degrees' , axisOrientation : 'neu' });, let resolutions = [ 0.703125 , 0.3515625 , 0.17578125 , 0.087890625 , 0.0439453125 , 0.02197265625 , 0.010986328125 , 0.0054931640625 , 0.00274658203125 , 0.001373291015625 , 6.866455078125 E - 4 , 3.4332275390625 E - 4 , 1.71661376953125 E - 4 , 8.58306884765625 E - 5 , 4.291534423828125 E - 5 , 2.1457672119140625 E - 5 , 1.0728836059570312 E - 5 , 5.364418029785156 E - 6 , 2.682209014892578 E - 6 , 1.341104507446289 E - 6 , 6.705522537231445 E - 7 , 3.3527612686157227 E - 7 ]; let url = 'http://localhost:9999/geoserver/gwc/service/wmts?' ; for ( const param in params ) { if ( baseParams . indexOf ( param . toUpperCase ()) < 0 ) { url = url + param + '=' + params [ param ] + '&' ; } } url = url . slice ( 0 , - 1 ); const source = new WMTS ({ url , layer : params.LAYER , matrixSet : params.TILEMATRIXSET , format : params.FORMAT , projection : projection , tileGrid : new WMTSTileGrid ({ tileSize : [ 256 , 256 ], extent : [ - 180.0 , - 90.0 , 180.0 , 90.0 ], origin : [ - 180.0 , 90.0 ], resolutions : resolutions , matrixIds : params.TILEMATRIX }), style : params.STYLE , wrapX : true }); let wmsLayer = new TileLayer ({ source : source }); let view = new View ({ center : [ 0 , 0 ], zoom : 2 , projection : projection ;, extent : [ - 180.0 , - 90.0 , 180.0 , 90.0 ] }); let map = new Map ({ controls : [ new MousePosition (), new Zoom (), ], layers : [ wmsLayer ], target : 'map' , view : wmsVioew }); //Get layer feature information by clicking on the layer map . on ( 'singleclick' , evt => { document . getElementById ( 'info' ). innerHTML = '' ; const source = source ; const resolution = view . getResolution (); const tilegrid = source . getTileGrid (); const tileResolutions = tilegrid . getResolutions (); let zoomIdx , diff = Infinity ; for ( let i = 0 ; i < tileResolutions . length ; i ++ ) { const tileResolution = tileResolutions [ i ]; const diffP = Math . abs ( resolution - tileResolution ); if ( diffP < diff ) { diff = diffP ; zoomIdx = i ; } if ( tileResolution < resolution ) { break ; } } const tileSize = tilegrid . getTileSize ( zoomIdx ); const tileOrigin = tilegrid . getOrigin ( zoomIdx ); const fx = ( evt . coordinate [ 0 ] - tileOrigin [ 0 ]) / ( resolution * tileSize [ 0 ]); const fy = ( tileOrigin [ 1 ] - evt . coordinate [ 1 ]) / ( resolution * tileSize [ 1 ]); const tileCol = Math . floor ( fx ); const tileRow = Math . floor ( fy ); const tileI = Math . floor (( fx - tileCol ) * tileSize [ 0 ]); const tileJ = Math . floor (( fy - tileRow ) * tileSize [ 1 ]); const matrixIds = tilegrid . getMatrixIds ()[ zoomIdx ]; let url = url ; for ( const param in params ) { if ( param . toUpperCase () === 'TILEMATRIX' ) { url = url + 'TILEMATRIX=' + matrixIds + '&' ; } else { url = url + param + '=' + params [ param ] + '&' ; } } url = url + 'SERVICE=WMTS&REQUEST=GetFeatureInfo' + '&INFOFORMAT=' + 'text/html' + '&TileCol=' + tileCol + '&TileRow=' + tileRow + '&I=' + tileI + '&J=' + tileJ ; if ( url ) { document . getElementById ( 'info' ). innerHTML = 'Loading... please wait...' ; this . http . get < any > ( url , { // withCredentials: true, responseType : 'text' as 'json' , headers : new HttpHeaders ({ 'Accept' : '*/*' , 'Content-Type' : 'text/html' }), }) . subscribe (( res ) => { document . getElementById ( 'info' ). innerHTML = res ; }, () => { document . getElementById ( 'info' ). innerHTML = '' ; }); } }); Footnotes NullPointerException stack trace from GeoServer console 09 Sep 17:11:56 INFO [geoserver.wms] - Request: getServiceInfo Sep 09, 2019 5:11:56 PM org.geoserver.GeoserverInitStartupListener$1 errorOccurred INFO: Problem occurs when computing a tile by the owner. java.lang.RuntimeException: javax.imageio.IIOException: Illegal value for Predictor in TIFF file at com.sun.media.jai.imageioimpl.ImageReadOpImage.computeTile(ImageReadOpImage.java:706) at com.sun.media.jai.util.SunTileScheduler.scheduleTile(SunTileScheduler.java:904) at javax.media.jai.OpImage.getTile(OpImage.java:1129) at javax.media.jai.PlanarImage.getData(PlanarImage.java:2085) at javax.media.jai.PlanarImage.getExtendedData(PlanarImage.java:2440) at javax.media.jai.ScaleOpImage.computeTile(ScaleOpImage.java:1255) at com.sun.media.jai.util.SunTileScheduler.scheduleTile(SunTileScheduler.java:904) at javax.media.jai.OpImage.getTile(OpImage.java:1129) at javax.media.jai.PlanarImage.getData(PlanarImage.java:2085) at javax.media.jai.StatisticsOpImage.getProperty(StatisticsOpImage.java:292) at com.sun.media.jai.opimage.ExtremaOpImage.getProperty(ExtremaOpImage.java:100) at javax.media.jai.RenderedOp$1.getProperty(RenderedOp.java:1808) at javax.media.jai.PropertyEnvironment.getProperty(PropertyEnvironment.java:197) at javax.media.jai.PropertySourceImpl.getProperty(PropertySourceImpl.java:277) at javax.media.jai.WritablePropertySourceImpl.getProperty(WritablePropertySourceImpl.java:130) at javax.media.jai.RenderedOp.getProperty(RenderedOp.java:1982) at org.geotools.image.ImageWorker.getComputedProperty(ImageWorker.java:1033) at org.geotools.image.ImageWorker.getExtremas(ImageWorker.java:1089) at org.geotools.image.ImageWorker.rescaleToBytes(ImageWorker.java:1400) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:139) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:53) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter$1.execute(StyleVisitorCoverageProcessingNodeAdapter.java:97) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.checkExecuted(BaseCoverageProcessingNode.java:234) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:332) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:52) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter.getOutput(StyleVisitorCoverageProcessingNodeAdapter.java:130) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.symbolize(GridCoverageRenderer.java:484) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:1021) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:831) at org.geoserver.wms.map.RenderedImageMapOutputFormat.directRasterRender(RenderedImageMapOutputFormat.java:1036) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:349) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:265) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:132) at org.geoserver.wms.GetMap.executeInternal(GetMap.java:720) at org.geoserver.wms.GetMap.run(GetMap.java:300) at org.geoserver.wms.GetMap.run(GetMap.java:123) at org.geoserver.wms.DefaultWebMapService.getMap(DefaultWebMapService.java:251) at sun.reflect.GeneratedMethodAccessor296.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:333) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.geoserver.kml.WebMapServiceKmlInterceptor.invoke(WebMapServiceKmlInterceptor.java:38) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:59) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:33) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:72) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.ows.util.RequestObjectLogger.invoke(RequestObjectLogger.java:50) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:213) at com.sun.proxy.$Proxy96.getMap(Unknown Source) at sun.reflect.GeneratedMethodAccessor254.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.geoserver.ows.Dispatcher.execute(Dispatcher.java:877) at org.geoserver.ows.Dispatcher.handleRequestInternal(Dispatcher.java:264) at org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:174) at org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter.handle(SimpleControllerHandlerAdapter.java:50) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) at javax.servlet.http.HttpServlet.service(HttpServlet.java:687) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:808) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1669) at org.geoserver.filters.ThreadLocalsCleanupFilter.doFilter(ThreadLocalsCleanupFilter.java:26) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:69) at org.geoserver.wms.animate.AnimatorFilter.doFilter(AnimatorFilter.java:73) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:66) at org.geoserver.filters.SpringDelegatingFilter.doFilter(SpringDelegatingFilter.java:41) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.platform.AdvancedDispatchFilter.doFilter(AdvancedDispatchFilter.java:37) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerAnonymousAuthenticationFilter.doFilter(GeoServerAnonymousAuthenticationFilter.java:51) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:158) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.geoserver.security.filter.GeoServerBasicAuthenticationFilter.doFilter(GeoServerBasicAuthenticationFilter.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.geoserver.security.filter.GeoServerSecurityContextPersistenceFilter$1.doFilter(GeoServerSecurityContextPersistenceFilter.java:52) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) at org.geoserver.security.GeoServerSecurityFilterChainProxy.doFilter(GeoServerSecurityFilterChainProxy.java:141) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.LoggingFilter.doFilter(LoggingFilter.java:90) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:79) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.GZIPFilter.doFilter(GZIPFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SessionDebugFilter.doFilter(SessionDebugFilter.java:46) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.FlushSafeFilter.doFilter(FlushSafeFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:256) at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:219) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:215) at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) at org.eclipse.jetty.server.Server.handle(Server.java:499) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) at java.lang.Thread.run(Thread.java:748) Caused by: javax.imageio.IIOException: Illegal value for Predictor in TIFF file at it.geosolutions.imageioimpl.plugins.tiff.TIFFLZWDecompressor. (TIFFLZWDecompressor.java:118) at it.geosolutions.imageioimpl.plugins.tiff.TIFFImageReader.read(TIFFImageReader.java:1856) at com.sun.media.jai.imageioimpl.ImageReadOpImage.computeTile(ImageReadOpImage.java:697) ... 147 more Sep 09, 2019 5:11:56 PM org.geoserver.GeoserverInitStartupListener$1 errorOccurred INFO: Problem occurs when computing a tile by the owner. java.lang.NullPointerException at javax.media.jai.PlanarImage.getData(PlanarImage.java:2110) at javax.media.jai.PlanarImage.getExtendedData(PlanarImage.java:2440) at javax.media.jai.ScaleOpImage.computeTile(ScaleOpImage.java:1255) at com.sun.media.jai.util.SunTileScheduler.scheduleTile(SunTileScheduler.java:904) at javax.media.jai.OpImage.getTile(OpImage.java:1129) at javax.media.jai.PlanarImage.getData(PlanarImage.java:2085) at javax.media.jai.StatisticsOpImage.getProperty(StatisticsOpImage.java:292) at com.sun.media.jai.opimage.ExtremaOpImage.getProperty(ExtremaOpImage.java:100) at javax.media.jai.RenderedOp$1.getProperty(RenderedOp.java:1808) at javax.media.jai.PropertyEnvironment.getProperty(PropertyEnvironment.java:197) at javax.media.jai.PropertySourceImpl.getProperty(PropertySourceImpl.java:277) at javax.media.jai.WritablePropertySourceImpl.getProperty(WritablePropertySourceImpl.java:130) at javax.media.jai.RenderedOp.getProperty(RenderedOp.java:1982) at org.geotools.image.ImageWorker.getComputedProperty(ImageWorker.java:1033) at org.geotools.image.ImageWorker.getExtremas(ImageWorker.java:1089) at org.geotools.image.ImageWorker.rescaleToBytes(ImageWorker.java:1400) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:139) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:53) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter$1.execute(StyleVisitorCoverageProcessingNodeAdapter.java:97) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.checkExecuted(BaseCoverageProcessingNode.java:234) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:332) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:52) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter.getOutput(StyleVisitorCoverageProcessingNodeAdapter.java:130) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.symbolize(GridCoverageRenderer.java:484) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:1021) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:831) at org.geoserver.wms.map.RenderedImageMapOutputFormat.directRasterRender(RenderedImageMapOutputFormat.java:1036) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:349) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:265) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:132) at org.geoserver.wms.GetMap.executeInternal(GetMap.java:720) at org.geoserver.wms.GetMap.run(GetMap.java:300) at org.geoserver.wms.GetMap.run(GetMap.java:123) at org.geoserver.wms.DefaultWebMapService.getMap(DefaultWebMapService.java:251) at sun.reflect.GeneratedMethodAccessor296.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:333) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.geoserver.kml.WebMapServiceKmlInterceptor.invoke(WebMapServiceKmlInterceptor.java:38) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:59) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:33) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:72) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.ows.util.RequestObjectLogger.invoke(RequestObjectLogger.java:50) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:213) at com.sun.proxy.$Proxy96.getMap(Unknown Source) at sun.reflect.GeneratedMethodAccessor254.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.geoserver.ows.Dispatcher.execute(Dispatcher.java:877) at org.geoserver.ows.Dispatcher.handleRequestInternal(Dispatcher.java:264) at org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:174) at org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter.handle(SimpleControllerHandlerAdapter.java:50) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) at javax.servlet.http.HttpServlet.service(HttpServlet.java:687) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:808) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1669) at org.geoserver.filters.ThreadLocalsCleanupFilter.doFilter(ThreadLocalsCleanupFilter.java:26) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:69) at org.geoserver.wms.animate.AnimatorFilter.doFilter(AnimatorFilter.java:73) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:66) at org.geoserver.filters.SpringDelegatingFilter.doFilter(SpringDelegatingFilter.java:41) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.platform.AdvancedDispatchFilter.doFilter(AdvancedDispatchFilter.java:37) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerAnonymousAuthenticationFilter.doFilter(GeoServerAnonymousAuthenticationFilter.java:51) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:158) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.geoserver.security.filter.GeoServerBasicAuthenticationFilter.doFilter(GeoServerBasicAuthenticationFilter.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.geoserver.security.filter.GeoServerSecurityContextPersistenceFilter$1.doFilter(GeoServerSecurityContextPersistenceFilter.java:52) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) at org.geoserver.security.GeoServerSecurityFilterChainProxy.doFilter(GeoServerSecurityFilterChainProxy.java:141) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.LoggingFilter.doFilter(LoggingFilter.java:90) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:79) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.GZIPFilter.doFilter(GZIPFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SessionDebugFilter.doFilter(SessionDebugFilter.java:46) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.FlushSafeFilter.doFilter(FlushSafeFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:256) at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:219) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:215) at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) at org.eclipse.jetty.server.Server.handle(Server.java:499) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) at java.lang.Thread.run(Thread.java:748) java.lang.NullPointerException at javax.media.jai.PlanarImage.getData(PlanarImage.java:2110) at javax.media.jai.StatisticsOpImage.getProperty(StatisticsOpImage.java:292) at com.sun.media.jai.opimage.ExtremaOpImage.getProperty(ExtremaOpImage.java:100) at javax.media.jai.RenderedOp$1.getProperty(RenderedOp.java:1808) at javax.media.jai.PropertyEnvironment.getProperty(PropertyEnvironment.java:197) at javax.media.jai.PropertySourceImpl.getProperty(PropertySourceImpl.java:277) at javax.media.jai.WritablePropertySourceImpl.getProperty(WritablePropertySourceImpl.java:130) at javax.media.jai.RenderedOp.getProperty(RenderedOp.java:1982) at org.geotools.image.ImageWorker.getComputedProperty(ImageWorker.java:1033) at org.geotools.image.ImageWorker.getExtremas(ImageWorker.java:1089) at org.geotools.image.ImageWorker.rescaleToBytes(ImageWorker.java:1400) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:139) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:53) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter$1.execute(StyleVisitorCoverageProcessingNodeAdapter.java:97) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.checkExecuted(BaseCoverageProcessingNode.java:234) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:332) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:52) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter.getOutput(StyleVisitorCoverageProcessingNodeAdapter.java:130) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.symbolize(GridCoverageRenderer.java:484) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:1021) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:831) at org.geoserver.wms.map.RenderedImageMapOutputFormat.directRasterRender(RenderedImageMapOutputFormat.java:1036) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:349) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:265) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:132) at org.geoserver.wms.GetMap.executeInternal(GetMap.java:720) at org.geoserver.wms.GetMap.run(GetMap.java:300) at org.geoserver.wms.GetMap.run(GetMap.java:123) at org.geoserver.wms.DefaultWebMapService.getMap(DefaultWebMapService.java:251) at sun.reflect.GeneratedMethodAccessor296.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:333) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.geoserver.kml.WebMapServiceKmlInterceptor.invoke(WebMapServiceKmlInterceptor.java:38) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:59) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:33) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:72) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.ows.util.RequestObjectLogger.invoke(RequestObjectLogger.java:50) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:213) at com.sun.proxy.$Proxy96.getMap(Unknown Source) at sun.reflect.GeneratedMethodAccessor254.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.geoserver.ows.Dispatcher.execute(Dispatcher.java:877) at org.geoserver.ows.Dispatcher.handleRequestInternal(Dispatcher.java:264) at org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:174) at org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter.handle(SimpleControllerHandlerAdapter.java:50) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) at javax.servlet.http.HttpServlet.service(HttpServlet.java:687) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:808) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1669) at org.geoserver.filters.ThreadLocalsCleanupFilter.doFilter(ThreadLocalsCleanupFilter.java:26) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:69) at org.geoserver.wms.animate.AnimatorFilter.doFilter(AnimatorFilter.java:73) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:66) at org.geoserver.filters.SpringDelegatingFilter.doFilter(SpringDelegatingFilter.java:41) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.platform.AdvancedDispatchFilter.doFilter(AdvancedDispatchFilter.java:37) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerAnonymousAuthenticationFilter.doFilter(GeoServerAnonymousAuthenticationFilter.java:51) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:158) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.geoserver.security.filter.GeoServerBasicAuthenticationFilter.doFilter(GeoServerBasicAuthenticationFilter.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.geoserver.security.filter.GeoServerSecurityContextPersistenceFilter$1.doFilter(GeoServerSecurityContextPersistenceFilter.java:52) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) at org.geoserver.security.GeoServerSecurityFilterChainProxy.doFilter(GeoServerSecurityFilterChainProxy.java:141) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.LoggingFilter.doFilter(LoggingFilter.java:90) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:79) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.GZIPFilter.doFilter(GZIPFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SessionDebugFilter.doFilter(SessionDebugFilter.java:46) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.FlushSafeFilter.doFilter(FlushSafeFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:256) at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:219) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:215) at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) at org.eclipse.jetty.server.Server.handle(Server.java:499) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) at java.lang.Thread.run(Thread.java:748) 09 Sep 17:11:56 ERROR [geoserver.ows] - org.geoserver.platform.ServiceException: Error rendering coverage on the fast path at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:351) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:265) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:132) at org.geoserver.wms.GetMap.executeInternal(GetMap.java:720) at org.geoserver.wms.GetMap.run(GetMap.java:300) at org.geoserver.wms.GetMap.run(GetMap.java:123) at org.geoserver.wms.DefaultWebMapService.getMap(DefaultWebMapService.java:251) at sun.reflect.GeneratedMethodAccessor296.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:333) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.geoserver.kml.WebMapServiceKmlInterceptor.invoke(WebMapServiceKmlInterceptor.java:38) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:59) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:33) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:72) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.ows.util.RequestObjectLogger.invoke(RequestObjectLogger.java:50) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:213) at com.sun.proxy.$Proxy96.getMap(Unknown Source) at sun.reflect.GeneratedMethodAccessor254.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.geoserver.ows.Dispatcher.execute(Dispatcher.java:877) at org.geoserver.ows.Dispatcher.handleRequestInternal(Dispatcher.java:264) at org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:174) at org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter.handle(SimpleControllerHandlerAdapter.java:50) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) at javax.servlet.http.HttpServlet.service(HttpServlet.java:687) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:808) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1669) at org.geoserver.filters.ThreadLocalsCleanupFilter.doFilter(ThreadLocalsCleanupFilter.java:26) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:69) at org.geoserver.wms.animate.AnimatorFilter.doFilter(AnimatorFilter.java:73) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:66) at org.geoserver.filters.SpringDelegatingFilter.doFilter(SpringDelegatingFilter.java:41) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.platform.AdvancedDispatchFilter.doFilter(AdvancedDispatchFilter.java:37) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerAnonymousAuthenticationFilter.doFilter(GeoServerAnonymousAuthenticationFilter.java:51) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:158) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.geoserver.security.filter.GeoServerBasicAuthenticationFilter.doFilter(GeoServerBasicAuthenticationFilter.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.geoserver.security.filter.GeoServerSecurityContextPersistenceFilter$1.doFilter(GeoServerSecurityContextPersistenceFilter.java:52) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) at org.geoserver.security.GeoServerSecurityFilterChainProxy.doFilter(GeoServerSecurityFilterChainProxy.java:141) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.LoggingFilter.doFilter(LoggingFilter.java:90) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:79) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.GZIPFilter.doFilter(GZIPFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SessionDebugFilter.doFilter(SessionDebugFilter.java:46) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.FlushSafeFilter.doFilter(FlushSafeFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:256) at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:219) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:215) at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) at org.eclipse.jetty.server.Server.handle(Server.java:499) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) at java.lang.Thread.run(Thread.java:748) Caused by: org.geoserver.platform.ServiceException: org.geotools.coverage.processing.CoverageProcessingException: java.lang.NullPointerException at org.geoserver.wms.map.RenderedImageMapOutputFormat.directRasterRender(RenderedImageMapOutputFormat.java:1200) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:349) ... 117 more Caused by: org.geotools.coverage.processing.CoverageProcessingException: java.lang.NullPointerException at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:333) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:52) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter.getOutput(StyleVisitorCoverageProcessingNodeAdapter.java:130) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.symbolize(GridCoverageRenderer.java:484) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:1021) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:831) at org.geoserver.wms.map.RenderedImageMapOutputFormat.directRasterRender(RenderedImageMapOutputFormat.java:1036) ... 118 more Caused by: java.lang.NullPointerException at javax.media.jai.PlanarImage.getData(PlanarImage.java:2110) at javax.media.jai.StatisticsOpImage.getProperty(StatisticsOpImage.java:292) at com.sun.media.jai.opimage.ExtremaOpImage.getProperty(ExtremaOpImage.java:100) at javax.media.jai.RenderedOp$1.getProperty(RenderedOp.java:1808) at javax.media.jai.PropertyEnvironment.getProperty(PropertyEnvironment.java:197) at javax.media.jai.PropertySourceImpl.getProperty(PropertySourceImpl.java:277) at javax.media.jai.WritablePropertySourceImpl.getProperty(WritablePropertySourceImpl.java:130) at javax.media.jai.RenderedOp.getProperty(RenderedOp.java:1982) at org.geotools.image.ImageWorker.getComputedProperty(ImageWorker.java:1033) at org.geotools.image.ImageWorker.getExtremas(ImageWorker.java:1089) at org.geotools.image.ImageWorker.rescaleToBytes(ImageWorker.java:1400) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:139) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:53) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter$1.execute(StyleVisitorCoverageProcessingNodeAdapter.java:97) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.checkExecuted(BaseCoverageProcessingNode.java:234) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:332) ... 124 more Illegal value exception from GeoServer console 24-Nov-2020 04:49:03.269 INFO [http-nio-8080-exec-7] org.geoserver.GeoserverInitStartupListener$1.errorOccurred Problem occurs when computing a tile by the owner. java.lang.RuntimeException: javax.imageio.IIOException: Illegal value for Predictor in TIFF file at com.sun.media.jai.imageioimpl.ImageReadOpImage.computeTile(ImageReadOpImage.java:706) at com.sun.media.jai.util.SunTileScheduler.scheduleTile(SunTileScheduler.java:904) at javax.media.jai.OpImage.getTile(OpImage.java:1129) at javax.media.jai.PlanarImage.cobbleFloat(PlanarImage.java:3254) at javax.media.jai.PlanarImage.getData(PlanarImage.java:2181) at it.geosolutions.jaiext.scale.ScaleOpImage.computeTile(ScaleOpImage.java:1651) at com.sun.media.jai.util.SunTileScheduler.scheduleTile(SunTileScheduler.java:904) at javax.media.jai.OpImage.getTile(OpImage.java:1129) at it.geosolutions.jaiext.stats.SimpleStatsOpImage.computeTile(SimpleStatsOpImage.java:95) at com.sun.media.jai.util.SunTileScheduler.scheduleTile(SunTileScheduler.java:904) at javax.media.jai.OpImage.getTile(OpImage.java:1129) at it.geosolutions.jaiext.stats.StatisticsOpImage.getProperty(StatisticsOpImage.java:333) at javax.media.jai.RenderedOp$1.getProperty(RenderedOp.java:1808) at javax.media.jai.PropertyEnvironment.getProperty(PropertyEnvironment.java:197) at javax.media.jai.PropertySourceImpl.getProperty(PropertySourceImpl.java:277) at javax.media.jai.WritablePropertySourceImpl.getProperty(WritablePropertySourceImpl.java:130) at javax.media.jai.RenderedOp.getProperty(RenderedOp.java:1982) at org.geotools.image.ImageWorker.getComputedProperty(ImageWorker.java:1078) at org.geotools.image.ImageWorker.getExtremas(ImageWorker.java:1111) at org.geotools.image.ImageWorker.rescaleToBytes(ImageWorker.java:1442) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:138) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:52) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter$1.execute(StyleVisitorCoverageProcessingNodeAdapter.java:96) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.checkExecuted(BaseCoverageProcessingNode.java:233) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:331) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:51) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter.getOutput(StyleVisitorCoverageProcessingNodeAdapter.java:129) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.symbolize(GridCoverageRenderer.java:482) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:1018) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:829) at org.geoserver.wms.map.RenderedImageMapOutputFormat.directRasterRender(RenderedImageMapOutputFormat.java:1058) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:353) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:269) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:132) at org.geoserver.wms.GetMap.executeInternal(GetMap.java:707) at org.geoserver.wms.GetMap.run(GetMap.java:287) at org.geoserver.wms.GetMap.run(GetMap.java:110) at org.geoserver.wms.DefaultWebMapService.getMap(DefaultWebMapService.java:251) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.geoserver.kml.WebMapServiceKmlInterceptor.invoke(WebMapServiceKmlInterceptor.java:38) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:55) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:31) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:72) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.geoserver.ows.util.RequestObjectLogger.invoke(RequestObjectLogger.java:50) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212) at com.sun.proxy.$Proxy46.getMap(Unknown Source) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.geoserver.ows.Dispatcher.execute(Dispatcher.java:877) at org.geoserver.ows.Dispatcher.handleRequestInternal(Dispatcher.java:264) at org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:177) at org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter.handle(SimpleControllerHandlerAdapter.java:52) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:998) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:890) at javax.servlet.http.HttpServlet.service(HttpServlet.java:634) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:875) at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.filters.CorsFilter.handleNonCORS(CorsFilter.java:430) at org.apache.catalina.filters.CorsFilter.doFilter(CorsFilter.java:169) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.filters.ThreadLocalsCleanupFilter.doFilter(ThreadLocalsCleanupFilter.java:26) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:69) at org.geoserver.flow.controller.IpBlacklistFilter.doFilter(IpBlacklistFilter.java:89) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:66) at org.geoserver.flow.ControlFlowCallback.doFilter(ControlFlowCallback.java:260) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:66) at org.geoserver.wms.animate.AnimatorFilter.doFilter(AnimatorFilter.java:73) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:66) at org.geoserver.filters.SpringDelegatingFilter.doFilter(SpringDelegatingFilter.java:41) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.platform.AdvancedDispatchFilter.doFilter(AdvancedDispatchFilter.java:37) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.geoserver.security.filter.GeoServerAnonymousAuthenticationFilter.doFilter(GeoServerAnonymousAuthenticationFilter.java:51) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:158) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.geoserver.security.filter.GeoServerBasicAuthenticationFilter.doFilter(GeoServerBasicAuthenticationFilter.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.geoserver.security.filter.GeoServerSecurityContextPersistenceFilter$1.doFilter(GeoServerSecurityContextPersistenceFilter.java:52) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178) at org.geoserver.security.GeoServerSecurityFilterChainProxy.doFilter(GeoServerSecurityFilterChainProxy.java:142) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.filters.LoggingFilter.doFilter(LoggingFilter.java:90) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.filters.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:79) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.filters.GZIPFilter.doFilter(GZIPFilter.java:42) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.filters.SessionDebugFilter.doFilter(SessionDebugFilter.java:46) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.filters.FlushSafeFilter.doFilter(FlushSafeFilter.java:42) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:494) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:137) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:651) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:407) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:754) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1376) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: javax.imageio.IIOException: Illegal value for Predictor in TIFF file at it.geosolutions.imageioimpl.plugins.tiff.TIFFLZWDecompressor. (TIFFLZWDecompressor.java:118) at it.geosolutions.imageioimpl.plugins.tiff.TIFFImageReader.read(TIFFImageReader.java:1856) at com.sun.media.jai.imageioimpl.ImageReadOpImage.computeTile(ImageReadOpImage.java:697) ... 166 more","title":"Serve raster tiles in GeoServer"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#steps-to-handle-raster-data","text":"","title":"Steps to handle raster data"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#download","text":"Download GeoServer and install, or create by a docker container","title":"Download"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#login","text":"Login the GeoServer by admin user, the default username/password is admin/geoserver.","title":"Login"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#create-a-raster-workspace","text":"","title":"Create a raster workspace"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#select-a-store-datasource","text":"Here we select GeoTIFF","title":"Select a store datasource"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#create-a-raster-store","text":"Here we specify a *.tif file","title":"Create a raster store"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#create-a-layer","text":"Create the layer under new created store and the format is : , and then publish it","title":"Create a layer"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#publish-review","text":"Have a review of all the information it reads including the band definitions, and save it","title":"Publish review"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#layer-preview","text":"Go the the layer preview and find the layer, and try to view it by OpenLayers","title":"Layer preview"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#layer-preview-result","text":"The geotiff file successfully being processed if we can see the layer","title":"Layer preview result"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#compressed-raster-layer-with-only-grey-band","text":"","title":"Compressed raster layer with only grey band"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#the-geotiff-file-failed-being-processed-for-unknown-reason","text":"","title":"The geotiff file failed being processed for unknown reason"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#exception-stack-trace-1","text":"Caused by: java.lang.NullPointerException at javax.media.jai.PlanarImage.getData(PlanarImage.java:2110) ...... <a href=\"#exception\" style=\"font-weight:bold\">View the full exception stack trace<sup>1</sup></a>","title":"Exception stack trace 1"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#exception-stack-trace-2","text":"Caused by: javax.imageio.IIOException: Illegal value for Predictor in TIFF file at it.geosolutions.imageioimpl.plugins.tiff.TIFFLZWDecompressor.<init>(TIFFLZWDecompressor.java:118) at it.geosolutions.imageioimpl.plugins.tiff.TIFFImageReader.read(TIFFImageReader.java:1856) at com.sun.media.jai.imageioimpl.ImageReadOpImage.computeTile(ImageReadOpImage.java:697) ... 166 more","title":"Exception stack trace 2"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#qgis-layer-preview","text":"Drag the geotiff file into the QGIS for preview","title":"QGIS layer preview"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#qgis-geotiff-layer-export","text":"Display the current layer, Select the menu item \"Layer-Save as...\" and export the geotiff with 4326 crs","title":"QGIS geotiff layer export"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#geoserver-layer-preview","text":"Modify the store in GeoServer to connect to the new geotiff file, and preview the layer again. It works with no color scheme","title":"GeoServer layer preview"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#cause-analysis","text":"The error raster geotiff only has one grey band, and the QGIS exported geotiff file is nearly twice the size of the original one. It is a compressed one, and that's why QGIS produces a bigger size when we save it as another. QGIS does not compress it, hence the new image is bigger. GeoServer doesn't accept compressed geotiff data. Regarding the GeoServer color problem, It's because that the style in GeoServer is not well defined.","title":"Cause analysis"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#define-style-in-geoserver","text":"","title":"Define style in GeoServer"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#create-style-in-qgis","text":"Open QGIS, drag the geotiff file into the QGIS. Right click on the data layer and select 'Properties', then select 'Style' on the left side. Change the render type to 'Singleband pseudocolor' and change the style by specifying the color ranges.","title":"Create style in QGIS"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#export-style-in-qgis","text":"Apply the change to see the new layer. Save the style using the 'Save Style' button on the bottom and save as .qml file.","title":"Export style in QGIS"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#copy-the-qml-content","text":"Open the .qml file with notepad and review the colorrampshader part.","title":"Copy the .qml content"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#generate-the-style-template-in-geoserver","text":"Go to the GeoServer admin page and click on 'Styles' and add a new style. Name the style and select the workspace, then choose 'Copy from existing style', select 'dem' and press 'copy...'","title":"Generate the style template in GeoServer"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#specify-the-style-content","text":"Change the name, title and abstract. Translate the .qml content into the GeoServer style content here. Notice the 'value'/'label'/'color' values in .qml match the 'quantity'/'label'/'color' in GeoServer. If the opacity is 0.0, it means that the color will not be visible, so it will be white. Press 'Validate' to check if it works. If there are no errors, then 'submit'.","title":"Specify the style content"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#generate-sld-in-qgis","text":"Comparing with exporting the .qml style in QGIS, we can directly generate .sld in QGIS and copy the content to create a style in GeoServer.","title":"Generate .sld in QGIS"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#create-style-in-geoserver-from-sld-file","text":"From the .sld file we exported from QGIS, we can easily create a style in GeoServer.","title":"Create style in Geoserver from .sld file"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#edit-layer-basic-info","text":"Go to 'Layers' and select the layer we just created. Make sure 'Enabled' and 'Advertised' are turned on and check if the 'Coverage Band Details' are set correctly, if not adjust them.","title":"Edit layer basic info"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#edit-wms-settings","text":"Select the 'Publishing' tab. With the 'WMS Settings' select 'Default Style' and change it to the style we just created. 'Save' the layer again.","title":"Edit WMS Settings"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#preview-layer","text":"View the layer again with the 'Layer preview' and 'Open Layers'. Now the layer should be displayed correctly.","title":"Preview layer"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#preview-layer-when-editing-style","text":"We could also edit the style and preview the result as soon as we apply in the style editing page.","title":"Preview layer when editing style"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#add-additional-styles","text":"Edit the layer again and with the 'WMS Settings' select additional styles and save. Remember to add the newly added style into it as well otherwise the restful api cannot list this style info under the layer.","title":"Add additional styles"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#preview-layer-with-additional-styles","text":"Preview the layer again and we could switch the style to any available one and see the result.","title":"Preview layer with additional styles"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#enable-cors-for-geoserver","text":"","title":"Enable CORS for GeoServer"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#clone-repository","text":"Clone the github repository docker-geoserver .","title":"Clone repository"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#create-webxml","text":"The contents of resources/overlays will be copied to the image file system during the build. For example, to include a static web xml with CORS support web.xml , create the file at resources/overlays/usr/local/tomcat/conf/web.xml .","title":"Create web.xml"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#enable-cors","text":"Add CORS enabled content into the web.xml as bellow. The full content of the web.xml can be found here . <filter> <filter-name> CorsFilter </filter-name> <filter-class> org.apache.catalina.filters.CorsFilter </filter-class> <init-param> <param-name> cors.allowed.origins </param-name> <param-value> * </param-value> </init-param> <init-param> <param-name> cors.allowed.methods </param-name> <param-value> GET,POST,HEAD,OPTIONS,PUT </param-value> </init-param> <init-param> <param-name> cors.allowed.headers </param-name> <param-value> Content-Type,X-Requested-With,accept,Origin,Access-Control-Request-Method,Access-Control-Request-Headers </param-value> </init-param> <init-param> <param-name> cors.exposed.headers </param-name> <param-value> Access-Control-Allow-Origin,Access-Control-Allow-Credentials </param-value> </init-param> <init-param> <param-name> cors.preflight.maxage </param-name> <param-value> 10 </param-value> </init-param> </filter> <filter-mapping> <filter-name> CorsFilter </filter-name> <url-pattern> /* </url-pattern> </filter-mapping>","title":"Enable CORS"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#docker-hub-modification","text":"Modify the build.sh script to own hub repository.","title":"Docker hub modification"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#build-and-push","text":"Build the docker image and push to own docker hub. Now the CORS enabled GeoServer docker image is ready to use. ./build.sh docker pull hustakin/geoserver","title":"Build and push"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#tomcat-error-log","text":"Sometimes the GeoServer container will met 404 issue. That's because the tomcat failed to start because of your modification. We could attach to the GeoServer container and inspect the tomcat error log to find the reason.","title":"Tomcat error log"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#client-http","text":"Please be noted the client HTTP should not use the credentials for CORS requests. For example, here I get feature information for raster data in angular6 client by clicking on the layer.","title":"Client http"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#renderer-the-raster-layer-in-the-web","text":"","title":"Renderer the raster layer in the web"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#leaflet-layer-using-wms","text":"let wmsLayer = L . tileLayer . wms ( 'http://localhost:9999/geoserver/raster/wms?' , { layers : 'raster:demo' , version : '1.1.1' , styles : '' , //Use the default style, we can also specify additional styles format : 'image/png' , transparent : true , maxZoom : 25 , tiled : true }); let map = L . map ( 'map' , { zoom : 0 , maxZoom : 25 , maxNativeZoom : 18 , layers : [ wmsLayer ], });","title":"Leaflet layer using WMS"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#leaflet-layer-using-wmts","text":"Please be noted that we should use EPSG:900913 other than EPSG:4326 here which for historical reasons is what GeoServer calls Web Mercator. let wmtsLayer = new L . TileLayer . WMTS ( 'http://localhost:9999/geoserver/gwc/service/wmts' , { layer : 'raster:demo' , style : \"\" , tilematrixSet : \"EPSG:900913\" , //Important!! It should be EPSG:900913 other than EPSG:4326 format : \"image/png\" , maxZoom : 25 , attribution : \"<a href='https://github.com/mylen/leaflet.TileLayer.WMTS'>GitHub</a>&copy; <a href='http://www.ign.fr'>IGN</a>\" }); let map = L . map ( 'map' , { zoom : 0 , maxZoom : 25 , maxNativeZoom : 18 , layers : [ wmtsLayer ], });","title":"Leaflet layer using WMTS"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#openlayers-layer-using-wmts","text":"let gridNames = [ 'EPSG:4326:0' , 'EPSG:4326:1' , 'EPSG:4326:2' , 'EPSG:4326:3' , 'EPSG:4326:4' , 'EPSG:4326:5' , 'EPSG:4326:6' , 'EPSG:4326:7' , 'EPSG:4326:8' , 'EPSG:4326:9' , 'EPSG:4326:10' , 'EPSG:4326:11' , 'EPSG:4326:12' , 'EPSG:4326:13' , 'EPSG:4326:14' , 'EPSG:4326:15' , 'EPSG:4326:16' , 'EPSG:4326:17' , 'EPSG:4326:18' , 'EPSG:4326:19' , 'EPSG:4326:20' , 'EPSG:4326:21' ]; let baseParams = [ 'VERSION' , 'LAYER' , 'STYLE' , 'TILEMATRIX' , 'TILEMATRIXSET' , 'SERVICE' , 'FORMAT' ]; let params = { VERSION : '1.0.0' , LAYER : 'raster:demo' , STYLE : '' , //Use the default style, we can also specify additional styles TILEMATRIX : gridNames , TILEMATRIXSET : 'EPSG:4326' , SERVICE : 'WMTS' , FORMAT : 'image/png' }; let projection = new Projection ({ code : 'EPSG:4326' , units : 'degrees' , axisOrientation : 'neu' });, let resolutions = [ 0.703125 , 0.3515625 , 0.17578125 , 0.087890625 , 0.0439453125 , 0.02197265625 , 0.010986328125 , 0.0054931640625 , 0.00274658203125 , 0.001373291015625 , 6.866455078125 E - 4 , 3.4332275390625 E - 4 , 1.71661376953125 E - 4 , 8.58306884765625 E - 5 , 4.291534423828125 E - 5 , 2.1457672119140625 E - 5 , 1.0728836059570312 E - 5 , 5.364418029785156 E - 6 , 2.682209014892578 E - 6 , 1.341104507446289 E - 6 , 6.705522537231445 E - 7 , 3.3527612686157227 E - 7 ]; let url = 'http://localhost:9999/geoserver/gwc/service/wmts?' ; for ( const param in params ) { if ( baseParams . indexOf ( param . toUpperCase ()) < 0 ) { url = url + param + '=' + params [ param ] + '&' ; } } url = url . slice ( 0 , - 1 ); const source = new WMTS ({ url , layer : params.LAYER , matrixSet : params.TILEMATRIXSET , format : params.FORMAT , projection : projection , tileGrid : new WMTSTileGrid ({ tileSize : [ 256 , 256 ], extent : [ - 180.0 , - 90.0 , 180.0 , 90.0 ], origin : [ - 180.0 , 90.0 ], resolutions : resolutions , matrixIds : params.TILEMATRIX }), style : params.STYLE , wrapX : true }); let wmsLayer = new TileLayer ({ source : source }); let view = new View ({ center : [ 0 , 0 ], zoom : 2 , projection : projection ;, extent : [ - 180.0 , - 90.0 , 180.0 , 90.0 ] }); let map = new Map ({ controls : [ new MousePosition (), new Zoom (), ], layers : [ wmsLayer ], target : 'map' , view : wmsVioew }); //Get layer feature information by clicking on the layer map . on ( 'singleclick' , evt => { document . getElementById ( 'info' ). innerHTML = '' ; const source = source ; const resolution = view . getResolution (); const tilegrid = source . getTileGrid (); const tileResolutions = tilegrid . getResolutions (); let zoomIdx , diff = Infinity ; for ( let i = 0 ; i < tileResolutions . length ; i ++ ) { const tileResolution = tileResolutions [ i ]; const diffP = Math . abs ( resolution - tileResolution ); if ( diffP < diff ) { diff = diffP ; zoomIdx = i ; } if ( tileResolution < resolution ) { break ; } } const tileSize = tilegrid . getTileSize ( zoomIdx ); const tileOrigin = tilegrid . getOrigin ( zoomIdx ); const fx = ( evt . coordinate [ 0 ] - tileOrigin [ 0 ]) / ( resolution * tileSize [ 0 ]); const fy = ( tileOrigin [ 1 ] - evt . coordinate [ 1 ]) / ( resolution * tileSize [ 1 ]); const tileCol = Math . floor ( fx ); const tileRow = Math . floor ( fy ); const tileI = Math . floor (( fx - tileCol ) * tileSize [ 0 ]); const tileJ = Math . floor (( fy - tileRow ) * tileSize [ 1 ]); const matrixIds = tilegrid . getMatrixIds ()[ zoomIdx ]; let url = url ; for ( const param in params ) { if ( param . toUpperCase () === 'TILEMATRIX' ) { url = url + 'TILEMATRIX=' + matrixIds + '&' ; } else { url = url + param + '=' + params [ param ] + '&' ; } } url = url + 'SERVICE=WMTS&REQUEST=GetFeatureInfo' + '&INFOFORMAT=' + 'text/html' + '&TileCol=' + tileCol + '&TileRow=' + tileRow + '&I=' + tileI + '&J=' + tileJ ; if ( url ) { document . getElementById ( 'info' ). innerHTML = 'Loading... please wait...' ; this . http . get < any > ( url , { // withCredentials: true, responseType : 'text' as 'json' , headers : new HttpHeaders ({ 'Accept' : '*/*' , 'Content-Type' : 'text/html' }), }) . subscribe (( res ) => { document . getElementById ( 'info' ). innerHTML = res ; }, () => { document . getElementById ( 'info' ). innerHTML = '' ; }); } });","title":"OpenLayers layer using WMTS"},{"location":"bestpractice/serve-raster-tiles-in-geoserver/#footnotes","text":"NullPointerException stack trace from GeoServer console 09 Sep 17:11:56 INFO [geoserver.wms] - Request: getServiceInfo Sep 09, 2019 5:11:56 PM org.geoserver.GeoserverInitStartupListener$1 errorOccurred INFO: Problem occurs when computing a tile by the owner. java.lang.RuntimeException: javax.imageio.IIOException: Illegal value for Predictor in TIFF file at com.sun.media.jai.imageioimpl.ImageReadOpImage.computeTile(ImageReadOpImage.java:706) at com.sun.media.jai.util.SunTileScheduler.scheduleTile(SunTileScheduler.java:904) at javax.media.jai.OpImage.getTile(OpImage.java:1129) at javax.media.jai.PlanarImage.getData(PlanarImage.java:2085) at javax.media.jai.PlanarImage.getExtendedData(PlanarImage.java:2440) at javax.media.jai.ScaleOpImage.computeTile(ScaleOpImage.java:1255) at com.sun.media.jai.util.SunTileScheduler.scheduleTile(SunTileScheduler.java:904) at javax.media.jai.OpImage.getTile(OpImage.java:1129) at javax.media.jai.PlanarImage.getData(PlanarImage.java:2085) at javax.media.jai.StatisticsOpImage.getProperty(StatisticsOpImage.java:292) at com.sun.media.jai.opimage.ExtremaOpImage.getProperty(ExtremaOpImage.java:100) at javax.media.jai.RenderedOp$1.getProperty(RenderedOp.java:1808) at javax.media.jai.PropertyEnvironment.getProperty(PropertyEnvironment.java:197) at javax.media.jai.PropertySourceImpl.getProperty(PropertySourceImpl.java:277) at javax.media.jai.WritablePropertySourceImpl.getProperty(WritablePropertySourceImpl.java:130) at javax.media.jai.RenderedOp.getProperty(RenderedOp.java:1982) at org.geotools.image.ImageWorker.getComputedProperty(ImageWorker.java:1033) at org.geotools.image.ImageWorker.getExtremas(ImageWorker.java:1089) at org.geotools.image.ImageWorker.rescaleToBytes(ImageWorker.java:1400) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:139) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:53) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter$1.execute(StyleVisitorCoverageProcessingNodeAdapter.java:97) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.checkExecuted(BaseCoverageProcessingNode.java:234) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:332) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:52) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter.getOutput(StyleVisitorCoverageProcessingNodeAdapter.java:130) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.symbolize(GridCoverageRenderer.java:484) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:1021) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:831) at org.geoserver.wms.map.RenderedImageMapOutputFormat.directRasterRender(RenderedImageMapOutputFormat.java:1036) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:349) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:265) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:132) at org.geoserver.wms.GetMap.executeInternal(GetMap.java:720) at org.geoserver.wms.GetMap.run(GetMap.java:300) at org.geoserver.wms.GetMap.run(GetMap.java:123) at org.geoserver.wms.DefaultWebMapService.getMap(DefaultWebMapService.java:251) at sun.reflect.GeneratedMethodAccessor296.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:333) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.geoserver.kml.WebMapServiceKmlInterceptor.invoke(WebMapServiceKmlInterceptor.java:38) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:59) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:33) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:72) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.ows.util.RequestObjectLogger.invoke(RequestObjectLogger.java:50) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:213) at com.sun.proxy.$Proxy96.getMap(Unknown Source) at sun.reflect.GeneratedMethodAccessor254.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.geoserver.ows.Dispatcher.execute(Dispatcher.java:877) at org.geoserver.ows.Dispatcher.handleRequestInternal(Dispatcher.java:264) at org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:174) at org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter.handle(SimpleControllerHandlerAdapter.java:50) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) at javax.servlet.http.HttpServlet.service(HttpServlet.java:687) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:808) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1669) at org.geoserver.filters.ThreadLocalsCleanupFilter.doFilter(ThreadLocalsCleanupFilter.java:26) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:69) at org.geoserver.wms.animate.AnimatorFilter.doFilter(AnimatorFilter.java:73) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:66) at org.geoserver.filters.SpringDelegatingFilter.doFilter(SpringDelegatingFilter.java:41) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.platform.AdvancedDispatchFilter.doFilter(AdvancedDispatchFilter.java:37) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerAnonymousAuthenticationFilter.doFilter(GeoServerAnonymousAuthenticationFilter.java:51) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:158) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.geoserver.security.filter.GeoServerBasicAuthenticationFilter.doFilter(GeoServerBasicAuthenticationFilter.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.geoserver.security.filter.GeoServerSecurityContextPersistenceFilter$1.doFilter(GeoServerSecurityContextPersistenceFilter.java:52) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) at org.geoserver.security.GeoServerSecurityFilterChainProxy.doFilter(GeoServerSecurityFilterChainProxy.java:141) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.LoggingFilter.doFilter(LoggingFilter.java:90) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:79) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.GZIPFilter.doFilter(GZIPFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SessionDebugFilter.doFilter(SessionDebugFilter.java:46) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.FlushSafeFilter.doFilter(FlushSafeFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:256) at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:219) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:215) at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) at org.eclipse.jetty.server.Server.handle(Server.java:499) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) at java.lang.Thread.run(Thread.java:748) Caused by: javax.imageio.IIOException: Illegal value for Predictor in TIFF file at it.geosolutions.imageioimpl.plugins.tiff.TIFFLZWDecompressor. (TIFFLZWDecompressor.java:118) at it.geosolutions.imageioimpl.plugins.tiff.TIFFImageReader.read(TIFFImageReader.java:1856) at com.sun.media.jai.imageioimpl.ImageReadOpImage.computeTile(ImageReadOpImage.java:697) ... 147 more Sep 09, 2019 5:11:56 PM org.geoserver.GeoserverInitStartupListener$1 errorOccurred INFO: Problem occurs when computing a tile by the owner. java.lang.NullPointerException at javax.media.jai.PlanarImage.getData(PlanarImage.java:2110) at javax.media.jai.PlanarImage.getExtendedData(PlanarImage.java:2440) at javax.media.jai.ScaleOpImage.computeTile(ScaleOpImage.java:1255) at com.sun.media.jai.util.SunTileScheduler.scheduleTile(SunTileScheduler.java:904) at javax.media.jai.OpImage.getTile(OpImage.java:1129) at javax.media.jai.PlanarImage.getData(PlanarImage.java:2085) at javax.media.jai.StatisticsOpImage.getProperty(StatisticsOpImage.java:292) at com.sun.media.jai.opimage.ExtremaOpImage.getProperty(ExtremaOpImage.java:100) at javax.media.jai.RenderedOp$1.getProperty(RenderedOp.java:1808) at javax.media.jai.PropertyEnvironment.getProperty(PropertyEnvironment.java:197) at javax.media.jai.PropertySourceImpl.getProperty(PropertySourceImpl.java:277) at javax.media.jai.WritablePropertySourceImpl.getProperty(WritablePropertySourceImpl.java:130) at javax.media.jai.RenderedOp.getProperty(RenderedOp.java:1982) at org.geotools.image.ImageWorker.getComputedProperty(ImageWorker.java:1033) at org.geotools.image.ImageWorker.getExtremas(ImageWorker.java:1089) at org.geotools.image.ImageWorker.rescaleToBytes(ImageWorker.java:1400) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:139) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:53) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter$1.execute(StyleVisitorCoverageProcessingNodeAdapter.java:97) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.checkExecuted(BaseCoverageProcessingNode.java:234) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:332) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:52) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter.getOutput(StyleVisitorCoverageProcessingNodeAdapter.java:130) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.symbolize(GridCoverageRenderer.java:484) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:1021) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:831) at org.geoserver.wms.map.RenderedImageMapOutputFormat.directRasterRender(RenderedImageMapOutputFormat.java:1036) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:349) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:265) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:132) at org.geoserver.wms.GetMap.executeInternal(GetMap.java:720) at org.geoserver.wms.GetMap.run(GetMap.java:300) at org.geoserver.wms.GetMap.run(GetMap.java:123) at org.geoserver.wms.DefaultWebMapService.getMap(DefaultWebMapService.java:251) at sun.reflect.GeneratedMethodAccessor296.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:333) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.geoserver.kml.WebMapServiceKmlInterceptor.invoke(WebMapServiceKmlInterceptor.java:38) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:59) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:33) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:72) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.ows.util.RequestObjectLogger.invoke(RequestObjectLogger.java:50) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:213) at com.sun.proxy.$Proxy96.getMap(Unknown Source) at sun.reflect.GeneratedMethodAccessor254.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.geoserver.ows.Dispatcher.execute(Dispatcher.java:877) at org.geoserver.ows.Dispatcher.handleRequestInternal(Dispatcher.java:264) at org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:174) at org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter.handle(SimpleControllerHandlerAdapter.java:50) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) at javax.servlet.http.HttpServlet.service(HttpServlet.java:687) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:808) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1669) at org.geoserver.filters.ThreadLocalsCleanupFilter.doFilter(ThreadLocalsCleanupFilter.java:26) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:69) at org.geoserver.wms.animate.AnimatorFilter.doFilter(AnimatorFilter.java:73) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:66) at org.geoserver.filters.SpringDelegatingFilter.doFilter(SpringDelegatingFilter.java:41) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.platform.AdvancedDispatchFilter.doFilter(AdvancedDispatchFilter.java:37) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerAnonymousAuthenticationFilter.doFilter(GeoServerAnonymousAuthenticationFilter.java:51) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:158) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.geoserver.security.filter.GeoServerBasicAuthenticationFilter.doFilter(GeoServerBasicAuthenticationFilter.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.geoserver.security.filter.GeoServerSecurityContextPersistenceFilter$1.doFilter(GeoServerSecurityContextPersistenceFilter.java:52) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) at org.geoserver.security.GeoServerSecurityFilterChainProxy.doFilter(GeoServerSecurityFilterChainProxy.java:141) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.LoggingFilter.doFilter(LoggingFilter.java:90) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:79) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.GZIPFilter.doFilter(GZIPFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SessionDebugFilter.doFilter(SessionDebugFilter.java:46) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.FlushSafeFilter.doFilter(FlushSafeFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:256) at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:219) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:215) at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) at org.eclipse.jetty.server.Server.handle(Server.java:499) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) at java.lang.Thread.run(Thread.java:748) java.lang.NullPointerException at javax.media.jai.PlanarImage.getData(PlanarImage.java:2110) at javax.media.jai.StatisticsOpImage.getProperty(StatisticsOpImage.java:292) at com.sun.media.jai.opimage.ExtremaOpImage.getProperty(ExtremaOpImage.java:100) at javax.media.jai.RenderedOp$1.getProperty(RenderedOp.java:1808) at javax.media.jai.PropertyEnvironment.getProperty(PropertyEnvironment.java:197) at javax.media.jai.PropertySourceImpl.getProperty(PropertySourceImpl.java:277) at javax.media.jai.WritablePropertySourceImpl.getProperty(WritablePropertySourceImpl.java:130) at javax.media.jai.RenderedOp.getProperty(RenderedOp.java:1982) at org.geotools.image.ImageWorker.getComputedProperty(ImageWorker.java:1033) at org.geotools.image.ImageWorker.getExtremas(ImageWorker.java:1089) at org.geotools.image.ImageWorker.rescaleToBytes(ImageWorker.java:1400) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:139) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:53) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter$1.execute(StyleVisitorCoverageProcessingNodeAdapter.java:97) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.checkExecuted(BaseCoverageProcessingNode.java:234) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:332) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:52) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter.getOutput(StyleVisitorCoverageProcessingNodeAdapter.java:130) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.symbolize(GridCoverageRenderer.java:484) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:1021) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:831) at org.geoserver.wms.map.RenderedImageMapOutputFormat.directRasterRender(RenderedImageMapOutputFormat.java:1036) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:349) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:265) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:132) at org.geoserver.wms.GetMap.executeInternal(GetMap.java:720) at org.geoserver.wms.GetMap.run(GetMap.java:300) at org.geoserver.wms.GetMap.run(GetMap.java:123) at org.geoserver.wms.DefaultWebMapService.getMap(DefaultWebMapService.java:251) at sun.reflect.GeneratedMethodAccessor296.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:333) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.geoserver.kml.WebMapServiceKmlInterceptor.invoke(WebMapServiceKmlInterceptor.java:38) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:59) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:33) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:72) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.ows.util.RequestObjectLogger.invoke(RequestObjectLogger.java:50) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:213) at com.sun.proxy.$Proxy96.getMap(Unknown Source) at sun.reflect.GeneratedMethodAccessor254.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.geoserver.ows.Dispatcher.execute(Dispatcher.java:877) at org.geoserver.ows.Dispatcher.handleRequestInternal(Dispatcher.java:264) at org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:174) at org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter.handle(SimpleControllerHandlerAdapter.java:50) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) at javax.servlet.http.HttpServlet.service(HttpServlet.java:687) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:808) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1669) at org.geoserver.filters.ThreadLocalsCleanupFilter.doFilter(ThreadLocalsCleanupFilter.java:26) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:69) at org.geoserver.wms.animate.AnimatorFilter.doFilter(AnimatorFilter.java:73) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:66) at org.geoserver.filters.SpringDelegatingFilter.doFilter(SpringDelegatingFilter.java:41) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.platform.AdvancedDispatchFilter.doFilter(AdvancedDispatchFilter.java:37) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerAnonymousAuthenticationFilter.doFilter(GeoServerAnonymousAuthenticationFilter.java:51) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:158) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.geoserver.security.filter.GeoServerBasicAuthenticationFilter.doFilter(GeoServerBasicAuthenticationFilter.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.geoserver.security.filter.GeoServerSecurityContextPersistenceFilter$1.doFilter(GeoServerSecurityContextPersistenceFilter.java:52) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) at org.geoserver.security.GeoServerSecurityFilterChainProxy.doFilter(GeoServerSecurityFilterChainProxy.java:141) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.LoggingFilter.doFilter(LoggingFilter.java:90) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:79) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.GZIPFilter.doFilter(GZIPFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SessionDebugFilter.doFilter(SessionDebugFilter.java:46) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.FlushSafeFilter.doFilter(FlushSafeFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:256) at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:219) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:215) at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) at org.eclipse.jetty.server.Server.handle(Server.java:499) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) at java.lang.Thread.run(Thread.java:748) 09 Sep 17:11:56 ERROR [geoserver.ows] - org.geoserver.platform.ServiceException: Error rendering coverage on the fast path at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:351) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:265) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:132) at org.geoserver.wms.GetMap.executeInternal(GetMap.java:720) at org.geoserver.wms.GetMap.run(GetMap.java:300) at org.geoserver.wms.GetMap.run(GetMap.java:123) at org.geoserver.wms.DefaultWebMapService.getMap(DefaultWebMapService.java:251) at sun.reflect.GeneratedMethodAccessor296.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:333) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.geoserver.kml.WebMapServiceKmlInterceptor.invoke(WebMapServiceKmlInterceptor.java:38) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:59) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:33) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:72) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.geoserver.ows.util.RequestObjectLogger.invoke(RequestObjectLogger.java:50) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:213) at com.sun.proxy.$Proxy96.getMap(Unknown Source) at sun.reflect.GeneratedMethodAccessor254.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.geoserver.ows.Dispatcher.execute(Dispatcher.java:877) at org.geoserver.ows.Dispatcher.handleRequestInternal(Dispatcher.java:264) at org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:174) at org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter.handle(SimpleControllerHandlerAdapter.java:50) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) at javax.servlet.http.HttpServlet.service(HttpServlet.java:687) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:808) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1669) at org.geoserver.filters.ThreadLocalsCleanupFilter.doFilter(ThreadLocalsCleanupFilter.java:26) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:69) at org.geoserver.wms.animate.AnimatorFilter.doFilter(AnimatorFilter.java:73) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:66) at org.geoserver.filters.SpringDelegatingFilter.doFilter(SpringDelegatingFilter.java:41) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.platform.AdvancedDispatchFilter.doFilter(AdvancedDispatchFilter.java:37) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerAnonymousAuthenticationFilter.doFilter(GeoServerAnonymousAuthenticationFilter.java:51) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:158) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.geoserver.security.filter.GeoServerBasicAuthenticationFilter.doFilter(GeoServerBasicAuthenticationFilter.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.geoserver.security.filter.GeoServerSecurityContextPersistenceFilter$1.doFilter(GeoServerSecurityContextPersistenceFilter.java:52) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) at org.geoserver.security.GeoServerSecurityFilterChainProxy.doFilter(GeoServerSecurityFilterChainProxy.java:141) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.LoggingFilter.doFilter(LoggingFilter.java:90) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:79) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.GZIPFilter.doFilter(GZIPFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.SessionDebugFilter.doFilter(SessionDebugFilter.java:46) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.geoserver.filters.FlushSafeFilter.doFilter(FlushSafeFilter.java:42) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:256) at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:219) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:215) at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) at org.eclipse.jetty.server.Server.handle(Server.java:499) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257) at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) at java.lang.Thread.run(Thread.java:748) Caused by: org.geoserver.platform.ServiceException: org.geotools.coverage.processing.CoverageProcessingException: java.lang.NullPointerException at org.geoserver.wms.map.RenderedImageMapOutputFormat.directRasterRender(RenderedImageMapOutputFormat.java:1200) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:349) ... 117 more Caused by: org.geotools.coverage.processing.CoverageProcessingException: java.lang.NullPointerException at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:333) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:52) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter.getOutput(StyleVisitorCoverageProcessingNodeAdapter.java:130) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.symbolize(GridCoverageRenderer.java:484) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:1021) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:831) at org.geoserver.wms.map.RenderedImageMapOutputFormat.directRasterRender(RenderedImageMapOutputFormat.java:1036) ... 118 more Caused by: java.lang.NullPointerException at javax.media.jai.PlanarImage.getData(PlanarImage.java:2110) at javax.media.jai.StatisticsOpImage.getProperty(StatisticsOpImage.java:292) at com.sun.media.jai.opimage.ExtremaOpImage.getProperty(ExtremaOpImage.java:100) at javax.media.jai.RenderedOp$1.getProperty(RenderedOp.java:1808) at javax.media.jai.PropertyEnvironment.getProperty(PropertyEnvironment.java:197) at javax.media.jai.PropertySourceImpl.getProperty(PropertySourceImpl.java:277) at javax.media.jai.WritablePropertySourceImpl.getProperty(WritablePropertySourceImpl.java:130) at javax.media.jai.RenderedOp.getProperty(RenderedOp.java:1982) at org.geotools.image.ImageWorker.getComputedProperty(ImageWorker.java:1033) at org.geotools.image.ImageWorker.getExtremas(ImageWorker.java:1089) at org.geotools.image.ImageWorker.rescaleToBytes(ImageWorker.java:1400) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:139) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:53) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter$1.execute(StyleVisitorCoverageProcessingNodeAdapter.java:97) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.checkExecuted(BaseCoverageProcessingNode.java:234) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:332) ... 124 more Illegal value exception from GeoServer console 24-Nov-2020 04:49:03.269 INFO [http-nio-8080-exec-7] org.geoserver.GeoserverInitStartupListener$1.errorOccurred Problem occurs when computing a tile by the owner. java.lang.RuntimeException: javax.imageio.IIOException: Illegal value for Predictor in TIFF file at com.sun.media.jai.imageioimpl.ImageReadOpImage.computeTile(ImageReadOpImage.java:706) at com.sun.media.jai.util.SunTileScheduler.scheduleTile(SunTileScheduler.java:904) at javax.media.jai.OpImage.getTile(OpImage.java:1129) at javax.media.jai.PlanarImage.cobbleFloat(PlanarImage.java:3254) at javax.media.jai.PlanarImage.getData(PlanarImage.java:2181) at it.geosolutions.jaiext.scale.ScaleOpImage.computeTile(ScaleOpImage.java:1651) at com.sun.media.jai.util.SunTileScheduler.scheduleTile(SunTileScheduler.java:904) at javax.media.jai.OpImage.getTile(OpImage.java:1129) at it.geosolutions.jaiext.stats.SimpleStatsOpImage.computeTile(SimpleStatsOpImage.java:95) at com.sun.media.jai.util.SunTileScheduler.scheduleTile(SunTileScheduler.java:904) at javax.media.jai.OpImage.getTile(OpImage.java:1129) at it.geosolutions.jaiext.stats.StatisticsOpImage.getProperty(StatisticsOpImage.java:333) at javax.media.jai.RenderedOp$1.getProperty(RenderedOp.java:1808) at javax.media.jai.PropertyEnvironment.getProperty(PropertyEnvironment.java:197) at javax.media.jai.PropertySourceImpl.getProperty(PropertySourceImpl.java:277) at javax.media.jai.WritablePropertySourceImpl.getProperty(WritablePropertySourceImpl.java:130) at javax.media.jai.RenderedOp.getProperty(RenderedOp.java:1982) at org.geotools.image.ImageWorker.getComputedProperty(ImageWorker.java:1078) at org.geotools.image.ImageWorker.getExtremas(ImageWorker.java:1111) at org.geotools.image.ImageWorker.rescaleToBytes(ImageWorker.java:1442) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:138) at org.geotools.renderer.lite.gridcoverage2d.RasterSymbolizerHelper.execute(RasterSymbolizerHelper.java:52) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter$1.execute(StyleVisitorCoverageProcessingNodeAdapter.java:96) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.checkExecuted(BaseCoverageProcessingNode.java:233) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:331) at org.geotools.renderer.lite.gridcoverage2d.BaseCoverageProcessingNode.getOutput(BaseCoverageProcessingNode.java:51) at org.geotools.renderer.lite.gridcoverage2d.StyleVisitorCoverageProcessingNodeAdapter.getOutput(StyleVisitorCoverageProcessingNodeAdapter.java:129) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.symbolize(GridCoverageRenderer.java:482) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:1018) at org.geotools.renderer.lite.gridcoverage2d.GridCoverageRenderer.renderImage(GridCoverageRenderer.java:829) at org.geoserver.wms.map.RenderedImageMapOutputFormat.directRasterRender(RenderedImageMapOutputFormat.java:1058) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:353) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:269) at org.geoserver.wms.map.RenderedImageMapOutputFormat.produceMap(RenderedImageMapOutputFormat.java:132) at org.geoserver.wms.GetMap.executeInternal(GetMap.java:707) at org.geoserver.wms.GetMap.run(GetMap.java:287) at org.geoserver.wms.GetMap.run(GetMap.java:110) at org.geoserver.wms.DefaultWebMapService.getMap(DefaultWebMapService.java:251) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.geoserver.kml.WebMapServiceKmlInterceptor.invoke(WebMapServiceKmlInterceptor.java:38) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:55) at org.geoserver.gwc.wms.CacheSeedingWebMapService.invoke(CacheSeedingWebMapService.java:31) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:72) at org.geoserver.gwc.wms.CachingWebMapService.invoke(CachingWebMapService.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.geoserver.ows.util.RequestObjectLogger.invoke(RequestObjectLogger.java:50) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212) at com.sun.proxy.$Proxy46.getMap(Unknown Source) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.geoserver.ows.Dispatcher.execute(Dispatcher.java:877) at org.geoserver.ows.Dispatcher.handleRequestInternal(Dispatcher.java:264) at org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:177) at org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter.handle(SimpleControllerHandlerAdapter.java:52) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:998) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:890) at javax.servlet.http.HttpServlet.service(HttpServlet.java:634) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:875) at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.filters.CorsFilter.handleNonCORS(CorsFilter.java:430) at org.apache.catalina.filters.CorsFilter.doFilter(CorsFilter.java:169) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.filters.ThreadLocalsCleanupFilter.doFilter(ThreadLocalsCleanupFilter.java:26) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:69) at org.geoserver.flow.controller.IpBlacklistFilter.doFilter(IpBlacklistFilter.java:89) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:66) at org.geoserver.flow.ControlFlowCallback.doFilter(ControlFlowCallback.java:260) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:66) at org.geoserver.wms.animate.AnimatorFilter.doFilter(AnimatorFilter.java:73) at org.geoserver.filters.SpringDelegatingFilter$Chain.doFilter(SpringDelegatingFilter.java:66) at org.geoserver.filters.SpringDelegatingFilter.doFilter(SpringDelegatingFilter.java:41) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.platform.AdvancedDispatchFilter.doFilter(AdvancedDispatchFilter.java:37) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.geoserver.security.filter.GeoServerAnonymousAuthenticationFilter.doFilter(GeoServerAnonymousAuthenticationFilter.java:51) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:158) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.geoserver.security.filter.GeoServerBasicAuthenticationFilter.doFilter(GeoServerBasicAuthenticationFilter.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:70) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.geoserver.security.filter.GeoServerSecurityContextPersistenceFilter$1.doFilter(GeoServerSecurityContextPersistenceFilter.java:52) at org.geoserver.security.filter.GeoServerCompositeFilter$NestedFilterChain.doFilter(GeoServerCompositeFilter.java:74) at org.geoserver.security.filter.GeoServerCompositeFilter.doFilter(GeoServerCompositeFilter.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178) at org.geoserver.security.GeoServerSecurityFilterChainProxy.doFilter(GeoServerSecurityFilterChainProxy.java:142) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.filters.LoggingFilter.doFilter(LoggingFilter.java:90) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.filters.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:79) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.filters.GZIPFilter.doFilter(GZIPFilter.java:42) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.filters.SessionDebugFilter.doFilter(SessionDebugFilter.java:46) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.geoserver.filters.FlushSafeFilter.doFilter(FlushSafeFilter.java:42) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:494) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:137) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:651) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:407) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:754) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1376) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: javax.imageio.IIOException: Illegal value for Predictor in TIFF file at it.geosolutions.imageioimpl.plugins.tiff.TIFFLZWDecompressor. (TIFFLZWDecompressor.java:118) at it.geosolutions.imageioimpl.plugins.tiff.TIFFImageReader.read(TIFFImageReader.java:1856) at com.sun.media.jai.imageioimpl.ImageReadOpImage.computeTile(ImageReadOpImage.java:697) ... 166 more","title":"Footnotes"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/","text":"Jenkins Pipeline (or simply \"Pipeline\" with a capital \"P\") is a suite of plugins which supports implementing and integrating continuous delivery pipelines into Jenkins. Blue Ocean rethinks the user experience of Jenkins. Designed from the ground up for Jenkins Pipeline, but still compatible with freestyle jobs, Blue Ocean reduces clutter and increases clarity for every member of the team. Install Jenkins in K8s Create namespace kubectl create namespace devops Create Jenkins containers Create pv/pvc/deployment/service/ingress by yaml files kubectl create -f ops-storage.yml kubectl create -f rbac.yml kubectl create -f jenkins.yml Storage yaml The content of ops-storage.yml is as bellow. apiVersion : v1 kind : PersistentVolume metadata : name : opspv spec : capacity : storage : 20Gi accessModes : - ReadWriteOnce persistentVolumeReclaimPolicy : Retain storageClassName : local-storage local : path : /mnt/data nodeAffinity : required : nodeSelectorTerms : - matchExpressions : - key : node operator : In values : - dev --- kind : PersistentVolumeClaim apiVersion : v1 metadata : name : opspvc namespace : devops spec : accessModes : - ReadWriteOnce storageClassName : local-storage resources : requests : storage : 20Gi RBAC yaml The content of rbac.yml is as bellow. apiVersion : v1 kind : ServiceAccount metadata : name : jenkins namespace : devops --- kind : ClusterRole apiVersion : rbac.authorization.k8s.io/v1beta1 metadata : name : jenkins rules : - apiGroups : [ \"extensions\" , \"apps\" ] resources : [ \"deployments\" ] verbs : [ \"create\" , \"delete\" , \"get\" , \"list\" , \"watch\" , \"patch\" , \"update\" ] - apiGroups : [ \"\" ] resources : [ \"services\" ] verbs : [ \"create\" , \"delete\" , \"get\" , \"list\" , \"watch\" , \"patch\" , \"update\" ] - apiGroups : [ \"\" ] resources : [ \"pods\" ] verbs : [ \"create\" , \"delete\" , \"get\" , \"list\" , \"patch\" , \"update\" , \"watch\" ] - apiGroups : [ \"\" ] resources : [ \"pods/exec\" ] verbs : [ \"create\" , \"delete\" , \"get\" , \"list\" , \"patch\" , \"update\" , \"watch\" ] - apiGroups : [ \"\" ] resources : [ \"pods/log\" ] verbs : [ \"get\" , \"list\" , \"watch\" ] - apiGroups : [ \"\" ] resources : [ \"secrets\" ] verbs : [ \"get\" ] --- apiVersion : rbac.authorization.k8s.io/v1beta1 kind : ClusterRoleBinding metadata : name : jenkins namespace : devops roleRef : apiGroup : rbac.authorization.k8s.io kind : ClusterRole name : jenkins subjects : - kind : ServiceAccount name : jenkins namespace : devops Jenkins yaml The content of jenkins.yml is as bellow. Remember to replace the Traefik ingress configuration [domain] to your domain. apiVersion : extensions/v1beta1 kind : Deployment metadata : name : jenkins namespace : devops spec : template : metadata : labels : app : jenkins spec : terminationGracePeriodSeconds : 10 serviceAccount : jenkins containers : - name : jenkins image : jenkins/jenkins:lts imagePullPolicy : IfNotPresent ports : - containerPort : 8080 name : web protocol : TCP - containerPort : 50000 name : agent protocol : TCP resources : limits : cpu : 1000m memory : 1Gi requests : cpu : 500m memory : 512Mi livenessProbe : httpGet : path : /login port : 8080 initialDelaySeconds : 60 timeoutSeconds : 5 failureThreshold : 12 readinessProbe : httpGet : path : /login port : 8080 initialDelaySeconds : 60 timeoutSeconds : 5 failureThreshold : 12 volumeMounts : - name : jenkinshome subPath : jenkins mountPath : /var/jenkins_home env : - name : LIMITS_MEMORY valueFrom : resourceFieldRef : resource : limits.memory divisor : 1Mi - name : JAVA_OPTS value : -Xmx$(LIMITS_MEMORY)m -XshowSettings:vm -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85 -Duser.timezone=Asia/Shanghai securityContext : fsGroup : 1000 volumes : - name : jenkinshome persistentVolumeClaim : claimName : opspvc --- apiVersion : v1 kind : Service metadata : name : jenkins namespace : devops labels : app : jenkins spec : selector : app : jenkins type : NodePort ports : - name : web port : 8080 targetPort : web nodePort : 30002 - name : agent port : 50000 targetPort : agent --- apiVersion : extensions/v1beta1 kind : Ingress metadata : name : jenkins-ingress namespace : devops spec : rules : - host : [ domain ] http : paths : - path : / backend : serviceName : jenkins servicePort : web Wait until running Check if pods runs kubectl get pods -n devops Login Jenkins Check the Jenkins password and login, then install plugins. #Please check the jenkins startup logs or check the content in this file cat /mnt/data/jenkins/secrets/initialAdminPassword Install plugins Installed plugins include: * Blue Ocean * Kubernetes plugin (Job and Stage Monitoring Plugin) * NodeJS Plugin * Embeddable Build Status Plugin Jenkins Slave Image Jenkins Slave jobs will run in your Kubernetes cluster, so it is important that the kubectl version for you Kubernetes cluster is the same with the Jenkins Slave docker image, otherwise you may meet some version conflict issues for Jenkins Pipelines jobs. I build my own Jenkins Slave docker image hustakin/jenkins-slave:latest with the kubectl version v1.14.2. For different version, you should build your own jenkins slave docker image with another kubectl version based on image cnych/jenkins:jnlp. Kuberctl replace The easiest way to customize different version kubectl is to replace the executable file \"kubectl\" from image cnych/jenkins:jnlp. You can find the file in your kubernetes cluster or download it. #Find current kubectl which kubectl #/usr/bin/kubectl #Download v1.14.2 kubectl and modify it to executable curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.14.2/bin/darwin/amd64/kubectl chmod +x ./kubectl Dockerfile Copy the kubectl file to current folder and build the Dockerfile. FROM cnych/jenkins:jnlp MAINTAINER Frankie Fan \"hustakin@gmail.com\" ENV REFRESHED_AT 2019 -6-26 COPY kubectl /usr/local/bin/kubectl ENTRYPOINT [ \"jenkins-slave\" ] Jenkins Configurations Configure Kubernetes Click Manage Jenkins->Configure System->Add a new cloud->Kubernetes. Test the connection and input namespace and Jenkins inner url by format ( . .svc.cluster.local:8080) Configure Jenkins Slave k8s template Add pod template, and remember to clean the \"Command to run\" and \"Arguments to pass to the command\" (This's really important!). The image hustakin/jenkins-slave:latest has the kubectl version of v1.14.2 Configure Jenkins Slave k8s volumes Add volumes in the pod template including docker, .kube config files as well as the maven cache. (Each node of the cluster will cache the maven into /home/ec2-user/.m2) Configure service account The service account is created in previous RBAC yaml step. Configure global tool Click Manage Jenkins->Global Tool Configuration. Configure maven installations. Configure NodeJS installations Click Manage Jenkins->Global Tool Configuration. Configure NodeJS installations. Configure DockerHub credentials Click Jenkins->Credentials->(global)->Add credentials. Specify your DockerHub username and password. Remember the ID here will be used in your Jenkinsfile to specify \"credentialsId\". Configure Pipelines Write Dockerfile and Jenkinsfile and k8s.yaml in your project root folder and push it to GitHub. Create the repository in Dockerhub for your project in order to save docker built images. Jenkinsfile content for SpringBoot The Jenkinsfile content is as bellow node('jenkins-jnlp') { env.MVN_HOME = \"${tool 'Maven'}\" env.PATH=\"${env.MVN_HOME}/bin:${env.PATH}\" stage('Prepare') { echo \"1.Prepare Stage\" checkout scm script { build_tag = sh(returnStdout: true, script: 'git rev-parse --short HEAD').trim() if (env.BRANCH_NAME != 'master') { build_tag = \"${env.BRANCH_NAME}-${build_tag}\" } } } stage('Compile') { echo \"2.Compile SpringBoot App Stage\" sh \"mvn clean package -Dmaven.test.skip=true\" } stage('Build') { echo \"3.Build Docker Image Stage\" sh \"docker build -t hustakin/test:${build_tag} .\" } stage('Push') { echo \"4.Push Docker Image Stage\" withCredentials([usernamePassword(credentialsId: 'dockerHub', passwordVariable: 'dockerHubPassword', usernameVariable: 'dockerHubUser')]) { sh \"docker login -u ${dockerHubUser} -p ${dockerHubPassword}\" sh \"docker push hustakin/test:${build_tag}\" } } stage('Deploy') { echo \"5. Deploy To K8S Cluster Stage\" sh \"sed -i 's/<BUILD_TAG>/${build_tag}/' k8s.yaml\" sh \"sed -i 's/<BRANCH_NAME>/${env.BRANCH_NAME}/' k8s.yaml\" sh \"kubectl apply -f k8s.yaml --record\" } } Dockerfile content for SpringBoot The Dockerfile content is as bellow FROM openjdk:8-jre MAINTAINER Frankie Fan \"hustakin@gmail.com\" ENV REFRESHED_AT 2019 -7-3 VOLUME /tmp ADD web/target/test.jar test.jar ENTRYPOINT [ \"java\" , \"-XX:-BytecodeVerificationLocal\" , \"-XX:-BytecodeVerificationRemote\" , \"-XX:CICompilerCount=3\" , \"-XX:InitialHeapSize=268435456\" , \"-XX:+ManagementServer\" , \"-XX:MaxHeapSize=4263510016\" , \"-XX:MaxNewSize=2147483648\" , \"-XX:MinHeapDeltaBytes=524288\" , \"-XX:NewSize=89128960\" , \"-XX:OldSize=179306496\" , \"-XX:TieredStopAtLevel=1\" , \"-XX:+UseCompressedClassPointers\" , \"-XX:+UseCompressedOops\" , \"-XX:-UseLargePagesIndividualAllocation\" , \"-XX:+UseParallelGC\" , \"-Djava.security.egd=file:/dev/./urandom\" , \"-Dspring.profiles.active=dev\" , \"-jar\" , \"/test.jar\" ] EXPOSE 80 443 K8s content for SpringBoot The k8s.yaml content is as bellow kind : Deployment apiVersion : extensions/v1beta1 metadata : name : test-server namespace : agric spec : replicas : 2 minReadySeconds : 10 strategy : type : RollingUpdate rollingUpdate : maxUnavailable : 1 maxSurge : 1 template : metadata : labels : app : test-server spec : containers : - name : test-server image : hustakin/test:<BUILD_TAG> env : - name : branch value : <BRANCH_NAME> ports : - containerPort : 80 protocol : TCP name : web - containerPort : 443 protocol : TCP name : https # inventory probe readinessProbe : httpGet : path : /ready port : 80 initialDelaySeconds : 15 periodSeconds : 5 failureThreshold : 5 imagePullSecrets : - name : docker-hub Jenkinsfile content for Angular The Jenkinsfile content is as bellow node('jenkins-jnlp') { env.NODEJS_HOME = \"${tool 'Node'}\" env.PATH=\"${env.NODEJS_HOME}/bin:${env.PATH}\" stage('Prepare') { echo \"1.Prepare Stage\" checkout scm script { build_tag = sh(returnStdout: true, script: 'git rev-parse --short HEAD').trim() if (env.BRANCH_NAME != 'master') { build_tag = \"${env.BRANCH_NAME}-${build_tag}\" } } } stage('Compile') { echo \"2.Compile Angular App Stage\" sh \"npm install\" sh \"npm install node-sass\" sh \"npm run prod\" } stage('Build') { echo \"3.Build Docker Image Stage\" sh \"docker build -t hustakin/test-front:${build_tag} .\" } stage('Push') { echo \"4.Push Docker Image Stage\" withCredentials([usernamePassword(credentialsId: 'dockerHub', passwordVariable: 'dockerHubPassword', usernameVariable: 'dockerHubUser')]) { sh \"docker login -u ${dockerHubUser} -p ${dockerHubPassword}\" sh \"docker push hustakin/test-front:${build_tag}\" } } stage('Deploy') { echo \"5. Deploy To K8S Cluster Stage\" sh \"sed -i 's/<BUILD_TAG>/${build_tag}/' k8s.yaml\" sh \"sed -i 's/<BRANCH_NAME>/${env.BRANCH_NAME}/' k8s.yaml\" sh \"kubectl apply -f k8s.yaml --record\" } } Dockerfile content for Angular The Dockerfile content is as bellow FROM nginx:1.16.0 MAINTAINER Frankie Fan \"hustakin@gmail.com\" ENV REFRESHED_AT 2019 -6-5 COPY nginx/default.conf /etc/nginx/conf.d/ RUN rm -rf /usr/share/nginx/html/* COPY /dist /usr/share/nginx/html CMD [ \"nginx\" , \"-g\" , \"daemon off;\" ] EXPOSE 80 Nginx conf content for Angular The nginx/default.conf content is as bellow. server { listen 80 ; sendfile on ; default_type application/octet-stream ; gzip on ; gzip_http_version 1 .1 ; gzip_disable \"MSIE [1-6]\\.\" ; gzip_min_length 256 ; gzip_vary on ; gzip_proxied expired no-cache no-store private auth ; gzip_types text/plain text/css application/json application/javascript application/x-javascript text/xml application/xml application/xml+rss text/javascript ; gzip_comp_level 9 ; root /usr/share/nginx/html ; location / { try_files $uri $uri/ /index.html = 404 ; } } K8s content for Angular The k8s.yaml content is as bellow kind : Deployment apiVersion : extensions/v1beta1 metadata : name : test-front-dev namespace : agric spec : replicas : 2 minReadySeconds : 10 strategy : type : RollingUpdate rollingUpdate : maxUnavailable : 1 maxSurge : 1 template : metadata : labels : app : test-front-dev spec : containers : - name : test-front-dev image : hustakin/test-front:<BUILD_TAG> env : - name : branch value : <BRANCH_NAME> ports : - containerPort : 80 protocol : TCP name : web - containerPort : 443 protocol : TCP name : https imagePullSecrets : - name : docker-hub Create Github Pipeline Click Jenkins->Open Blue Ocean->New Pipeline, and create pipeline for your project. Create Github Pipeline The jenkins pipeline should work now. Enter your jenkins job and master branch, you could see the stage view here. Trigger pipeline Push your code changes to Github. Click Jenkins->Open Blue Ocean. You can trigger the build for all pipelines you created by clicking the Run button. Blue Ocean build Click Jenkins->Open Blue Ocean, and click the pipeline you just created, you will see the Jenkinsfile stages and related logs here.","title":"Setup Jenkins Pipeline and Blue Ocean in Kubernetes"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#install-jenkins-in-k8s","text":"","title":"Install Jenkins in K8s"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#create-namespace","text":"kubectl create namespace devops","title":"Create namespace"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#create-jenkins-containers","text":"Create pv/pvc/deployment/service/ingress by yaml files kubectl create -f ops-storage.yml kubectl create -f rbac.yml kubectl create -f jenkins.yml","title":"Create Jenkins containers"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#storage-yaml","text":"The content of ops-storage.yml is as bellow. apiVersion : v1 kind : PersistentVolume metadata : name : opspv spec : capacity : storage : 20Gi accessModes : - ReadWriteOnce persistentVolumeReclaimPolicy : Retain storageClassName : local-storage local : path : /mnt/data nodeAffinity : required : nodeSelectorTerms : - matchExpressions : - key : node operator : In values : - dev --- kind : PersistentVolumeClaim apiVersion : v1 metadata : name : opspvc namespace : devops spec : accessModes : - ReadWriteOnce storageClassName : local-storage resources : requests : storage : 20Gi","title":"Storage yaml"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#rbac-yaml","text":"The content of rbac.yml is as bellow. apiVersion : v1 kind : ServiceAccount metadata : name : jenkins namespace : devops --- kind : ClusterRole apiVersion : rbac.authorization.k8s.io/v1beta1 metadata : name : jenkins rules : - apiGroups : [ \"extensions\" , \"apps\" ] resources : [ \"deployments\" ] verbs : [ \"create\" , \"delete\" , \"get\" , \"list\" , \"watch\" , \"patch\" , \"update\" ] - apiGroups : [ \"\" ] resources : [ \"services\" ] verbs : [ \"create\" , \"delete\" , \"get\" , \"list\" , \"watch\" , \"patch\" , \"update\" ] - apiGroups : [ \"\" ] resources : [ \"pods\" ] verbs : [ \"create\" , \"delete\" , \"get\" , \"list\" , \"patch\" , \"update\" , \"watch\" ] - apiGroups : [ \"\" ] resources : [ \"pods/exec\" ] verbs : [ \"create\" , \"delete\" , \"get\" , \"list\" , \"patch\" , \"update\" , \"watch\" ] - apiGroups : [ \"\" ] resources : [ \"pods/log\" ] verbs : [ \"get\" , \"list\" , \"watch\" ] - apiGroups : [ \"\" ] resources : [ \"secrets\" ] verbs : [ \"get\" ] --- apiVersion : rbac.authorization.k8s.io/v1beta1 kind : ClusterRoleBinding metadata : name : jenkins namespace : devops roleRef : apiGroup : rbac.authorization.k8s.io kind : ClusterRole name : jenkins subjects : - kind : ServiceAccount name : jenkins namespace : devops","title":"RBAC yaml"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#jenkins-yaml","text":"The content of jenkins.yml is as bellow. Remember to replace the Traefik ingress configuration [domain] to your domain. apiVersion : extensions/v1beta1 kind : Deployment metadata : name : jenkins namespace : devops spec : template : metadata : labels : app : jenkins spec : terminationGracePeriodSeconds : 10 serviceAccount : jenkins containers : - name : jenkins image : jenkins/jenkins:lts imagePullPolicy : IfNotPresent ports : - containerPort : 8080 name : web protocol : TCP - containerPort : 50000 name : agent protocol : TCP resources : limits : cpu : 1000m memory : 1Gi requests : cpu : 500m memory : 512Mi livenessProbe : httpGet : path : /login port : 8080 initialDelaySeconds : 60 timeoutSeconds : 5 failureThreshold : 12 readinessProbe : httpGet : path : /login port : 8080 initialDelaySeconds : 60 timeoutSeconds : 5 failureThreshold : 12 volumeMounts : - name : jenkinshome subPath : jenkins mountPath : /var/jenkins_home env : - name : LIMITS_MEMORY valueFrom : resourceFieldRef : resource : limits.memory divisor : 1Mi - name : JAVA_OPTS value : -Xmx$(LIMITS_MEMORY)m -XshowSettings:vm -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85 -Duser.timezone=Asia/Shanghai securityContext : fsGroup : 1000 volumes : - name : jenkinshome persistentVolumeClaim : claimName : opspvc --- apiVersion : v1 kind : Service metadata : name : jenkins namespace : devops labels : app : jenkins spec : selector : app : jenkins type : NodePort ports : - name : web port : 8080 targetPort : web nodePort : 30002 - name : agent port : 50000 targetPort : agent --- apiVersion : extensions/v1beta1 kind : Ingress metadata : name : jenkins-ingress namespace : devops spec : rules : - host : [ domain ] http : paths : - path : / backend : serviceName : jenkins servicePort : web","title":"Jenkins yaml"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#wait-until-running","text":"Check if pods runs kubectl get pods -n devops","title":"Wait until running"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#login-jenkins","text":"Check the Jenkins password and login, then install plugins. #Please check the jenkins startup logs or check the content in this file cat /mnt/data/jenkins/secrets/initialAdminPassword","title":"Login Jenkins"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#install-plugins","text":"Installed plugins include: * Blue Ocean * Kubernetes plugin (Job and Stage Monitoring Plugin) * NodeJS Plugin * Embeddable Build Status Plugin","title":"Install plugins"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#jenkins-slave-image","text":"Jenkins Slave jobs will run in your Kubernetes cluster, so it is important that the kubectl version for you Kubernetes cluster is the same with the Jenkins Slave docker image, otherwise you may meet some version conflict issues for Jenkins Pipelines jobs. I build my own Jenkins Slave docker image hustakin/jenkins-slave:latest with the kubectl version v1.14.2. For different version, you should build your own jenkins slave docker image with another kubectl version based on image cnych/jenkins:jnlp.","title":"Jenkins Slave Image"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#kuberctl-replace","text":"The easiest way to customize different version kubectl is to replace the executable file \"kubectl\" from image cnych/jenkins:jnlp. You can find the file in your kubernetes cluster or download it. #Find current kubectl which kubectl #/usr/bin/kubectl #Download v1.14.2 kubectl and modify it to executable curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.14.2/bin/darwin/amd64/kubectl chmod +x ./kubectl","title":"Kuberctl replace"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#dockerfile","text":"Copy the kubectl file to current folder and build the Dockerfile. FROM cnych/jenkins:jnlp MAINTAINER Frankie Fan \"hustakin@gmail.com\" ENV REFRESHED_AT 2019 -6-26 COPY kubectl /usr/local/bin/kubectl ENTRYPOINT [ \"jenkins-slave\" ]","title":"Dockerfile"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#jenkins-configurations","text":"","title":"Jenkins Configurations"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#configure-kubernetes","text":"Click Manage Jenkins->Configure System->Add a new cloud->Kubernetes. Test the connection and input namespace and Jenkins inner url by format ( . .svc.cluster.local:8080)","title":"Configure Kubernetes"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#configure-jenkins-slave-k8s-template","text":"Add pod template, and remember to clean the \"Command to run\" and \"Arguments to pass to the command\" (This's really important!). The image hustakin/jenkins-slave:latest has the kubectl version of v1.14.2","title":"Configure Jenkins Slave k8s template"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#configure-jenkins-slave-k8s-volumes","text":"Add volumes in the pod template including docker, .kube config files as well as the maven cache. (Each node of the cluster will cache the maven into /home/ec2-user/.m2)","title":"Configure Jenkins Slave k8s volumes"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#configure-service-account","text":"The service account is created in previous RBAC yaml step.","title":"Configure service account"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#configure-global-tool","text":"Click Manage Jenkins->Global Tool Configuration. Configure maven installations.","title":"Configure global tool"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#configure-nodejs-installations","text":"Click Manage Jenkins->Global Tool Configuration. Configure NodeJS installations.","title":"Configure NodeJS installations"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#configure-dockerhub-credentials","text":"Click Jenkins->Credentials->(global)->Add credentials. Specify your DockerHub username and password. Remember the ID here will be used in your Jenkinsfile to specify \"credentialsId\".","title":"Configure DockerHub credentials"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#configure-pipelines","text":"Write Dockerfile and Jenkinsfile and k8s.yaml in your project root folder and push it to GitHub. Create the repository in Dockerhub for your project in order to save docker built images.","title":"Configure Pipelines"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#jenkinsfile-content-for-springboot","text":"The Jenkinsfile content is as bellow node('jenkins-jnlp') { env.MVN_HOME = \"${tool 'Maven'}\" env.PATH=\"${env.MVN_HOME}/bin:${env.PATH}\" stage('Prepare') { echo \"1.Prepare Stage\" checkout scm script { build_tag = sh(returnStdout: true, script: 'git rev-parse --short HEAD').trim() if (env.BRANCH_NAME != 'master') { build_tag = \"${env.BRANCH_NAME}-${build_tag}\" } } } stage('Compile') { echo \"2.Compile SpringBoot App Stage\" sh \"mvn clean package -Dmaven.test.skip=true\" } stage('Build') { echo \"3.Build Docker Image Stage\" sh \"docker build -t hustakin/test:${build_tag} .\" } stage('Push') { echo \"4.Push Docker Image Stage\" withCredentials([usernamePassword(credentialsId: 'dockerHub', passwordVariable: 'dockerHubPassword', usernameVariable: 'dockerHubUser')]) { sh \"docker login -u ${dockerHubUser} -p ${dockerHubPassword}\" sh \"docker push hustakin/test:${build_tag}\" } } stage('Deploy') { echo \"5. Deploy To K8S Cluster Stage\" sh \"sed -i 's/<BUILD_TAG>/${build_tag}/' k8s.yaml\" sh \"sed -i 's/<BRANCH_NAME>/${env.BRANCH_NAME}/' k8s.yaml\" sh \"kubectl apply -f k8s.yaml --record\" } }","title":"Jenkinsfile content for SpringBoot"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#dockerfile-content-for-springboot","text":"The Dockerfile content is as bellow FROM openjdk:8-jre MAINTAINER Frankie Fan \"hustakin@gmail.com\" ENV REFRESHED_AT 2019 -7-3 VOLUME /tmp ADD web/target/test.jar test.jar ENTRYPOINT [ \"java\" , \"-XX:-BytecodeVerificationLocal\" , \"-XX:-BytecodeVerificationRemote\" , \"-XX:CICompilerCount=3\" , \"-XX:InitialHeapSize=268435456\" , \"-XX:+ManagementServer\" , \"-XX:MaxHeapSize=4263510016\" , \"-XX:MaxNewSize=2147483648\" , \"-XX:MinHeapDeltaBytes=524288\" , \"-XX:NewSize=89128960\" , \"-XX:OldSize=179306496\" , \"-XX:TieredStopAtLevel=1\" , \"-XX:+UseCompressedClassPointers\" , \"-XX:+UseCompressedOops\" , \"-XX:-UseLargePagesIndividualAllocation\" , \"-XX:+UseParallelGC\" , \"-Djava.security.egd=file:/dev/./urandom\" , \"-Dspring.profiles.active=dev\" , \"-jar\" , \"/test.jar\" ] EXPOSE 80 443","title":"Dockerfile content for SpringBoot"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#k8s-content-for-springboot","text":"The k8s.yaml content is as bellow kind : Deployment apiVersion : extensions/v1beta1 metadata : name : test-server namespace : agric spec : replicas : 2 minReadySeconds : 10 strategy : type : RollingUpdate rollingUpdate : maxUnavailable : 1 maxSurge : 1 template : metadata : labels : app : test-server spec : containers : - name : test-server image : hustakin/test:<BUILD_TAG> env : - name : branch value : <BRANCH_NAME> ports : - containerPort : 80 protocol : TCP name : web - containerPort : 443 protocol : TCP name : https # inventory probe readinessProbe : httpGet : path : /ready port : 80 initialDelaySeconds : 15 periodSeconds : 5 failureThreshold : 5 imagePullSecrets : - name : docker-hub","title":"K8s content for SpringBoot"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#jenkinsfile-content-for-angular","text":"The Jenkinsfile content is as bellow node('jenkins-jnlp') { env.NODEJS_HOME = \"${tool 'Node'}\" env.PATH=\"${env.NODEJS_HOME}/bin:${env.PATH}\" stage('Prepare') { echo \"1.Prepare Stage\" checkout scm script { build_tag = sh(returnStdout: true, script: 'git rev-parse --short HEAD').trim() if (env.BRANCH_NAME != 'master') { build_tag = \"${env.BRANCH_NAME}-${build_tag}\" } } } stage('Compile') { echo \"2.Compile Angular App Stage\" sh \"npm install\" sh \"npm install node-sass\" sh \"npm run prod\" } stage('Build') { echo \"3.Build Docker Image Stage\" sh \"docker build -t hustakin/test-front:${build_tag} .\" } stage('Push') { echo \"4.Push Docker Image Stage\" withCredentials([usernamePassword(credentialsId: 'dockerHub', passwordVariable: 'dockerHubPassword', usernameVariable: 'dockerHubUser')]) { sh \"docker login -u ${dockerHubUser} -p ${dockerHubPassword}\" sh \"docker push hustakin/test-front:${build_tag}\" } } stage('Deploy') { echo \"5. Deploy To K8S Cluster Stage\" sh \"sed -i 's/<BUILD_TAG>/${build_tag}/' k8s.yaml\" sh \"sed -i 's/<BRANCH_NAME>/${env.BRANCH_NAME}/' k8s.yaml\" sh \"kubectl apply -f k8s.yaml --record\" } }","title":"Jenkinsfile content for Angular"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#dockerfile-content-for-angular","text":"The Dockerfile content is as bellow FROM nginx:1.16.0 MAINTAINER Frankie Fan \"hustakin@gmail.com\" ENV REFRESHED_AT 2019 -6-5 COPY nginx/default.conf /etc/nginx/conf.d/ RUN rm -rf /usr/share/nginx/html/* COPY /dist /usr/share/nginx/html CMD [ \"nginx\" , \"-g\" , \"daemon off;\" ] EXPOSE 80","title":"Dockerfile content for Angular"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#nginx-conf-content-for-angular","text":"The nginx/default.conf content is as bellow. server { listen 80 ; sendfile on ; default_type application/octet-stream ; gzip on ; gzip_http_version 1 .1 ; gzip_disable \"MSIE [1-6]\\.\" ; gzip_min_length 256 ; gzip_vary on ; gzip_proxied expired no-cache no-store private auth ; gzip_types text/plain text/css application/json application/javascript application/x-javascript text/xml application/xml application/xml+rss text/javascript ; gzip_comp_level 9 ; root /usr/share/nginx/html ; location / { try_files $uri $uri/ /index.html = 404 ; } }","title":"Nginx conf content for Angular"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#k8s-content-for-angular","text":"The k8s.yaml content is as bellow kind : Deployment apiVersion : extensions/v1beta1 metadata : name : test-front-dev namespace : agric spec : replicas : 2 minReadySeconds : 10 strategy : type : RollingUpdate rollingUpdate : maxUnavailable : 1 maxSurge : 1 template : metadata : labels : app : test-front-dev spec : containers : - name : test-front-dev image : hustakin/test-front:<BUILD_TAG> env : - name : branch value : <BRANCH_NAME> ports : - containerPort : 80 protocol : TCP name : web - containerPort : 443 protocol : TCP name : https imagePullSecrets : - name : docker-hub","title":"K8s content for Angular"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#create-github-pipeline","text":"Click Jenkins->Open Blue Ocean->New Pipeline, and create pipeline for your project.","title":"Create Github Pipeline"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#create-github-pipeline_1","text":"The jenkins pipeline should work now. Enter your jenkins job and master branch, you could see the stage view here.","title":"Create Github Pipeline"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#trigger-pipeline","text":"Push your code changes to Github. Click Jenkins->Open Blue Ocean. You can trigger the build for all pipelines you created by clicking the Run button.","title":"Trigger pipeline"},{"location":"bestpractice/setup-jenkins-pipeline-in-kubernetes/#blue-ocean-build","text":"Click Jenkins->Open Blue Ocean, and click the pipeline you just created, you will see the Jenkinsfile stages and related logs here.","title":"Blue Ocean build"},{"location":"bestpractice/setup-vncserver-for-ubuntu/","text":"Install ubuntu-desktop and VNC server #Update the package sources sudo apt-get update sudo apt-get upgrade #Install ubuntu-desktop sudo apt-get install ubuntu-desktop #Install VNC server sudo apt-get install vnc4server #Install gnome tools sudo apt-get install gnome-core gnome-panel gnome-settings-daemon metacity nautilus gnome-terminal #Fix the vi direction/delete key not working issue sudo apt-get remove vim-common sudo apt-get install vim #Install net tools to test network sudo apt install net-tools netstat -tulpn Launch VNC server and set access password vncserver :1 #Telnet to test VNC server it's running telnet localhost 5901 Connecting to VNC From your Desktop Download and install the RealVNC Viewer on your laptop. Create a connection and specify your ubuntu address with the port 5901 and connect it, remember to input the password you just set. Connecting to VNC From your Desktop You may see the blank Gnome desktop after you connect to your VNC server. Fix the VNC grey screen issue You should modify the xstartup script to fix this issue. vi .vnc/xstartup xstartup content #!/bin/sh # Uncomment the following two lines for normal desktop: #unset SESSION_MANAGER #exec /etc/X11/xinit/xinitrc [ -x /etc/vnc/xstartup ] && exec /etc/vnc/xstartup [ -r $HOME /.Xresources ] && xrdb $HOME /.Xresources xsetroot -solid grey vncconfig -iconic -nowin & x-terminal-emulator -geometry 80x24+10+10 -ls -title \" $VNCDESKTOP Desktop\" & x-window-manager & #These are newly added commands export XKL_XMODMAP_DISABLE = 1 unset SESSION_MANAGER unset DBUS_SESSION_BUS_ADDRESS gnome-panel & gnmoe-settings-daemon & metacity & nautilus & gnome-terminal & Restart the VNC server after modification vncserver -kill :1 vncserver Connected to VNC From your Desktop Now you can connected to your VNC server desktop","title":"Using VNC to Operate a Desktop on Ubuntu 18.04"},{"location":"bestpractice/setup-vncserver-for-ubuntu/#install-ubuntu-desktop-and-vnc-server","text":"#Update the package sources sudo apt-get update sudo apt-get upgrade #Install ubuntu-desktop sudo apt-get install ubuntu-desktop #Install VNC server sudo apt-get install vnc4server #Install gnome tools sudo apt-get install gnome-core gnome-panel gnome-settings-daemon metacity nautilus gnome-terminal #Fix the vi direction/delete key not working issue sudo apt-get remove vim-common sudo apt-get install vim #Install net tools to test network sudo apt install net-tools netstat -tulpn","title":"Install ubuntu-desktop and VNC server"},{"location":"bestpractice/setup-vncserver-for-ubuntu/#launch-vnc-server-and-set-access-password","text":"vncserver :1 #Telnet to test VNC server it's running telnet localhost 5901","title":"Launch VNC server and set access password"},{"location":"bestpractice/setup-vncserver-for-ubuntu/#connecting-to-vnc-from-your-desktop","text":"Download and install the RealVNC Viewer on your laptop. Create a connection and specify your ubuntu address with the port 5901 and connect it, remember to input the password you just set.","title":"Connecting to VNC From your Desktop"},{"location":"bestpractice/setup-vncserver-for-ubuntu/#connecting-to-vnc-from-your-desktop_1","text":"You may see the blank Gnome desktop after you connect to your VNC server.","title":"Connecting to VNC From your Desktop"},{"location":"bestpractice/setup-vncserver-for-ubuntu/#fix-the-vnc-grey-screen-issue","text":"You should modify the xstartup script to fix this issue. vi .vnc/xstartup xstartup content #!/bin/sh # Uncomment the following two lines for normal desktop: #unset SESSION_MANAGER #exec /etc/X11/xinit/xinitrc [ -x /etc/vnc/xstartup ] && exec /etc/vnc/xstartup [ -r $HOME /.Xresources ] && xrdb $HOME /.Xresources xsetroot -solid grey vncconfig -iconic -nowin & x-terminal-emulator -geometry 80x24+10+10 -ls -title \" $VNCDESKTOP Desktop\" & x-window-manager & #These are newly added commands export XKL_XMODMAP_DISABLE = 1 unset SESSION_MANAGER unset DBUS_SESSION_BUS_ADDRESS gnome-panel & gnmoe-settings-daemon & metacity & nautilus & gnome-terminal &","title":"Fix the VNC grey screen issue"},{"location":"bestpractice/setup-vncserver-for-ubuntu/#restart-the-vnc-server-after-modification","text":"vncserver -kill :1 vncserver","title":"Restart the VNC server after modification"},{"location":"bestpractice/setup-vncserver-for-ubuntu/#connected-to-vnc-from-your-desktop","text":"Now you can connected to your VNC server desktop","title":"Connected to VNC From your Desktop"},{"location":"bestpractice/use-github-actions-to-build-multi-envs-ci/","text":"GitHub Actions Automate, customize, and execute your software development workflows right in your repository with GitHub Actions. You can discover, create, and share actions to perform any job you'd like, including CI/CD, and combine actions in a completely customized workflow. Prepare Docker Hub repository Create a repository in your Docker hub for this GitHub repository Docker image Create workflow in GitHub Actions Go to the Actions page of your GitHub repository, and create a whatever workflow you'd like. Write workflow and define env Use a branch dev to trigger the CI. Define the build args \"PROFILE\" or any other argument in the workflow and you will use it as the profile to run SpringBoot. Be noted that you should define the Docker Hub account and repository here. on : push : branches : - dev jobs : hello_world_job : runs-on : ubuntu-latest name : A job to build and push docker steps : - name : Checkout code uses : actions/checkout@v2 - name : Set up Docker Buildx uses : docker/setup-buildx-action@v1 - name : Login to DockerHub uses : docker/login-action@v1 with : username : ${{ secrets.DOCKER_HUB_USER }} password : ${{ secrets.DOCKER_HUB_PASS }} - name : Build and push uses : docker/build-push-action@v2 with : context : . file : ./Dockerfile pull : true push : true cache-from : type=registry,ref=hustakin/hello-world-docker-action:latest cache-to : type=inline tags : hustakin/hello-world-docker-action:latest build-args : PROFILE=nectar,ARG2=test Create secrets for the Github repository You should create the secrets DOCKER_HUB_USER (Docker Hub account) and DOCKER_HUB_PASS (Docker Hub password) as per you defined in the above workflow. Create Dockerfile Create a Dockerfile in the root folder of your project. You can specify the build argument in the Dockerfile and read it. You will see the Github Action workflow triggered after you push the code to the dev branch. See GitHub Actions workflow logs You will see the build argument PROFILE could be get in your Dockerfile. Write Dockerfile for SpringBoot The jar file of your SpringBoot project can be built by command: mvn clean package -Dmaven.test.skip=true. Write the Dockerfile to run your SpringBoot jar file. Please be noted you cannot read the ARG directly, but you can pass it to an env variable and read the variable instead. FROM openjdk:8-jre ARG PROFILE ENV PROFILE_VAR=$PROFILE VOLUME /tmp # Add the built jar for docker image building ADD target/hello-world-docker-action.jar hello-world-docker-action.jar ENTRYPOINT [\"/bin/bash\", \"-c\", \"java\",\"-Dspring.profiles.active=$PROFILE_VAR\",\"-jar\",\"/hello-world-docker-action.jar\"] # DO NOT USE(The variable would not be substituted) : ENTRYPOINT [\"java\",\"-Dspring.profiles.active=$PROFILE_VAR\",\"-jar\",\"/hello-world-docker-action.jar\"] # CAN ALSO USE: ENTRYPOINT java -Dspring.profiles.active=$PROFILE_VAR -jar /hello-world-docker-action.jar EXPOSE 80 Unlike the shell form, the exec form does not invoke a command shell. This means that normal shell processing does not happen. For example, ENTRYPOINT [ \"echo\", \"$HOME\" ] will not do variable substitution on $HOME. If you want shell processing then either use the shell form or execute a shell directly, for example: ENTRYPOINT [ \"sh\", \"-c\", \"echo $HOME\" ]. When using the exec form and executing a shell directly, as in the case for the shell form, it is the shell that is doing the environment variable expansion, not docker. Another way to pass variables There is another way to pass variables if the above way doesn't work. You can put the command into a script file and add the shell as entrypoint. FROM openjdk:8-jre ARG PROFILE ENV PROFILE_VAR=$PROFILE VOLUME /tmp # Add the built jar for docker image building ADD target/hello-world-docker-action.jar hello-world-docker-action.jar # Build a shell script because the ENTRYPOINT command doesn't like using ENV RUN echo \"#!/bin/bash \\n java -Dspring.profiles.active=${PROFILE_VAR} -jar /hello-world-docker-action.jar\" > ./entrypoint.sh RUN chmod +x ./entrypoint.sh # Run the generated shell script. ENTRYPOINT [\"./entrypoint.sh\"] EXPOSE 80 Write workflow to build jar Add a step to run the maven building command in order to get the above jar file. on : push : branches : - dev jobs : hello_world_job : runs-on : ubuntu-latest name : A job to build and push docker steps : - name : Checkout code uses : actions/checkout@v2 - name : Set up JDK 1.8 uses : actions/setup-java@v1 with : java-version : 1.8 - name : Build with Maven run : mvn clean package -Dmaven.test.skip=true - name : Set up Docker Buildx uses : docker/setup-buildx-action@v1 - name : Login to DockerHub uses : docker/login-action@v1 with : username : ${{ secrets.DOCKER_HUB_USER }} password : ${{ secrets.DOCKER_HUB_PASS }} - name : Build and push uses : docker/build-push-action@v2 with : context : . file : ./Dockerfile pull : true push : true cache-from : type=registry,ref=hustakin/hello-world-docker-action:latest cache-to : type=inline tags : hustakin/hello-world-docker-action:latest build-args : PROFILE=nectar,ARG2=test Add more workflow for other branches Add another branch for another environment. Each workflow yml -> Specific trigger branch -> Specify each profile value for the env -> Run the specific profile SpringBoot application. Take another trigger branch and env \"amazon\" for example: Manually/Automatically run docker container creating scripts In development mode, when you want to build a specific env you could push the code to the related trigger branch to let workflow run. After the workflow finish, you can manually run a shell script in the specific env to build docker container from the latest docker image in Docker Hub. You could also add a WebHook in your workflow or in your Docker Hub to trigger the automatic building scripts for specific env. Angular profiles passing Regarding Angular project, you will need to add env profiles in the \"configurations\" node of the angular.json, and add commands of different envs in your package.json. Now you could create workflows for all your env and execute different npm command to build. In your Angular app, you could import the environment and read the settings inside it. Add a workflow status badge You can display a status badge in your repository to indicate the status of your workflows. A status badge shows whether a workflow is currently failing or passing. A common place to add a status badge is in the README.md file of your repository, but you can add it to any web page you'd like. By default, badges display the status of your default branch. You can also display the status of a workflow run for a specific branch or event using the branch and event query parameters in the URL. ![Workflow status](https://github.com/<OWNER>/<REPOSITORY>/workflows/<WORKFLOW_NAME>/badge.svg)","title":"Setup CI in Github Actions for multiple environments regarding SpringBoot or Angular"},{"location":"bestpractice/use-github-actions-to-build-multi-envs-ci/#github-actions","text":"Automate, customize, and execute your software development workflows right in your repository with GitHub Actions. You can discover, create, and share actions to perform any job you'd like, including CI/CD, and combine actions in a completely customized workflow.","title":"GitHub Actions"},{"location":"bestpractice/use-github-actions-to-build-multi-envs-ci/#prepare-docker-hub-repository","text":"Create a repository in your Docker hub for this GitHub repository Docker image","title":"Prepare Docker Hub repository"},{"location":"bestpractice/use-github-actions-to-build-multi-envs-ci/#create-workflow-in-github-actions","text":"Go to the Actions page of your GitHub repository, and create a whatever workflow you'd like.","title":"Create workflow in GitHub Actions"},{"location":"bestpractice/use-github-actions-to-build-multi-envs-ci/#write-workflow-and-define-env","text":"Use a branch dev to trigger the CI. Define the build args \"PROFILE\" or any other argument in the workflow and you will use it as the profile to run SpringBoot. Be noted that you should define the Docker Hub account and repository here. on : push : branches : - dev jobs : hello_world_job : runs-on : ubuntu-latest name : A job to build and push docker steps : - name : Checkout code uses : actions/checkout@v2 - name : Set up Docker Buildx uses : docker/setup-buildx-action@v1 - name : Login to DockerHub uses : docker/login-action@v1 with : username : ${{ secrets.DOCKER_HUB_USER }} password : ${{ secrets.DOCKER_HUB_PASS }} - name : Build and push uses : docker/build-push-action@v2 with : context : . file : ./Dockerfile pull : true push : true cache-from : type=registry,ref=hustakin/hello-world-docker-action:latest cache-to : type=inline tags : hustakin/hello-world-docker-action:latest build-args : PROFILE=nectar,ARG2=test","title":"Write workflow and define env"},{"location":"bestpractice/use-github-actions-to-build-multi-envs-ci/#create-secrets-for-the-github-repository","text":"You should create the secrets DOCKER_HUB_USER (Docker Hub account) and DOCKER_HUB_PASS (Docker Hub password) as per you defined in the above workflow.","title":"Create secrets for the Github repository"},{"location":"bestpractice/use-github-actions-to-build-multi-envs-ci/#create-dockerfile","text":"Create a Dockerfile in the root folder of your project. You can specify the build argument in the Dockerfile and read it. You will see the Github Action workflow triggered after you push the code to the dev branch.","title":"Create Dockerfile"},{"location":"bestpractice/use-github-actions-to-build-multi-envs-ci/#see-github-actions-workflow-logs","text":"You will see the build argument PROFILE could be get in your Dockerfile.","title":"See GitHub Actions workflow logs"},{"location":"bestpractice/use-github-actions-to-build-multi-envs-ci/#write-dockerfile-for-springboot","text":"The jar file of your SpringBoot project can be built by command: mvn clean package -Dmaven.test.skip=true. Write the Dockerfile to run your SpringBoot jar file. Please be noted you cannot read the ARG directly, but you can pass it to an env variable and read the variable instead. FROM openjdk:8-jre ARG PROFILE ENV PROFILE_VAR=$PROFILE VOLUME /tmp # Add the built jar for docker image building ADD target/hello-world-docker-action.jar hello-world-docker-action.jar ENTRYPOINT [\"/bin/bash\", \"-c\", \"java\",\"-Dspring.profiles.active=$PROFILE_VAR\",\"-jar\",\"/hello-world-docker-action.jar\"] # DO NOT USE(The variable would not be substituted) : ENTRYPOINT [\"java\",\"-Dspring.profiles.active=$PROFILE_VAR\",\"-jar\",\"/hello-world-docker-action.jar\"] # CAN ALSO USE: ENTRYPOINT java -Dspring.profiles.active=$PROFILE_VAR -jar /hello-world-docker-action.jar EXPOSE 80 Unlike the shell form, the exec form does not invoke a command shell. This means that normal shell processing does not happen. For example, ENTRYPOINT [ \"echo\", \"$HOME\" ] will not do variable substitution on $HOME. If you want shell processing then either use the shell form or execute a shell directly, for example: ENTRYPOINT [ \"sh\", \"-c\", \"echo $HOME\" ]. When using the exec form and executing a shell directly, as in the case for the shell form, it is the shell that is doing the environment variable expansion, not docker.","title":"Write Dockerfile for SpringBoot"},{"location":"bestpractice/use-github-actions-to-build-multi-envs-ci/#another-way-to-pass-variables","text":"There is another way to pass variables if the above way doesn't work. You can put the command into a script file and add the shell as entrypoint. FROM openjdk:8-jre ARG PROFILE ENV PROFILE_VAR=$PROFILE VOLUME /tmp # Add the built jar for docker image building ADD target/hello-world-docker-action.jar hello-world-docker-action.jar # Build a shell script because the ENTRYPOINT command doesn't like using ENV RUN echo \"#!/bin/bash \\n java -Dspring.profiles.active=${PROFILE_VAR} -jar /hello-world-docker-action.jar\" > ./entrypoint.sh RUN chmod +x ./entrypoint.sh # Run the generated shell script. ENTRYPOINT [\"./entrypoint.sh\"] EXPOSE 80","title":"Another way to pass variables"},{"location":"bestpractice/use-github-actions-to-build-multi-envs-ci/#write-workflow-to-build-jar","text":"Add a step to run the maven building command in order to get the above jar file. on : push : branches : - dev jobs : hello_world_job : runs-on : ubuntu-latest name : A job to build and push docker steps : - name : Checkout code uses : actions/checkout@v2 - name : Set up JDK 1.8 uses : actions/setup-java@v1 with : java-version : 1.8 - name : Build with Maven run : mvn clean package -Dmaven.test.skip=true - name : Set up Docker Buildx uses : docker/setup-buildx-action@v1 - name : Login to DockerHub uses : docker/login-action@v1 with : username : ${{ secrets.DOCKER_HUB_USER }} password : ${{ secrets.DOCKER_HUB_PASS }} - name : Build and push uses : docker/build-push-action@v2 with : context : . file : ./Dockerfile pull : true push : true cache-from : type=registry,ref=hustakin/hello-world-docker-action:latest cache-to : type=inline tags : hustakin/hello-world-docker-action:latest build-args : PROFILE=nectar,ARG2=test","title":"Write workflow to build jar"},{"location":"bestpractice/use-github-actions-to-build-multi-envs-ci/#add-more-workflow-for-other-branches","text":"Add another branch for another environment. Each workflow yml -> Specific trigger branch -> Specify each profile value for the env -> Run the specific profile SpringBoot application. Take another trigger branch and env \"amazon\" for example:","title":"Add more workflow for other branches"},{"location":"bestpractice/use-github-actions-to-build-multi-envs-ci/#manuallyautomatically-run-docker-container-creating-scripts","text":"In development mode, when you want to build a specific env you could push the code to the related trigger branch to let workflow run. After the workflow finish, you can manually run a shell script in the specific env to build docker container from the latest docker image in Docker Hub. You could also add a WebHook in your workflow or in your Docker Hub to trigger the automatic building scripts for specific env.","title":"Manually/Automatically run docker container creating scripts"},{"location":"bestpractice/use-github-actions-to-build-multi-envs-ci/#angular-profiles-passing","text":"Regarding Angular project, you will need to add env profiles in the \"configurations\" node of the angular.json, and add commands of different envs in your package.json. Now you could create workflows for all your env and execute different npm command to build. In your Angular app, you could import the environment and read the settings inside it.","title":"Angular profiles passing"},{"location":"bestpractice/use-github-actions-to-build-multi-envs-ci/#add-a-workflow-status-badge","text":"You can display a status badge in your repository to indicate the status of your workflows. A status badge shows whether a workflow is currently failing or passing. A common place to add a status badge is in the README.md file of your repository, but you can add it to any web page you'd like. By default, badges display the status of your default branch. You can also display the status of a workflow run for a specific branch or event using the branch and event query parameters in the URL. ![Workflow status](https://github.com/<OWNER>/<REPOSITORY>/workflows/<WORKFLOW_NAME>/badge.svg)","title":"Add a workflow status badge"},{"location":"devops/amazon-ec2-101/","text":"Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud. It is designed to make web-scale cloud computing easier for developers. Create new instance and prepare the env EC2-Launch Instance, select ubuntu, select general purpose t2.medium, select security group, select ssh key, don't select \"Delete on Termination\" for volume. Import SSH key into local system. chmod 400 aws.pem ssh-add aws.pem SSH to the ec2 instance when it's ready. ssh ubuntu@134.216.31.161 Install docker and add current user to docker group and docker login, and install docker-compose. sudo curl -sSL https://get.docker.com/ | sh sudo groupadd docker sudo usermod -aG docker $USER sudo docker login sudo curl -L https://github.com/docker/compose/releases/download/1.20.0/docker-compose- ` uname -s ` - ` uname -m ` -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose docker-compose --version Run ftp container. sudo docker run -d -v /upload:/home/vsftpd \\ -p 20 :20 -p 21 :21 -p 40000 -40080:40000-40080 \\ -e FTP_USER = user -e FTP_PASS = pass \\ -e PASV_ADDRESS = 134 .216.31.161 -e PASV_MIN_PORT = 40000 -e PASV_MAX_PORT = 40080 \\ --name vsftpd --restart = always fauria/vsftpd Mount jenkins_home backup to the /data volume, and run jenkins container. sudo docker run --name jenkins -p 8080 :8080 -p 50000 :50000 -v /data/jenkins_home:/var/jenkins_home -d jenkins Modify backup jenkins_home permission if needed. sudo chmod -R 777 jenkins_home sudo docker restart jenkins Modify ~/docker folder owner to ubuntu which is the default root username. sudo chmod -R ubuntu:ubuntu ~/docker Modify timezone to brisbane. date -R sudo tzselect append the content to ~/.profile: TZ = 'Australia/Brisbane' ; export TZ sudo hwclock --systohc Add cron auto mongoDB backup task. sudo service cron start sudo crontab -l copy the mongobk.sh to ~ folder crontab -e //add the content into it: 0 2 * * * sudo bash ~/mongobk.sh sudo service cron reload #The mongobk.sh content is as bellow #!/bin/bash #Backup mongodb database and compress them #add cron task in linux: 0 2 * * * \"sudo bash ~/mongobk.sh\" DATE = ` date +%Y-%m-%d ` DAYS = 15 OUT_DIR = /data/dump/backup TAR_DIR = /data/dump/backup_list TAR_BAK = \"mongod_bak_ $DATE .tar.gz\" rm -rf $OUT_DIR /* mkdir -p $OUT_DIR / $DATE mkdir -p $TAR_DIR mongodump -h localhost:27017 -d develop -o $OUT_DIR / $DATE -u user -p pass tar -zcvf $TAR_DIR / $TAR_BAK $OUT_DIR / $DATE #tar -zxvf *.tar.gz # delete backup 15 days ago find $TAR_DIR / -mtime + $DAYS -delete exit #The mongobk.sh content end Backup and restore root volume See the link for detail: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-using-volumes.html. 1. Backup volume: Create a snapshot for the root volume. 2. Launch a new ec2 instance, after it's ready go to volumes page and add a new volume from the snapshot. 3. See disk devices and mount points of them. lsblk #NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT #xvda 202:0 0 8G 0 disk #|-xvda1 202:1 0 8G 0 part / #xvdf 202:80 0 8G 0 disk #|-xvdf1 202:81 0 8G 0 part 4. Mount the new volume as the root volume, and see the result. sudo mount /dev/xvdf1 / lsblk #NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT #xvda 202:0 0 8G 0 disk #|-xvda1 202:1 0 8G 0 part / #xvdf 202:80 0 8G 0 disk #|-xvdf1 202:81 0 8G 0 part / 5. Reboot the instance, remember to remove the local known_hosts record if needed. 6. See devices and mount points. lsblk #NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT #xvda 202:0 0 8G 0 disk #|-xvda1 202:1 0 8G 0 part #xvdf 202:80 0 8G 0 disk #|-xvdf1 202:81 0 8G 0 part / 7. If the above operations don't work, try the bellow operations. * Stop the instance, detach the old volume and attach the new volume as /dev/sda1, then start the instance, it should work. * Maybe because the system is from different series. You have to mount the volume to a folder, then copy the data folder to local and restore all applications. * Make a snapshot for the volume, and create a new instance from template, add an additional disk with the snapshot selected. Extend the volume size of an instance EC2-volumes, modify the volume and enlarge current size. See the disk devices status. lsblk #NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT #xvda 202:0 0 16G 0 disk #|-xvda1 202:1 0 8G 0 part / See current effective disk status. df -h #Filesystem Size Used Avail Use% Mounted on #udev 2.0G 0 2.0G 0% /dev #tmpfs 396M 5.6M 390M 2% /run #/dev/xvda1 7.7G 7.7G 184K 100% / Extend the volume and see: sudo growpart /dev/xvda 1 (xvda1 in lsblk result means change the partition 1 here). sudo growpart /dev/xvda 1 #CHANGED: partition=1 start=2048 old: size=16775135 end=16777183 new: size=33552351,end=33554399 lsblk #NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT #xvda 202:0 0 16G 0 disk #|-xvda1 202:1 0 16G 0 part / Extend the disk and see. sudo resize2fs /dev/xvda1 #resize2fs 1.42.13 (17-May-2015) #Filesystem at /dev/xvda1 is mounted on /; on-line resizing required #old_desc_blocks = 1, new_desc_blocks = 1 #The filesystem on /dev/xvda1 is now 4194043 (4k) blocks long. df -h #Filesystem Size Used Avail Use% Mounted on #udev 2.0G 0 2.0G 0% /dev #tmpfs 396M 5.6M 390M 2% /run #/dev/xvda1 16G 7.7G 7.8G 50% /","title":"Amazon EC2 101"},{"location":"devops/amazon-ec2-101/#create-new-instance-and-prepare-the-env","text":"EC2-Launch Instance, select ubuntu, select general purpose t2.medium, select security group, select ssh key, don't select \"Delete on Termination\" for volume. Import SSH key into local system. chmod 400 aws.pem ssh-add aws.pem SSH to the ec2 instance when it's ready. ssh ubuntu@134.216.31.161 Install docker and add current user to docker group and docker login, and install docker-compose. sudo curl -sSL https://get.docker.com/ | sh sudo groupadd docker sudo usermod -aG docker $USER sudo docker login sudo curl -L https://github.com/docker/compose/releases/download/1.20.0/docker-compose- ` uname -s ` - ` uname -m ` -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose docker-compose --version Run ftp container. sudo docker run -d -v /upload:/home/vsftpd \\ -p 20 :20 -p 21 :21 -p 40000 -40080:40000-40080 \\ -e FTP_USER = user -e FTP_PASS = pass \\ -e PASV_ADDRESS = 134 .216.31.161 -e PASV_MIN_PORT = 40000 -e PASV_MAX_PORT = 40080 \\ --name vsftpd --restart = always fauria/vsftpd Mount jenkins_home backup to the /data volume, and run jenkins container. sudo docker run --name jenkins -p 8080 :8080 -p 50000 :50000 -v /data/jenkins_home:/var/jenkins_home -d jenkins Modify backup jenkins_home permission if needed. sudo chmod -R 777 jenkins_home sudo docker restart jenkins Modify ~/docker folder owner to ubuntu which is the default root username. sudo chmod -R ubuntu:ubuntu ~/docker Modify timezone to brisbane. date -R sudo tzselect append the content to ~/.profile: TZ = 'Australia/Brisbane' ; export TZ sudo hwclock --systohc Add cron auto mongoDB backup task. sudo service cron start sudo crontab -l copy the mongobk.sh to ~ folder crontab -e //add the content into it: 0 2 * * * sudo bash ~/mongobk.sh sudo service cron reload #The mongobk.sh content is as bellow #!/bin/bash #Backup mongodb database and compress them #add cron task in linux: 0 2 * * * \"sudo bash ~/mongobk.sh\" DATE = ` date +%Y-%m-%d ` DAYS = 15 OUT_DIR = /data/dump/backup TAR_DIR = /data/dump/backup_list TAR_BAK = \"mongod_bak_ $DATE .tar.gz\" rm -rf $OUT_DIR /* mkdir -p $OUT_DIR / $DATE mkdir -p $TAR_DIR mongodump -h localhost:27017 -d develop -o $OUT_DIR / $DATE -u user -p pass tar -zcvf $TAR_DIR / $TAR_BAK $OUT_DIR / $DATE #tar -zxvf *.tar.gz # delete backup 15 days ago find $TAR_DIR / -mtime + $DAYS -delete exit #The mongobk.sh content end","title":"Create new instance and prepare the env"},{"location":"devops/amazon-ec2-101/#backup-and-restore-root-volume","text":"See the link for detail: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-using-volumes.html. 1. Backup volume: Create a snapshot for the root volume. 2. Launch a new ec2 instance, after it's ready go to volumes page and add a new volume from the snapshot. 3. See disk devices and mount points of them. lsblk #NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT #xvda 202:0 0 8G 0 disk #|-xvda1 202:1 0 8G 0 part / #xvdf 202:80 0 8G 0 disk #|-xvdf1 202:81 0 8G 0 part 4. Mount the new volume as the root volume, and see the result. sudo mount /dev/xvdf1 / lsblk #NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT #xvda 202:0 0 8G 0 disk #|-xvda1 202:1 0 8G 0 part / #xvdf 202:80 0 8G 0 disk #|-xvdf1 202:81 0 8G 0 part / 5. Reboot the instance, remember to remove the local known_hosts record if needed. 6. See devices and mount points. lsblk #NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT #xvda 202:0 0 8G 0 disk #|-xvda1 202:1 0 8G 0 part #xvdf 202:80 0 8G 0 disk #|-xvdf1 202:81 0 8G 0 part / 7. If the above operations don't work, try the bellow operations. * Stop the instance, detach the old volume and attach the new volume as /dev/sda1, then start the instance, it should work. * Maybe because the system is from different series. You have to mount the volume to a folder, then copy the data folder to local and restore all applications. * Make a snapshot for the volume, and create a new instance from template, add an additional disk with the snapshot selected.","title":"Backup and restore root volume"},{"location":"devops/amazon-ec2-101/#extend-the-volume-size-of-an-instance","text":"EC2-volumes, modify the volume and enlarge current size. See the disk devices status. lsblk #NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT #xvda 202:0 0 16G 0 disk #|-xvda1 202:1 0 8G 0 part / See current effective disk status. df -h #Filesystem Size Used Avail Use% Mounted on #udev 2.0G 0 2.0G 0% /dev #tmpfs 396M 5.6M 390M 2% /run #/dev/xvda1 7.7G 7.7G 184K 100% / Extend the volume and see: sudo growpart /dev/xvda 1 (xvda1 in lsblk result means change the partition 1 here). sudo growpart /dev/xvda 1 #CHANGED: partition=1 start=2048 old: size=16775135 end=16777183 new: size=33552351,end=33554399 lsblk #NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT #xvda 202:0 0 16G 0 disk #|-xvda1 202:1 0 16G 0 part / Extend the disk and see. sudo resize2fs /dev/xvda1 #resize2fs 1.42.13 (17-May-2015) #Filesystem at /dev/xvda1 is mounted on /; on-line resizing required #old_desc_blocks = 1, new_desc_blocks = 1 #The filesystem on /dev/xvda1 is now 4194043 (4k) blocks long. df -h #Filesystem Size Used Avail Use% Mounted on #udev 2.0G 0 2.0G 0% /dev #tmpfs 396M 5.6M 390M 2% /run #/dev/xvda1 16G 7.7G 7.8G 50% /","title":"Extend the volume size of an instance"},{"location":"devops/getting-started-with-kubernetes/","text":"Kubernetes (K8s) is an open-source system for automating deployment, scaling, and management of containerized applications. It groups containers that make up an application into logical units for easy management and discovery. Kubernetes builds upon 15 years of experience of running production workloads at Google, combined with best-of-breed ideas and practices from the community. Install on linux cluster Compile kubernetes git clone https://github.com/kubernetes/kubernetes.git cd kubernetes make release Install master node #Add repos cat <<EOF > /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kube* EOF #Set SELinux in permissive mode (effectively disabling it) setenforce 0 sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config #Install yum install -y kubelet kubeadm kubectl --disableexcludes = kubernetes systemctl enable --now kubelet cat <<EOF > /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sysctl --system #Install network plugin sudo kubeadm init --pod-network-cidr = 192 .168.0.0/16 kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/rbac-kdd.yamlrm kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml #Copy kubernetes config to user folder mkdir -p $HOME /.kube sudo cp -i /etc/kubernetes/admin.conf $HOME /.kube/config sudo chown $( id -u ) : $( id -g ) $HOME /.kube/config Install slave node #Run on master node to get the join commands sudo kubeadm token create --print-join-command #Copy the join commands and run on slave node kubeadm join <master-ip>:6443 --token 2kjo2d.8qno0vzvbgabp1e8 --discovery-token-ca-cert-hash sha256:2f1ebea7d7369a2d18b58f2926573e193e13ef7525649df1740ddb87963e1315 Install metrics server git clone https://github.com/kodekloudhub/kubernetes-metrics-server.git kubectl create -f kubernetes-metrics-server/ kubectl top nodes kubectl top pods Install prometheus kubectl apply --filename https://raw.githubusercontent.com/giantswarm/kubernetes-prometheus/master/manifests-all.yaml #Maybe you should download the manifests-all.yaml and customize it yourself. For example, you would add Grafana configuration in it. #Create Traefik ingress yaml and apply Install helm #Download helm tar.gz file from https://github.com/helm/helm/releases tar -zxvf helm-v2.14.1-linux-amd64.tar.gz sudo cp linux-amd64/helm /usr/local/bin helm init helm version kubectl get pod -n kube-system -l app = helm kubectl create -f rbac.yml kubectl patch deploy --namespace kube-system tiller-deploy -p '{\"spec\":{\"template\":{\"spec\":{\"serviceAccount\":\"tiller\"}}}}' Traefik Create Traefik toml defaultEntryPoints = [\"http\",\"https\"] # Enable inner-cluster https navigation insecureSkipVerify = true [entryPoints] [entryPoints.http] address = \":80\" [entryPoints.http.redirect] entryPoint = \"https\" [entryPoints.https] address = \":443\" [entryPoints.https.tls] [[entryPoints.https.tls.certificates]] certFile = \"/etc/kubernetes/ssl/cert.pem\" keyFile = \"/etc/kubernetes/ssl/privkey.pem\" [metrics] [metrics.prometheus] entryPoint = \"traefik\" buckets = [0.1, 0.3, 1.2, 5.0] Create Traefik yaml kind : Deployment apiVersion : extensions/v1beta1 metadata : name : traefik-ingress-controller namespace : kube-system labels : k8s-app : traefik-ingress-lb spec : replicas : 1 selector : matchLabels : k8s-app : traefik-ingress-lb template : metadata : labels : k8s-app : traefik-ingress-lb name : traefik-ingress-lb spec : serviceAccountName : traefik-ingress-controller terminationGracePeriodSeconds : 60 tolerations : - operator : \"Exists\" nodeSelector : node : master volumes : - name : ssl secret : secretName : traefik-cert - name : config configMap : name : traefik-conf containers : - image : traefik name : traefik-ingress-lb volumeMounts : - mountPath : \"/etc/kubernetes/ssl\" name : \"ssl\" - mountPath : \"/home/ec2-user/kube/traefik\" name : \"config\" ports : - name : http containerPort : 80 hostPort : 80 - name : https containerPort : 443 hostPort : 443 - name : admin containerPort : 8080 args : - --api - --kubernetes - --logLevel=INFO - --configfile=/home/ec2-user/kube/traefik/traefik.toml --- kind : Service apiVersion : v1 metadata : name : traefik-ingress-service namespace : kube-system spec : selector : k8s-app : traefik-ingress-lb ports : - protocol : TCP port : 80 name : web - protocol : TCP port : 443 name : https - protocol : TCP port : 8080 name : admin type : NodePort Create Traefik rbac apiVersion : v1 kind : ServiceAccount metadata : name : traefik-ingress-controller namespace : kube-system --- kind : ClusterRole apiVersion : rbac.authorization.k8s.io/v1beta1 metadata : name : traefik-ingress-controller rules : - apiGroups : - \"\" resources : - services - endpoints - secrets verbs : - get - list - watch - apiGroups : - extensions resources : - ingresses verbs : - get - list - watch --- kind : ClusterRoleBinding apiVersion : rbac.authorization.k8s.io/v1beta1 metadata : name : traefik-ingress-controller roleRef : apiGroup : rbac.authorization.k8s.io kind : ClusterRole name : traefik-ingress-controller subjects : - kind : ServiceAccount name : traefik-ingress-controller namespace : kube-system Create Traefik web-ui ingress apiVersion : extensions/v1beta1 kind : Ingress metadata : name : traefik-web-ui namespace : kube-system annotations : kubernetes.io/ingress.class : traefik spec : rules : - host : [ domain ] http : paths : - backend : serviceName : traefik-ingress-service servicePort : 8080 Create Traefik HTTPS cert sudo -s cd /etc/letsencrypt/live/ [ domain ] #Update https cert keys and go to domain management console to modify the txt record kubectl create secret generic traefik-cert --from-file = privkey.pem --from-file = cert.pem -n kube-system cp cert.pem privkey.pem /etc/kubernetes/ssl/ #exit and go to the traefik k8s scripts folder kubectl create configmap traefik-conf --from-file = traefik.toml -n kube-system kubectl get cm -n kube-system Renew Traefik HTTPS cert kubectl delete secret traefik-cert -n kube-system kubectl delete configmap traefik-conf -n kube-system kubectl delete -f traefik.yml #Re-run the above \"Create Traefik HTTPS cert\" steps kubectl create -f traefik.yml Update Traefik.toml #Firstly modify the traefik.toml kubectl delete configmap traefik-conf -n kube-system kubectl create configmap traefik-conf --from-file = traefik.toml -n kube-system kubectl delete -f traefik.yml kubectl create -f traefik.yml Kubernetes Dashboard for local Create service account #admin-user.yaml apiVersion : v1 kind : ServiceAccount metadata : name : admin-user namespace : kube-system Create role binding #admin-user-role-binding.yaml apiVersion : rbac.authorization.k8s.io/v1beta1 kind : ClusterRoleBinding metadata : name : admin-user roleRef : apiGroup : rbac.authorization.k8s.io kind : ClusterRole name : cluster-admin subjects : - kind : ServiceAccount name : admin-user namespace : kube-system Apply yaml #Apply service account kubectl create -f admin-user.yaml #Apply role binding kubectl create -f admin-user-role-binding.yaml Retrieve login token kubectl -n kube-system describe secret $( kubectl -n kube-system get secret | grep admin-user | awk '{print $1}' ) Install dashboard kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended/kubernetes-dashboard.yaml #Create proxy to allow only localhost navigating kubectl proxy kubectl proxy --address = '0.0.0.0' --accept-hosts = '^*$' Kubernetes Dashboard for public Create certificates mkdir $HOME /certs cd $HOME /certs openssl genrsa -out dashboard.key 2048 openssl rsa -in dashboard.key -out dashboard.key openssl req -sha256 -new -key dashboard.key -out dashboard.csr -subj '/CN=localhost' openssl x509 -req -sha256 -days 365 -in dashboard.csr -signkey dashboard.key -out dashboard.crt kubectl -n kube-system create secret generic kubernetes-dashboard-certs --from-file = $HOME /certs Install dashboard kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml #Wait and check if the replica set is fulfilled kubectl -n kube-system get rs Create PSP kubectl -n kube-system create -f - <<EOF apiVersion: extensions/v1beta1 kind: PodSecurityPolicy metadata: name: dashboard spec: privileged: false seLinux: rule: RunAsAny supplementalGroups: rule: RunAsAny runAsUser: rule: RunAsAny fsGroup: rule: RunAsAny volumes: - '*' EOF Create role kubectl -n kube-system create role psp:dashboard --verb = use --resource = podsecuritypolicy --resource-name = dashboard Bind role and account kubectl -n kube-system create rolebinding kubernetes-dashboard-policy --role = psp:dashboard --serviceaccount = kube-system:kubernetes-dashboard kubectl --as = system:serviceaccount:kube-system:kubernetes-dashboard -n kube-system auth can-i use podsecuritypolicy/dashboard Expose service on NodePort #Edit the kubernetes-dashboard service and change the following options: # spec.type from ClusterIP to NodePort * spec.ports [ 0 ] .nodePort from 32641 to whatever port you want it to be exposed on kubectl -n kube-system edit service kubernetes-dashboard kubectl -n kube-system get services Navigate the dashboard publicly #Configure the dns in the domain provider console https:// [ domain ] :30104/ Expose Traefik ingress apiVersion : extensions/v1beta1 kind : Ingress metadata : name : dashboard-ingress namespace : kube-system spec : rules : - host : [ domain ] http : paths : - path : / backend : serviceName : kubernetes-dashboard servicePort : 443 Scenarios Run a busybox container kubectl run -i --tty --image busybox test --restart = Never --rm /bin/sh User docker hub secret in pods #docker login and get the file: ~/.docker/config.json docker login kubectl create secret generic docker-hub --from-file = .dockerconfigjson = ~/.docker/config.json --type = kubernetes.io/dockerconfigjson --namespace = test #Create a Pod that uses the Secret like bellow kind: Deployment apiVersion: extensions/v1beta1 metadata: name: test-server namespace: test spec: replicas: 2 template: metadata: labels: app: test-server spec: containers: - name: test-server image: demo/test-server imagePullSecrets: - name: docker-hub Default storage class apiVersion : storage.k8s.io/v1 kind : StorageClass metadata : name : standard provisioner : kubernetes.io/aws-ebs parameters : type : gp2 reclaimPolicy : Retain mountOptions : - debug volumeBindingMode : Immediate Create MongoDB with two DB auth settings kind : Deployment apiVersion : extensions/v1beta1 metadata : name : dev-mongodb namespace : test spec : replicas : 1 template : metadata : labels : app : dev-mongodb spec : hostname : mongodb containers : - name : dev-mongodb image : hustakin/mongo-auth2:latest env : - name : MONGODB_ADMIN_USER value : admin - name : MONGODB_ADMIN_PASS value : 111 - name : MONGODB_APP1_DATABASE value : db1 - name : MONGODB_APP1_USER value : user1 - name : MONGODB_APP1_PASS value : pass1 - name : MONGODB_APP2_DATABASE value : db2 - name : MONGODB_APP2_USER value : user2 - name : MONGODB_APP2_PASS value : pass2 ports : - containerPort : 27017 protocol : TCP name : db volumeMounts : - mountPath : /data/db name : dev-mongo-persistent-storage livenessProbe : exec : command : - mongo - --eval - \"db.adminCommand('ping')\" failureThreshold : 3 periodSeconds : 10 successThreshold : 1 timeoutSeconds : 5 readinessProbe : exec : command : - mongo - --eval - \"db.adminCommand('ping')\" failureThreshold : 3 periodSeconds : 10 successThreshold : 1 timeoutSeconds : 1 imagePullSecrets : - name : docker-hub volumes : - name : dev-mongo-persistent-storage persistentVolumeClaim : claimName : dev-local-data-pvc --- kind : Service apiVersion : v1 metadata : labels : app : mongodb name : mongodb namespace : test annotations : traefik.ingress.kubernetes.io/affinity : \"true\" traefik.ingress.kubernetes.io/session-cookie-name : \"sticky\" spec : type : ClusterIP ports : - protocol : TCP port : 27017 name : db selector : app : dev-mongodb --- apiVersion : v1 kind : PersistentVolume metadata : name : dev-local-data-pv spec : capacity : storage : 50Gi accessModes : - ReadWriteOnce persistentVolumeReclaimPolicy : Retain storageClassName : local-storage local : path : /mnt/data nodeAffinity : required : nodeSelectorTerms : - matchExpressions : - key : node operator : In values : - db --- kind : PersistentVolumeClaim apiVersion : v1 metadata : name : dev-local-data-pvc namespace : test spec : accessModes : - ReadWriteOnce storageClassName : local-storage resources : requests : storage : 50Gi Useful commands Scenarios Commands Create or update 1. kubectl create -f pod.yml 2. kubectl apply -f pod.yml Sort top pods in all namespace kubectl top pod -A | sort -rnk 4 Add a label to the specific node kubectl label nodes [node-name] [label]=[value] List remaining resources in a namespace kubectl api-resources --verbs=list --namespaced -o name | xargs -n 1 kubectl get --show-kind --ignore-not-found -n monitoring Delete namespace forcely kubectl delete ns heptio-sonobuoy --grace-period=0 --force Copy the file in a pod to local kubectl cp [pod-name]:/heap_dump.hprof heap_dump.hprof -n test Check the k8s logs journalctl -f -u kubelet Delete all evicted pods from all namespaces kubectl get pods --all-namespaces | grep Evicted | awk '{print $2 \" --namespace=\" $1}' | xargs kubectl delete pod Delete all containers in ImagePullBackOff state from all namespaces kubectl get pods --all-namespaces | grep 'ImagePullBackOff' | awk '{print $2 \" --namespace=\" $1}' | xargs kubectl delete pod Delete all containers in ImagePullBackOff or ErrImagePull or Evicted state from all namespaces kubectl get pods --all-namespaces | grep -E 'ImagePullBackOff|ErrImagePull|Evicted' | awk '{print $2 \" --namespace=\" $1}' | xargs kubectl delete pod","title":"Getting started with Kubernetes"},{"location":"devops/getting-started-with-kubernetes/#install-on-linux-cluster","text":"","title":"Install on linux cluster"},{"location":"devops/getting-started-with-kubernetes/#compile-kubernetes","text":"git clone https://github.com/kubernetes/kubernetes.git cd kubernetes make release","title":"Compile kubernetes"},{"location":"devops/getting-started-with-kubernetes/#install-master-node","text":"#Add repos cat <<EOF > /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kube* EOF #Set SELinux in permissive mode (effectively disabling it) setenforce 0 sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config #Install yum install -y kubelet kubeadm kubectl --disableexcludes = kubernetes systemctl enable --now kubelet cat <<EOF > /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sysctl --system #Install network plugin sudo kubeadm init --pod-network-cidr = 192 .168.0.0/16 kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/rbac-kdd.yamlrm kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml #Copy kubernetes config to user folder mkdir -p $HOME /.kube sudo cp -i /etc/kubernetes/admin.conf $HOME /.kube/config sudo chown $( id -u ) : $( id -g ) $HOME /.kube/config","title":"Install master node"},{"location":"devops/getting-started-with-kubernetes/#install-slave-node","text":"#Run on master node to get the join commands sudo kubeadm token create --print-join-command #Copy the join commands and run on slave node kubeadm join <master-ip>:6443 --token 2kjo2d.8qno0vzvbgabp1e8 --discovery-token-ca-cert-hash sha256:2f1ebea7d7369a2d18b58f2926573e193e13ef7525649df1740ddb87963e1315","title":"Install slave node"},{"location":"devops/getting-started-with-kubernetes/#install-metrics-server","text":"git clone https://github.com/kodekloudhub/kubernetes-metrics-server.git kubectl create -f kubernetes-metrics-server/ kubectl top nodes kubectl top pods","title":"Install metrics server"},{"location":"devops/getting-started-with-kubernetes/#install-prometheus","text":"kubectl apply --filename https://raw.githubusercontent.com/giantswarm/kubernetes-prometheus/master/manifests-all.yaml #Maybe you should download the manifests-all.yaml and customize it yourself. For example, you would add Grafana configuration in it. #Create Traefik ingress yaml and apply","title":"Install prometheus"},{"location":"devops/getting-started-with-kubernetes/#install-helm","text":"#Download helm tar.gz file from https://github.com/helm/helm/releases tar -zxvf helm-v2.14.1-linux-amd64.tar.gz sudo cp linux-amd64/helm /usr/local/bin helm init helm version kubectl get pod -n kube-system -l app = helm kubectl create -f rbac.yml kubectl patch deploy --namespace kube-system tiller-deploy -p '{\"spec\":{\"template\":{\"spec\":{\"serviceAccount\":\"tiller\"}}}}'","title":"Install helm"},{"location":"devops/getting-started-with-kubernetes/#traefik","text":"","title":"Traefik"},{"location":"devops/getting-started-with-kubernetes/#create-traefik-toml","text":"defaultEntryPoints = [\"http\",\"https\"] # Enable inner-cluster https navigation insecureSkipVerify = true [entryPoints] [entryPoints.http] address = \":80\" [entryPoints.http.redirect] entryPoint = \"https\" [entryPoints.https] address = \":443\" [entryPoints.https.tls] [[entryPoints.https.tls.certificates]] certFile = \"/etc/kubernetes/ssl/cert.pem\" keyFile = \"/etc/kubernetes/ssl/privkey.pem\" [metrics] [metrics.prometheus] entryPoint = \"traefik\" buckets = [0.1, 0.3, 1.2, 5.0]","title":"Create Traefik toml"},{"location":"devops/getting-started-with-kubernetes/#create-traefik-yaml","text":"kind : Deployment apiVersion : extensions/v1beta1 metadata : name : traefik-ingress-controller namespace : kube-system labels : k8s-app : traefik-ingress-lb spec : replicas : 1 selector : matchLabels : k8s-app : traefik-ingress-lb template : metadata : labels : k8s-app : traefik-ingress-lb name : traefik-ingress-lb spec : serviceAccountName : traefik-ingress-controller terminationGracePeriodSeconds : 60 tolerations : - operator : \"Exists\" nodeSelector : node : master volumes : - name : ssl secret : secretName : traefik-cert - name : config configMap : name : traefik-conf containers : - image : traefik name : traefik-ingress-lb volumeMounts : - mountPath : \"/etc/kubernetes/ssl\" name : \"ssl\" - mountPath : \"/home/ec2-user/kube/traefik\" name : \"config\" ports : - name : http containerPort : 80 hostPort : 80 - name : https containerPort : 443 hostPort : 443 - name : admin containerPort : 8080 args : - --api - --kubernetes - --logLevel=INFO - --configfile=/home/ec2-user/kube/traefik/traefik.toml --- kind : Service apiVersion : v1 metadata : name : traefik-ingress-service namespace : kube-system spec : selector : k8s-app : traefik-ingress-lb ports : - protocol : TCP port : 80 name : web - protocol : TCP port : 443 name : https - protocol : TCP port : 8080 name : admin type : NodePort","title":"Create Traefik yaml"},{"location":"devops/getting-started-with-kubernetes/#create-traefik-rbac","text":"apiVersion : v1 kind : ServiceAccount metadata : name : traefik-ingress-controller namespace : kube-system --- kind : ClusterRole apiVersion : rbac.authorization.k8s.io/v1beta1 metadata : name : traefik-ingress-controller rules : - apiGroups : - \"\" resources : - services - endpoints - secrets verbs : - get - list - watch - apiGroups : - extensions resources : - ingresses verbs : - get - list - watch --- kind : ClusterRoleBinding apiVersion : rbac.authorization.k8s.io/v1beta1 metadata : name : traefik-ingress-controller roleRef : apiGroup : rbac.authorization.k8s.io kind : ClusterRole name : traefik-ingress-controller subjects : - kind : ServiceAccount name : traefik-ingress-controller namespace : kube-system","title":"Create Traefik rbac"},{"location":"devops/getting-started-with-kubernetes/#create-traefik-web-ui-ingress","text":"apiVersion : extensions/v1beta1 kind : Ingress metadata : name : traefik-web-ui namespace : kube-system annotations : kubernetes.io/ingress.class : traefik spec : rules : - host : [ domain ] http : paths : - backend : serviceName : traefik-ingress-service servicePort : 8080","title":"Create Traefik web-ui ingress"},{"location":"devops/getting-started-with-kubernetes/#create-traefik-https-cert","text":"sudo -s cd /etc/letsencrypt/live/ [ domain ] #Update https cert keys and go to domain management console to modify the txt record kubectl create secret generic traefik-cert --from-file = privkey.pem --from-file = cert.pem -n kube-system cp cert.pem privkey.pem /etc/kubernetes/ssl/ #exit and go to the traefik k8s scripts folder kubectl create configmap traefik-conf --from-file = traefik.toml -n kube-system kubectl get cm -n kube-system","title":"Create Traefik HTTPS cert"},{"location":"devops/getting-started-with-kubernetes/#renew-traefik-https-cert","text":"kubectl delete secret traefik-cert -n kube-system kubectl delete configmap traefik-conf -n kube-system kubectl delete -f traefik.yml #Re-run the above \"Create Traefik HTTPS cert\" steps kubectl create -f traefik.yml","title":"Renew Traefik HTTPS cert"},{"location":"devops/getting-started-with-kubernetes/#update-traefiktoml","text":"#Firstly modify the traefik.toml kubectl delete configmap traefik-conf -n kube-system kubectl create configmap traefik-conf --from-file = traefik.toml -n kube-system kubectl delete -f traefik.yml kubectl create -f traefik.yml","title":"Update Traefik.toml"},{"location":"devops/getting-started-with-kubernetes/#kubernetes-dashboard-for-local","text":"","title":"Kubernetes Dashboard for local"},{"location":"devops/getting-started-with-kubernetes/#create-service-account","text":"#admin-user.yaml apiVersion : v1 kind : ServiceAccount metadata : name : admin-user namespace : kube-system","title":"Create service account"},{"location":"devops/getting-started-with-kubernetes/#create-role-binding","text":"#admin-user-role-binding.yaml apiVersion : rbac.authorization.k8s.io/v1beta1 kind : ClusterRoleBinding metadata : name : admin-user roleRef : apiGroup : rbac.authorization.k8s.io kind : ClusterRole name : cluster-admin subjects : - kind : ServiceAccount name : admin-user namespace : kube-system","title":"Create role binding"},{"location":"devops/getting-started-with-kubernetes/#apply-yaml","text":"#Apply service account kubectl create -f admin-user.yaml #Apply role binding kubectl create -f admin-user-role-binding.yaml","title":"Apply yaml"},{"location":"devops/getting-started-with-kubernetes/#retrieve-login-token","text":"kubectl -n kube-system describe secret $( kubectl -n kube-system get secret | grep admin-user | awk '{print $1}' )","title":"Retrieve login token"},{"location":"devops/getting-started-with-kubernetes/#install-dashboard","text":"kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended/kubernetes-dashboard.yaml #Create proxy to allow only localhost navigating kubectl proxy kubectl proxy --address = '0.0.0.0' --accept-hosts = '^*$'","title":"Install dashboard"},{"location":"devops/getting-started-with-kubernetes/#kubernetes-dashboard-for-public","text":"","title":"Kubernetes Dashboard for public"},{"location":"devops/getting-started-with-kubernetes/#create-certificates","text":"mkdir $HOME /certs cd $HOME /certs openssl genrsa -out dashboard.key 2048 openssl rsa -in dashboard.key -out dashboard.key openssl req -sha256 -new -key dashboard.key -out dashboard.csr -subj '/CN=localhost' openssl x509 -req -sha256 -days 365 -in dashboard.csr -signkey dashboard.key -out dashboard.crt kubectl -n kube-system create secret generic kubernetes-dashboard-certs --from-file = $HOME /certs","title":"Create certificates"},{"location":"devops/getting-started-with-kubernetes/#install-dashboard_1","text":"kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml #Wait and check if the replica set is fulfilled kubectl -n kube-system get rs","title":"Install dashboard"},{"location":"devops/getting-started-with-kubernetes/#create-psp","text":"kubectl -n kube-system create -f - <<EOF apiVersion: extensions/v1beta1 kind: PodSecurityPolicy metadata: name: dashboard spec: privileged: false seLinux: rule: RunAsAny supplementalGroups: rule: RunAsAny runAsUser: rule: RunAsAny fsGroup: rule: RunAsAny volumes: - '*' EOF","title":"Create PSP"},{"location":"devops/getting-started-with-kubernetes/#create-role","text":"kubectl -n kube-system create role psp:dashboard --verb = use --resource = podsecuritypolicy --resource-name = dashboard","title":"Create role"},{"location":"devops/getting-started-with-kubernetes/#bind-role-and-account","text":"kubectl -n kube-system create rolebinding kubernetes-dashboard-policy --role = psp:dashboard --serviceaccount = kube-system:kubernetes-dashboard kubectl --as = system:serviceaccount:kube-system:kubernetes-dashboard -n kube-system auth can-i use podsecuritypolicy/dashboard","title":"Bind role and account"},{"location":"devops/getting-started-with-kubernetes/#expose-service-on-nodeport","text":"#Edit the kubernetes-dashboard service and change the following options: # spec.type from ClusterIP to NodePort * spec.ports [ 0 ] .nodePort from 32641 to whatever port you want it to be exposed on kubectl -n kube-system edit service kubernetes-dashboard kubectl -n kube-system get services","title":"Expose service on NodePort"},{"location":"devops/getting-started-with-kubernetes/#navigate-the-dashboard-publicly","text":"#Configure the dns in the domain provider console https:// [ domain ] :30104/","title":"Navigate the dashboard publicly"},{"location":"devops/getting-started-with-kubernetes/#expose-traefik-ingress","text":"apiVersion : extensions/v1beta1 kind : Ingress metadata : name : dashboard-ingress namespace : kube-system spec : rules : - host : [ domain ] http : paths : - path : / backend : serviceName : kubernetes-dashboard servicePort : 443","title":"Expose Traefik ingress"},{"location":"devops/getting-started-with-kubernetes/#scenarios","text":"","title":"Scenarios"},{"location":"devops/getting-started-with-kubernetes/#run-a-busybox-container","text":"kubectl run -i --tty --image busybox test --restart = Never --rm /bin/sh","title":"Run a busybox container"},{"location":"devops/getting-started-with-kubernetes/#user-docker-hub-secret-in-pods","text":"#docker login and get the file: ~/.docker/config.json docker login kubectl create secret generic docker-hub --from-file = .dockerconfigjson = ~/.docker/config.json --type = kubernetes.io/dockerconfigjson --namespace = test #Create a Pod that uses the Secret like bellow kind: Deployment apiVersion: extensions/v1beta1 metadata: name: test-server namespace: test spec: replicas: 2 template: metadata: labels: app: test-server spec: containers: - name: test-server image: demo/test-server imagePullSecrets: - name: docker-hub","title":"User docker hub secret in pods"},{"location":"devops/getting-started-with-kubernetes/#default-storage-class","text":"apiVersion : storage.k8s.io/v1 kind : StorageClass metadata : name : standard provisioner : kubernetes.io/aws-ebs parameters : type : gp2 reclaimPolicy : Retain mountOptions : - debug volumeBindingMode : Immediate","title":"Default storage class"},{"location":"devops/getting-started-with-kubernetes/#create-mongodb-with-two-db-auth-settings","text":"kind : Deployment apiVersion : extensions/v1beta1 metadata : name : dev-mongodb namespace : test spec : replicas : 1 template : metadata : labels : app : dev-mongodb spec : hostname : mongodb containers : - name : dev-mongodb image : hustakin/mongo-auth2:latest env : - name : MONGODB_ADMIN_USER value : admin - name : MONGODB_ADMIN_PASS value : 111 - name : MONGODB_APP1_DATABASE value : db1 - name : MONGODB_APP1_USER value : user1 - name : MONGODB_APP1_PASS value : pass1 - name : MONGODB_APP2_DATABASE value : db2 - name : MONGODB_APP2_USER value : user2 - name : MONGODB_APP2_PASS value : pass2 ports : - containerPort : 27017 protocol : TCP name : db volumeMounts : - mountPath : /data/db name : dev-mongo-persistent-storage livenessProbe : exec : command : - mongo - --eval - \"db.adminCommand('ping')\" failureThreshold : 3 periodSeconds : 10 successThreshold : 1 timeoutSeconds : 5 readinessProbe : exec : command : - mongo - --eval - \"db.adminCommand('ping')\" failureThreshold : 3 periodSeconds : 10 successThreshold : 1 timeoutSeconds : 1 imagePullSecrets : - name : docker-hub volumes : - name : dev-mongo-persistent-storage persistentVolumeClaim : claimName : dev-local-data-pvc --- kind : Service apiVersion : v1 metadata : labels : app : mongodb name : mongodb namespace : test annotations : traefik.ingress.kubernetes.io/affinity : \"true\" traefik.ingress.kubernetes.io/session-cookie-name : \"sticky\" spec : type : ClusterIP ports : - protocol : TCP port : 27017 name : db selector : app : dev-mongodb --- apiVersion : v1 kind : PersistentVolume metadata : name : dev-local-data-pv spec : capacity : storage : 50Gi accessModes : - ReadWriteOnce persistentVolumeReclaimPolicy : Retain storageClassName : local-storage local : path : /mnt/data nodeAffinity : required : nodeSelectorTerms : - matchExpressions : - key : node operator : In values : - db --- kind : PersistentVolumeClaim apiVersion : v1 metadata : name : dev-local-data-pvc namespace : test spec : accessModes : - ReadWriteOnce storageClassName : local-storage resources : requests : storage : 50Gi","title":"Create MongoDB with two DB auth settings"},{"location":"devops/getting-started-with-kubernetes/#useful-commands","text":"Scenarios Commands Create or update 1. kubectl create -f pod.yml 2. kubectl apply -f pod.yml Sort top pods in all namespace kubectl top pod -A | sort -rnk 4 Add a label to the specific node kubectl label nodes [node-name] [label]=[value] List remaining resources in a namespace kubectl api-resources --verbs=list --namespaced -o name | xargs -n 1 kubectl get --show-kind --ignore-not-found -n monitoring Delete namespace forcely kubectl delete ns heptio-sonobuoy --grace-period=0 --force Copy the file in a pod to local kubectl cp [pod-name]:/heap_dump.hprof heap_dump.hprof -n test Check the k8s logs journalctl -f -u kubelet Delete all evicted pods from all namespaces kubectl get pods --all-namespaces | grep Evicted | awk '{print $2 \" --namespace=\" $1}' | xargs kubectl delete pod Delete all containers in ImagePullBackOff state from all namespaces kubectl get pods --all-namespaces | grep 'ImagePullBackOff' | awk '{print $2 \" --namespace=\" $1}' | xargs kubectl delete pod Delete all containers in ImagePullBackOff or ErrImagePull or Evicted state from all namespaces kubectl get pods --all-namespaces | grep -E 'ImagePullBackOff|ErrImagePull|Evicted' | awk '{print $2 \" --namespace=\" $1}' | xargs kubectl delete pod","title":"Useful commands"},{"location":"devops/getting-started-with-vagrant/","text":"The article gives insight into the basic commands of Vagrant Vagrant local box #Vagrant\u4f1a\u5c06\u5bbf\u4e3b\u673a\u5f53\u524d\u76ee\u5f55\u6240\u6709\u6587\u4ef6\u6620\u5c04\u5230VM\u4e2d\u7684/vagrant\u76ee\u5f55\u4e0b #\u521b\u5efavagrant\u73af\u5883\uff0c\u9700\u8981\u5148\u8fdb\u5165\u6240\u5bf9\u5e94\u7684project\u76ee\u5f55 vagrant init ubuntu/trusty64 vagrant up #\u5236\u4f5c\u81ea\u5df1\u7684box vagrant package --output name-of-the-box.box #\u4e0b\u8f7d\u4f7f\u7528\u5df2\u6709\u7684box vagrant box add my-box name-of-the-box.box vagrant init my-box #\u82e5\u6ca1\u6709Vagrantfile\u5219\u9700\u8981\u521d\u59cb\u5316\u751f\u6210 vagrant up vagrant status vagrant ssh Vagrant remote box #\u4f7f\u7528\u4e91\u4e0a\u7684vagrant box #\u53ef\u5728Vagrant Cloud\u4e0a\u521b\u5efa\u81ea\u5df1\u7684box\uff0c\u9009\u62e9virtualbox\u4f5c\u4e3aprovider\u5e76\u4e0a\u4f20box\u6587\u4ef6\u6307\u5b9a\u7248\u672c\u540e\u53d1\u5e03 #Vagrant Cloud: https://app.vagrantup.com #Vagrantfile\u4e2d\u6307\u5b9abox\u540d\u548c\u7248\u672c config.vm.box = \"hustakin/nmserver-front\" config.vm.box_version = \"1.0.0\" #\u4e0b\u8f7d\u955c\u50cf\u5e76\u542f\u52a8 vagrant up Vagrant commands vagrant init # \u521d\u59cb\u5316 vagrant up # \u542f\u52a8\u865a\u62df\u673a vagrant reload # \u91cd\u65b0\u52a0\u8f7dVagrantfile\u914d\u7f6e vagrant halt #\uff08\u5173\u95ed\u865a\u62df\u673a\u2014\u2014\u5bf9\u5e94\u5c31\u662f\u5173\u673a\uff09 vagrant suspend #\uff08\u6682\u505c\u865a\u62df\u673a\uff09 vagrant resume #\uff08\u6062\u590d\u865a\u62df\u673a \u2014\u2014 \u4e0e\u524d\u9762\u7684\u6682\u505c\u76f8\u5bf9\u5e94\uff09 vagrant destroy #\uff08\u5220\u9664\u865a\u62df\u673a) vagrant ssh #(\u901a\u8fc7ssh\u8fdb\u5165\u865a\u62df\u673a) vagrant package # \u6253\u5305\u865a\u62df\u673a","title":"Getting started with Vagrant"},{"location":"devops/getting-started-with-vagrant/#vagrant-local-box","text":"#Vagrant\u4f1a\u5c06\u5bbf\u4e3b\u673a\u5f53\u524d\u76ee\u5f55\u6240\u6709\u6587\u4ef6\u6620\u5c04\u5230VM\u4e2d\u7684/vagrant\u76ee\u5f55\u4e0b #\u521b\u5efavagrant\u73af\u5883\uff0c\u9700\u8981\u5148\u8fdb\u5165\u6240\u5bf9\u5e94\u7684project\u76ee\u5f55 vagrant init ubuntu/trusty64 vagrant up #\u5236\u4f5c\u81ea\u5df1\u7684box vagrant package --output name-of-the-box.box #\u4e0b\u8f7d\u4f7f\u7528\u5df2\u6709\u7684box vagrant box add my-box name-of-the-box.box vagrant init my-box #\u82e5\u6ca1\u6709Vagrantfile\u5219\u9700\u8981\u521d\u59cb\u5316\u751f\u6210 vagrant up vagrant status vagrant ssh","title":"Vagrant local box"},{"location":"devops/getting-started-with-vagrant/#vagrant-remote-box","text":"#\u4f7f\u7528\u4e91\u4e0a\u7684vagrant box #\u53ef\u5728Vagrant Cloud\u4e0a\u521b\u5efa\u81ea\u5df1\u7684box\uff0c\u9009\u62e9virtualbox\u4f5c\u4e3aprovider\u5e76\u4e0a\u4f20box\u6587\u4ef6\u6307\u5b9a\u7248\u672c\u540e\u53d1\u5e03 #Vagrant Cloud: https://app.vagrantup.com #Vagrantfile\u4e2d\u6307\u5b9abox\u540d\u548c\u7248\u672c config.vm.box = \"hustakin/nmserver-front\" config.vm.box_version = \"1.0.0\" #\u4e0b\u8f7d\u955c\u50cf\u5e76\u542f\u52a8 vagrant up","title":"Vagrant remote box"},{"location":"devops/getting-started-with-vagrant/#vagrant-commands","text":"vagrant init # \u521d\u59cb\u5316 vagrant up # \u542f\u52a8\u865a\u62df\u673a vagrant reload # \u91cd\u65b0\u52a0\u8f7dVagrantfile\u914d\u7f6e vagrant halt #\uff08\u5173\u95ed\u865a\u62df\u673a\u2014\u2014\u5bf9\u5e94\u5c31\u662f\u5173\u673a\uff09 vagrant suspend #\uff08\u6682\u505c\u865a\u62df\u673a\uff09 vagrant resume #\uff08\u6062\u590d\u865a\u62df\u673a \u2014\u2014 \u4e0e\u524d\u9762\u7684\u6682\u505c\u76f8\u5bf9\u5e94\uff09 vagrant destroy #\uff08\u5220\u9664\u865a\u62df\u673a) vagrant ssh #(\u901a\u8fc7ssh\u8fdb\u5165\u865a\u62df\u673a) vagrant package # \u6253\u5305\u865a\u62df\u673a","title":"Vagrant commands"},{"location":"devops/important-docker-commands/","text":"Docker is a platform for developers and sysadmins to develop, deploy, and run applications with containers. The use of Linux containers to deploy applications is called containerization. Containers are not new, but their use for easily deploying applications is. Containerization is increasingly popular because containers are: Flexible: Even the most complex applications can be containerized. Lightweight: Containers leverage and share the host kernel. Interchangeable: You can deploy updates and upgrades on-the-fly. Portable: You can build locally, deploy to the cloud, and run anywhere. Scalable: You can increase and automatically distribute container replicas. Stackable: You can stack services vertically and on-the-fly. Install Install Docker sudo curl -sSL https://get.docker.com/ | sh #Docker user group setting (If not set, then docker build or docker-compose down commands would meet error like cannot connect to docker daemon) #Create the docker group sudo groupadd docker #Add your user to the docker group sudo usermod -aG docker $USER #Logout and login to the server again #BaseDeviceUUID configured in: /var/lib/docker/devicemapper/metadata/deviceset-metadata Install Docker-machine curl -L https://github.com/docker/machine/releases/download/v0.12.2/docker-machine- ` uname -s ` - ` uname -m ` >/tmp/docker-machine && chmod +x /tmp/docker-machine && sudo cp /tmp/docker-machine /usr/local/bin/docker-machine Install Docker-compose sudo curl -L https://github.com/docker/compose/releases/download/1.20.0/docker-compose- ` uname -s ` - ` uname -m ` -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose docker-compose --version #Uninstall docker-compose sudo rm /usr/local/bin/docker-compose #Start docker-compose app (read the docker-compose.yml in current folder) docker-compose up #Start docker-compose app in background mode (read the docker-compose.yml in current folder) docker-compose up -d #Remove docker-compose containers docker-compose rm -v Install Fig curl -L https://github.com/docker/fig/releases/download/1.18.0/fig- ` uname -s ` - ` uname -m ` > /usr/local/bin/fig ; chmod +x /usr/local/bin/fig sudo pip install -U fig Install Shipyard #Master node curl -sSL https://shipyard-project.com/deploy | PORT = 8888 bash -s #Slave node curl -sSL https://shipyard-project.com/deploy | ACTION = node DISCOVERY = etcd://http://<master>/:4001 bash -s Install Rancher sudo docker run -d --restart = unless-stopped -p 8888 :8080 rancher/server sudo docker run -d --restart = always -p 8888 :8080 rancher/server Docker containers nsenter docker run --rm -v /usr/local/bin:/target jpetazzo/nsenter #First, figure out the PID of the container you want to enter PID = $( docker inspect --format {{ .State.Pid }} <container_name_or_ID> ) #Then enter the container nsenter --target $PID --mount --uts --ipc --net --pid VSFTPD #Run vsftpd ftp container sudo docker run -d -v /upload:/home/vsftpd \\ -p 20 :20 -p 21 :21 -p 40000 -40080:40000-40080 \\ -e FTP_USER = user -e FTP_PASS = password \\ -e PASV_ADDRESS = 120 .220.209.94 -e PASV_MIN_PORT = 40000 -e PASV_MAX_PORT = 40080 \\ --name vsftpd --restart = always fauria/vsftpd #Run vsftpd sftp container(only has write permission in /share folder, and need to login in port 2022) sudo docker run --name sftp -v /upload/terminal:/home/terminal/share -p 2022 :22 -d atmoz/sftp user:password:1001 #Modify the user folder permissions sudo chmod 777 /upload/terminal/ MySQL docker run --name mysql -p 3306 :3306 -e MYSQL_ROOT_PASSWORD = admin -d mysql:5.7 MongoDB #Run mongodb container: sudo docker run -p 27017 :27017 -v /data/db:/data/db -h mongodb --name mongodb -d mongo #Connect to mongodb sudo docker run -it --link mongodb:mongodb --rm mongo sh -c 'exec mongo \"mongodb:27017/test\"' #Dump db docker run -i --rm --link reliable_mongo_ ${ RELIABLE_ENV_CONFIG } :mongo -v /tmp/mongodump:/tmp mongo bash -c 'mongodump -v --host $MONGO_PORT_27017_TCP_ADDR:$MONGO_PORT_27017_TCP_PORT --db ' $1 ' --out=/tmp && chmod 777 /tmp/*' SpringBoot sudo docker run -it --link mongodb:mongodb -p 8001 :8001 --name springboot-demo test/springboot-demo sh Nginx #Run nginx container: docker container run \\ -d \\ -p 80 :80 \\ --name nginx \\ nginx #Run nginx container with folder mapping: docker container run \\ -d \\ -p 80 :80 \\ --name nginx \\ --volume /nginx:/usr/share/nginx/html \\ nginx #Run nginx container with folder mapping and conf docker container run \\ --name nginx \\ --volume /nginx:/usr/share/nginx/html \\ --volume /nginx/conf:/etc/nginx \\ -p 80 :80 \\ -d \\ nginx #nginx.conf default content server { listen 80 ; sendfile on ; default_type application/octet-stream ; gzip on ; gzip_http_version 1 .1 ; gzip_disable \"MSIE [1-6]\\.\" ; gzip_min_length 256 ; gzip_vary on ; gzip_proxied expired no-cache no-store private auth ; gzip_types text/plain text/css application/json application/javascript application/x-javascript text/xml application/xml application/xml+rss text/javascript ; gzip_comp_level 9 ; root /usr/share/nginx/html ; location / { try_files $uri $uri / /index.html = 404 ; } } RStudio #Dockerfile FROM rocker/rstudio RUN R -e 'install.packages(\"lubridate\u201d)' #Run docker container docker build -t myrstudio . docker run --name rstudio -d -p 8787 :8787 myrstudio #Navigate the RStudio container http://localhost:8787 Jenkins #Run jenkins sudo docker run --name jenkins -p 8088 :8080 -p 50000 :50000 -v /var/jenkins_home -d jenkins #Backup jenkins data sudo docker cp jenkins:/var/jenkins_home jenkins_home sudo tar -czf jenkins_home.tar jenkins_home/ #Restore jenkins data sudo tar -xzf jenkins_home.tar sudo chmod -R 777 jenkins_home sudo docker cp jenkins_home jenkins:/var sudo docker restart jenkins Wordpress #Install mysql sudo docker run --name mysql -e MYSQL_ROOT_PASSWORD = 431197 -d mysql #Install wordpress sudo docker run --name demo_wordpress --link mysql:mysql -p 8080 :80 -d wordpress #Browse wordpress homepage: http://[domain]:8080 Docker commands Scenarios Commands Docker service 1. sudo service docker start 2. sudo service docker restart 3. sudo systemctl enable docker Docker service automatic start sudo systemctl enable docker Login DockerHub sudo docker login Check nginx configuration /usr/nginx/sbin/nginx -t Listen on 2375 for docker rest api sudo dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock & Inspect the container changes docker diff jenkins Commit the docker image from container docker commit -m \"finish the CI configuration for servers in jenkins\" jenkins test/demo Push the docker image to DockerHub docker push test/demo Basic commands sudo docker info sudo docker ps -a sudo docker run --name deamon -d ubuntu:latest /bin/sh -c \"while true; do echo hello world; sleep 1; done\" sudo docker logs -ft deamon sudo docker logs --tail = 100 deamon sudo docker top deamon sudo docker exec -d deamon touch /etc/test_file sudo docker start deamon sudo docker inspect deamon sudo docker inspect --format = '{{ .NetworkSettings.IPAddress}}' develop sudo docker rm d7cb3aad80d0 sudo docker build --no-cache -t = \"hustakin/develop\" . sudo docker run -d -p 8080 :80 --name develop hustakin/develop nginx -g \"daemon off;\" sudo docker run -d -P --name develop hustakin/develop nginx -g \"daemon off;\" sudo docker history hustakin/develop sudo docker port develop 80 docker kill $( docker ps -a -q ) sudo docker rm $( docker ps -a -q ) sudo docker run -t -i --name develop develop /bin/bash sudo docker stats deamon sudo docker system df sudo docker history jenkins docker system prune docker system df -v docker rmi $( docker images -q ) docker volume rm $( docker volume ls -qf dangling = true ) journalctl -r -u docker ( logs of docker engine ) journalctl -u docker.service ( logs of docker engine ) systemctl status docker.service ( logs of starting docker engine ) journalctl -xe ( detailed logs of starting docker engine )","title":"Important Docker commands"},{"location":"devops/important-docker-commands/#install","text":"","title":"Install"},{"location":"devops/important-docker-commands/#install-docker","text":"sudo curl -sSL https://get.docker.com/ | sh #Docker user group setting (If not set, then docker build or docker-compose down commands would meet error like cannot connect to docker daemon) #Create the docker group sudo groupadd docker #Add your user to the docker group sudo usermod -aG docker $USER #Logout and login to the server again #BaseDeviceUUID configured in: /var/lib/docker/devicemapper/metadata/deviceset-metadata","title":"Install Docker"},{"location":"devops/important-docker-commands/#install-docker-machine","text":"curl -L https://github.com/docker/machine/releases/download/v0.12.2/docker-machine- ` uname -s ` - ` uname -m ` >/tmp/docker-machine && chmod +x /tmp/docker-machine && sudo cp /tmp/docker-machine /usr/local/bin/docker-machine","title":"Install Docker-machine"},{"location":"devops/important-docker-commands/#install-docker-compose","text":"sudo curl -L https://github.com/docker/compose/releases/download/1.20.0/docker-compose- ` uname -s ` - ` uname -m ` -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose docker-compose --version #Uninstall docker-compose sudo rm /usr/local/bin/docker-compose #Start docker-compose app (read the docker-compose.yml in current folder) docker-compose up #Start docker-compose app in background mode (read the docker-compose.yml in current folder) docker-compose up -d #Remove docker-compose containers docker-compose rm -v","title":"Install Docker-compose"},{"location":"devops/important-docker-commands/#install-fig","text":"curl -L https://github.com/docker/fig/releases/download/1.18.0/fig- ` uname -s ` - ` uname -m ` > /usr/local/bin/fig ; chmod +x /usr/local/bin/fig sudo pip install -U fig","title":"Install Fig"},{"location":"devops/important-docker-commands/#install-shipyard","text":"#Master node curl -sSL https://shipyard-project.com/deploy | PORT = 8888 bash -s #Slave node curl -sSL https://shipyard-project.com/deploy | ACTION = node DISCOVERY = etcd://http://<master>/:4001 bash -s","title":"Install Shipyard"},{"location":"devops/important-docker-commands/#install-rancher","text":"sudo docker run -d --restart = unless-stopped -p 8888 :8080 rancher/server sudo docker run -d --restart = always -p 8888 :8080 rancher/server","title":"Install Rancher"},{"location":"devops/important-docker-commands/#docker-containers","text":"","title":"Docker containers"},{"location":"devops/important-docker-commands/#nsenter","text":"docker run --rm -v /usr/local/bin:/target jpetazzo/nsenter #First, figure out the PID of the container you want to enter PID = $( docker inspect --format {{ .State.Pid }} <container_name_or_ID> ) #Then enter the container nsenter --target $PID --mount --uts --ipc --net --pid","title":"nsenter"},{"location":"devops/important-docker-commands/#vsftpd","text":"#Run vsftpd ftp container sudo docker run -d -v /upload:/home/vsftpd \\ -p 20 :20 -p 21 :21 -p 40000 -40080:40000-40080 \\ -e FTP_USER = user -e FTP_PASS = password \\ -e PASV_ADDRESS = 120 .220.209.94 -e PASV_MIN_PORT = 40000 -e PASV_MAX_PORT = 40080 \\ --name vsftpd --restart = always fauria/vsftpd #Run vsftpd sftp container(only has write permission in /share folder, and need to login in port 2022) sudo docker run --name sftp -v /upload/terminal:/home/terminal/share -p 2022 :22 -d atmoz/sftp user:password:1001 #Modify the user folder permissions sudo chmod 777 /upload/terminal/","title":"VSFTPD"},{"location":"devops/important-docker-commands/#mysql","text":"docker run --name mysql -p 3306 :3306 -e MYSQL_ROOT_PASSWORD = admin -d mysql:5.7","title":"MySQL"},{"location":"devops/important-docker-commands/#mongodb","text":"#Run mongodb container: sudo docker run -p 27017 :27017 -v /data/db:/data/db -h mongodb --name mongodb -d mongo #Connect to mongodb sudo docker run -it --link mongodb:mongodb --rm mongo sh -c 'exec mongo \"mongodb:27017/test\"' #Dump db docker run -i --rm --link reliable_mongo_ ${ RELIABLE_ENV_CONFIG } :mongo -v /tmp/mongodump:/tmp mongo bash -c 'mongodump -v --host $MONGO_PORT_27017_TCP_ADDR:$MONGO_PORT_27017_TCP_PORT --db ' $1 ' --out=/tmp && chmod 777 /tmp/*'","title":"MongoDB"},{"location":"devops/important-docker-commands/#springboot","text":"sudo docker run -it --link mongodb:mongodb -p 8001 :8001 --name springboot-demo test/springboot-demo sh","title":"SpringBoot"},{"location":"devops/important-docker-commands/#nginx","text":"#Run nginx container: docker container run \\ -d \\ -p 80 :80 \\ --name nginx \\ nginx #Run nginx container with folder mapping: docker container run \\ -d \\ -p 80 :80 \\ --name nginx \\ --volume /nginx:/usr/share/nginx/html \\ nginx #Run nginx container with folder mapping and conf docker container run \\ --name nginx \\ --volume /nginx:/usr/share/nginx/html \\ --volume /nginx/conf:/etc/nginx \\ -p 80 :80 \\ -d \\ nginx #nginx.conf default content server { listen 80 ; sendfile on ; default_type application/octet-stream ; gzip on ; gzip_http_version 1 .1 ; gzip_disable \"MSIE [1-6]\\.\" ; gzip_min_length 256 ; gzip_vary on ; gzip_proxied expired no-cache no-store private auth ; gzip_types text/plain text/css application/json application/javascript application/x-javascript text/xml application/xml application/xml+rss text/javascript ; gzip_comp_level 9 ; root /usr/share/nginx/html ; location / { try_files $uri $uri / /index.html = 404 ; } }","title":"Nginx"},{"location":"devops/important-docker-commands/#rstudio","text":"#Dockerfile FROM rocker/rstudio RUN R -e 'install.packages(\"lubridate\u201d)' #Run docker container docker build -t myrstudio . docker run --name rstudio -d -p 8787 :8787 myrstudio #Navigate the RStudio container http://localhost:8787","title":"RStudio"},{"location":"devops/important-docker-commands/#jenkins","text":"#Run jenkins sudo docker run --name jenkins -p 8088 :8080 -p 50000 :50000 -v /var/jenkins_home -d jenkins #Backup jenkins data sudo docker cp jenkins:/var/jenkins_home jenkins_home sudo tar -czf jenkins_home.tar jenkins_home/ #Restore jenkins data sudo tar -xzf jenkins_home.tar sudo chmod -R 777 jenkins_home sudo docker cp jenkins_home jenkins:/var sudo docker restart jenkins","title":"Jenkins"},{"location":"devops/important-docker-commands/#wordpress","text":"#Install mysql sudo docker run --name mysql -e MYSQL_ROOT_PASSWORD = 431197 -d mysql #Install wordpress sudo docker run --name demo_wordpress --link mysql:mysql -p 8080 :80 -d wordpress #Browse wordpress homepage: http://[domain]:8080","title":"Wordpress"},{"location":"devops/important-docker-commands/#docker-commands","text":"Scenarios Commands Docker service 1. sudo service docker start 2. sudo service docker restart 3. sudo systemctl enable docker Docker service automatic start sudo systemctl enable docker Login DockerHub sudo docker login Check nginx configuration /usr/nginx/sbin/nginx -t Listen on 2375 for docker rest api sudo dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock & Inspect the container changes docker diff jenkins Commit the docker image from container docker commit -m \"finish the CI configuration for servers in jenkins\" jenkins test/demo Push the docker image to DockerHub docker push test/demo","title":"Docker commands"},{"location":"devops/important-docker-commands/#basic-commands","text":"sudo docker info sudo docker ps -a sudo docker run --name deamon -d ubuntu:latest /bin/sh -c \"while true; do echo hello world; sleep 1; done\" sudo docker logs -ft deamon sudo docker logs --tail = 100 deamon sudo docker top deamon sudo docker exec -d deamon touch /etc/test_file sudo docker start deamon sudo docker inspect deamon sudo docker inspect --format = '{{ .NetworkSettings.IPAddress}}' develop sudo docker rm d7cb3aad80d0 sudo docker build --no-cache -t = \"hustakin/develop\" . sudo docker run -d -p 8080 :80 --name develop hustakin/develop nginx -g \"daemon off;\" sudo docker run -d -P --name develop hustakin/develop nginx -g \"daemon off;\" sudo docker history hustakin/develop sudo docker port develop 80 docker kill $( docker ps -a -q ) sudo docker rm $( docker ps -a -q ) sudo docker run -t -i --name develop develop /bin/bash sudo docker stats deamon sudo docker system df sudo docker history jenkins docker system prune docker system df -v docker rmi $( docker images -q ) docker volume rm $( docker volume ls -qf dangling = true ) journalctl -r -u docker ( logs of docker engine ) journalctl -u docker.service ( logs of docker engine ) systemctl status docker.service ( logs of starting docker engine ) journalctl -xe ( detailed logs of starting docker engine )","title":"Basic commands"},{"location":"devops/important-linux-commands/","text":"The article gives insight into the most important commands System basic commands Scenarios Commands Inspect the host name hostname Inspect the host name and version uname -a Inspect the Linux information lsb_release -a Inspect the CPU information cat /proc/cpuinfo Inspect the memory free -m Inspect the user 1. w 2. who 3. whoami 4. tty Inspect the hard drive 1. df -h 2. df -aTh 3. du -h --max-depth=1 . Inspect the ports 1. netstat -ano | findstr 7001 2. sudo netstat -tunlp 3. netstat -aonp | grep 5050 Inspect the firewall sudo iptables -L -n Inspect the dns to host and port status nmap -Pn -p 27018 google.com.au Inspect the path env for current user echo $PATH Inspect the process by pid tasklist | findstr 23416 Inspect the process by name ps -ef | grep nginx Kill the process by pid taskkill -f -pid 9788 Curl and save to txt curl 130.220.209.90:9000 --trace-ascii dump.txt Get a root shell 1. sudo -s 2. sudo bash -c su - Clean Linux temp files sudo rm -rf /var/log/* Clean Linux temp files cursor and processes 1. sudo lsof | grep delete 2. sudo kill * MacOS kill process using specific port 1. lsof -i tcp:8443 2. kill 86166 Clean Linux swap and move into memory then restart and modify threshold 1. sudo swapoff -a && sudo swapon -a 2. sudo sysctl vm.swappiness=10 3. sudo vi /etc/sysctl.conf -> vm.swappiness=10 File commands Scenarios Commands Find a file with the given name under current path find . -name \"*\" Find a archive file containing the given xml file find . -name \"*.jar\" | xargs grep \"*.xml\" Find a file containing the given content under current path 1. grep -s -r \"*\" ./ 2. find . -name \"*.xml\" | xargs grep \"*\" Find a file containing the given content under current path and only print the file name to the output file find . -name \"*.*\" | xargs grep -ri \"APXMTMRR\" -l > grep_APXMTMRR.log Find the top size files 1. du -a . | sort -n -r | head -n 10 2. find . -type f -size +20000k -exec ls -lh {} \\; | awk '{ print $9 \": \" $5 }' List the folders' size in current folder du -h --max-depth=1 . List the latest changed files under current folder ls -lrth Find the files under specific folder and append the timestamp find /var -maxdepth 2 -type d -exec stat -c \"%n %y\" {} \\; Paste text with # in the VIM and keep the format :set paste Zip folder to a file sudo tar -zvcf /data/bak.tar.gz /data/db Unzip file to a folder sudo tar -zvxf /data/bak.tar.gz Copy file to remote by scp scp agriculture-platform/rebuild.sh ec2-user@130.220.209.90:/home/ec2-user/agriculture-platform/ rebuild.sh Copy Folder to remote by scp scp -r agriculture-platform ec2-user@130.220.209.90:/home/ec2-user Copy file from remote to local by scp 1. scp -i sshkey googlecloud@test.com:/home/googlecloud/test/keystore.p12 . 2. scp -i \"~/sshkey.pem\" -r ec2-user@test.com:/mnt/data data-test Clean the content in a file sed -i \"d\" Dockerfile Software commands Scenarios Commands Install software by yum 1. sudo yum -y install docker 2. sudo yum install java-1.8.0-openjdk.x86_64 Uninstall software by yum sudo yum -y remove docker List installed software by yum 1. yum list installed | grep docker 2. yum -y list docker* Search software by yum yum search java | grep 'java-' Install software by apt-get 1. apt-get update 2. apt-get install vim List installed software by RPM rpm -qa | grep docker Service commands Scenarios Commands Restart vsftpd systemctl restart vsftpd Restart nginx /usr/nginx/sbin/nginx -s reload Check nginx configuration /usr/nginx/sbin/nginx -t JVM commands Scenarios Commands Inspect JVM default heap flag java -XX:+PrintFlagsFinal -version | grep HeapSize Inspect the java process arguments jinfo -flags 1 Inspect the java process GC information jmap -heap 1 List java process jps List the basic class memory information by pid jmap -histo 1 | head List the class loaders memory information by pid jmap -clstats 1 Dump the java process heap information by pid jcmd 1 GC.heap_dump heap_dump.hprof Scenarios Maven and SpringBoot commands #Generate project mvn archetype:generate \\ -DgroupId = com.alibaba.test \\ -DartifactId = tutorial1 \\ -Dversion = 1 .0-SNAPSHOT \\ -Dpackage = com.alibaba.test.tutorial1 \\ -DarchetypeArtifactId = archetype-test-quickstart \\ -DarchetypeGroupId = com.alibaba.test.sample \\ -DarchetypeVersion = 1 .0 \\ -DinteractiveMode = false #Build project without testing mvn clean package -Dmaven.test.skip = true #Run SpringBoot with specific profile java -Dspring.profiles.active = dev -Xms256m -Xmx1024m -jar calculate-1.0.jar mvn spring-boot:run -Drun.profiles = dev mvn spring-boot:run -Drun.jvmArguments = \"-Dspring.profiles.active=dev\" #Run in debug mode java -agentlib:jdwp = transport = dt_socket,server = y,address = 5050 ,suspend = y -jar calculate-1.0.jar mvn spring-boot:run -Drun.jvmArguments = \"-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5005\u201d mvn spring-boot:run -Drun.jvmArguments=\" -Xdebug -Xrunjdwp:transport = dt_socket,server = y,suspend = n,address = 5005 -Dspring.profiles.active = dev \" #Create SpringBoot project using start.spring.io curl https://start.spring.io/starter.zip -d dependencies=web,data-jpa,devtools,h2 -d groupId=au.com.frankie -d artifactId=example -d name=example -d description=\" Spring Boot Example Application \" -d baseDir=example -o myapp.zip && unzip myapp.zip && rm -f myapp.zip SSH from server1 to server2 without password #Generate private/public key in server1, and copy the public key ssh-keygen -t rsa sudo cat ~/.ssh/id_rsa.pub #Append the public key to authorized keys in server2 vi ~/.ssh/authorized_keys #SSH from server1 to server2: ssh ec2-user@130.220.209.90 #Allow or deny IPs: (block the ssh request or not) sudo vi /etc/hosts.deny #(remove the client IP) sudo systemctl restart sshd.service Change Timezone(Ubuntu) date -R sudo timedatectl set-timezone Australia/Brisbane timedatectl sudo timedatectl set-local-rtc 1 sudo timedatectl set-local-rtc 0 Modify the fstab system file to automatically mount a volume after rebooting sudo vi /etc/fstab # modify the content as bellow /dev/vdb /mnt/data auto defaults,nofail,comment = cloudconfig 0 2 #reboot the instance Establish the tunnel from local port to online website by ngrok (the header setting is because of angular app Invalid Host Header issue) ngrok http 4200 -host-header = \"localhost:4200\" ngrok http --host-header = rewrite 4200 Pandoc usage pandoc -s README.md -o README.docx -M title:architecture #(markdown -> docx) pandoc --pdf-engine = xelatex README.md -o README.pdf #(markdown -> pdf) Recover rm -rf files #Install extundelete sudo yum search extundelete sudo yum install extundelete.* #Find filesystem and type(support ext3/ext4) to recover df -T #Find nodes and node to recover: sudo extundelete --inode 2 /dev/vda1 sudo extundelete --inode 393217 /dev/vda1 #Recover: sudo extundelete --restore-inode 542480 /dev/vda1 #Recover all deleted after time sudo yum search extundelete sudo yum install extundelete.* df -T sudo umount /dev/vdc date -d \"2018-06-02 23:00:00\" +%s sudo extundelete /dev/vdc --after 1527980400 --restore-all sudo cp -R /data . sudo mount /dev/vdc /data -t auto sudo cp -R ./data/* /data/ HTTPS certificate #Generate key keytool -genkey -alias tomcat -storetype PKCS12 -keyalg RSA -keysize 2048 -keystore keystore.p12 -validity 3650 #Install certbot and certbot-auto git clone https://github.com/certbot/certbot cd certbot ./certbot-auto ./certbot-auto --help #Generate certificates and a private key #Remember to stop springboot process first sudo ./certbot-auto certonly -a standalone -d test.com -d www.test.com #Convert PEM files to PKCS12 files sudo -s cd /etc/letsencrypt/live/test.com openssl pkcs12 -export -in fullchain.pem -inkey privkey.pem -out keystore.p12 -name tomcat -CAfile chain.pem -caname root #copy keystore.p12 file to ~/agriculture-platform folder, exit su, then start springboot process #Update HTTPS key(test.com) cd ~/certbot docker stop agriculture sudo ./certbot-auto certonly -a standalone -d test.com sudo -s cd /etc/letsencrypt/live/test.com openssl pkcs12 -export -in fullchain.pem -inkey privkey.pem -out keystore.p12 -name tomcat -CAfile chain.pem -caname root cp keystore.p12 /home/ec2-user/agriculture-platform/ exit cd ~/agriculture-platform/ vi Dockerfile #modify the date to recopy the key . rebuild.sh #Generate generic HTTPS key(*.test.com) ./certbot-auto certonly -d *.test.com --manual --preferred-challenges dns --server https://acme-v02.api.letsencrypt.org/directory ./certbot-auto certonly -d *.cloud.lava.xin --manual --preferred-challenges dns --server https://acme-v02.api.letsencrypt.org/directory #create txt record in dns #Generate p12 by crt and key openssl pkcs12 -export -name alpha -in alpha_v2.crt -inkey alpha.key -out alpha.p12 AWS volume #Extend volume lsblk #Check if the volume need to extent in Linux df -h sudo growpart /dev/xvda 1 #xvda1 in lsblk result means change the partition 1 here lsblk sudo resize2fs /dev/xvda1 df -h #Mount/Unmount volume lsblk df -h sudo mount /dev/xvdf1 /data sudo umount /dev/xvdf1 df -h NectarCloud volume #ttach and mount volume(/dev/vdc) sudo fdisk -l sudo mkfs.ext4 /dev/vdc sudo mount /dev/vdc /data -t auto sudo mount /dev/vdd /var/lib/docker -t auto sudo chmod -R 777 /data sudo umount /dev/vdd #Increase the volume size(/dev/vdc) sudo umount /dev/vdc sudo e2fsck -f /dev/vdb sudo resize2fs /dev/vdc sudo mount /dev/vdc /data -t auto Singularity in HPC #MongoDB singularity pull docker://mongo:3.4 singularity shell --bind data:/data mongo_3.4.sif singularity instance start mongo_3.4.sif mongodb mongod & mongo db LVM management #Install lvextend yum whatprovides */lvextend sudo yum install lvm2 #Enlarge the / disk df -h sudo lvextend -L +50G /dev/vda1 Openstack API #Install openstack client in Ubuntu sudo apt update sudo apt-get install python-pip python-dev sudo apt install python-openstackclient #Replace the queue with Queue #... ##import queue #import Queue as queue #... vi /home/ubuntu/.local/lib/python2.7/site-packages/openstack/utils.py vi /home/ubuntu/.local/lib/python2.7/site-packages/openstack/cloud/openstackcloud.py openstack server list MongoDB operation #Authentication mongo --port 27017 -u \"database\" -p \"password\" --authenticationDatabase \"admin\" use admin db.auth ( 'database' , 'password' ) #Clear plan cache db.StandardCases.getPlanCache () .clear () #Inspect database/collection size db.stats () db.BackupDatas.stat () #Check aggregation plan db.StandardCases.aggregate ([ { $match : { datasetId: \"5a6fddf188fba650b83b94c9\" , validated: true, \"timestamp.minuteStr\" : { $lte : \"2018-09-09 00:00\" , $gte : \"2017-12-31 00:00\" } } } , { $project : { date: \" $timestamp .minuteStr\" , toStat: 1 } } , { $group : { _id: \" $date \" , toStat: { $push : \" $toStat \" } } } , { $sort : { _id: 1 } } ] , { cursor: {} , allowDiskUse: true, explain: true }) #Check aggregation execution plan db.StandardCases.explain ( \"executionStats\" ) .aggregate ([ { $match : { datasetId: \"5a6fddf188fba650b83b94c9\" , validated: true, \"timestamp.minuteStr\" : { $lte : \"2018-09-09 00:00\" , $gte : \"2017-12-31 00:00\" } , \"filter.Tunnels_to_survey~Plants_to_survey~Variety\" : { $in : [ \"Eureka\" ] } } } , { $project : { date: \" $timestamp .minuteStr\" , toStat: 1 } } , { $group : { _id: \" $date \" , toStat: { $push : \" $toStat \" } } } , { $sort : { _id: 1 } } ]) Crontab service #Start/stop service sudo /sbin/service crond start sudo /sbin/service crond stop sudo /sbin/service crond restart sudo /sbin/service crond reload #Current services crontab -l #Edit services crontab -e #Delete services crontab -r Less commands #less generate min.css lessc --clean-css AdminLTE.less ../../dist/css/AdminLTE.min.css Git commands #Git clone git clone https://hustakin@github.com/hustakin/***.git #Configure new git remote url and push git remote add origin https://hustakin@github.com/hustakin/***.git git push --set-upstream origin master #Modify git remote url git remote set-url origin https://hustakin@github.com/hustakin/***.git git remote -v #Find the size of git repository git count-objects -v #Prune all of the reflog references from this point back (unless you\u2019re explicitly only operating on one branch) and repack the repository git -c gc.auto = 1 -c gc.autodetach = false -c gc.autopacklimit = 1 -c gc.garbageexpire = now -c gc.reflogexpireunreachable = now gc --prune = all #Push all your changes back to the Bitbucket repository git push --all --force && git push --tags --force #Force push the local to remote git push -u origin master -f MongoDB commands #Find by id in mongoldb compass { \"_id\" : { \" $oid \" : \"5973048f0b30d6ed2104ad9d\" }} #start/shutdown commands: mongod -f /etc/mongodb.conf mongod --shutdown -f /etc/mongodb.conf #MongoDB on mac #The databases are stored in the /usr/local/var/mongodb/ or /usr/local/opt/mongodb/ directory #The mongod.conf file is here: /usr/local/etc/mongod.conf #The mongo logs can be found at /usr/local/var/log/mongodb/ #The mongo binaries are here: /usr/local/Cellar/mongodb/[version]/bin Install tools Maven wget http://www.strategylions.com.au/mirror/maven/maven-3/3.5.4/binaries/apache-maven-3.5.4-bin.tar.gz tar xvf apache-maven-3.5.4-bin.tar.gz sudo mv apache-maven-3.5.4 /usr/local/apache-maven # Add the env variables to your ~/.bashrc file export M2_HOME = /usr/local/apache-maven export M2 = $M2_HOME /bin export PATH = $M2 : $PATH source ~/.bashrc mvn -version rm -rf apache-maven-3.5.4-bin.tar.gz Ping and telnet apt-get update yes | apt-get install iputils-ping yes | apt-get install telnet Grunt #Install plugin to grunt and update the package.json dependency npm install grunt --save-dev ( for testing framework, like grunt.. ) npm install grunt --save ( for production purpose. )","title":"Important linux commands"},{"location":"devops/important-linux-commands/#system-basic-commands","text":"Scenarios Commands Inspect the host name hostname Inspect the host name and version uname -a Inspect the Linux information lsb_release -a Inspect the CPU information cat /proc/cpuinfo Inspect the memory free -m Inspect the user 1. w 2. who 3. whoami 4. tty Inspect the hard drive 1. df -h 2. df -aTh 3. du -h --max-depth=1 . Inspect the ports 1. netstat -ano | findstr 7001 2. sudo netstat -tunlp 3. netstat -aonp | grep 5050 Inspect the firewall sudo iptables -L -n Inspect the dns to host and port status nmap -Pn -p 27018 google.com.au Inspect the path env for current user echo $PATH Inspect the process by pid tasklist | findstr 23416 Inspect the process by name ps -ef | grep nginx Kill the process by pid taskkill -f -pid 9788 Curl and save to txt curl 130.220.209.90:9000 --trace-ascii dump.txt Get a root shell 1. sudo -s 2. sudo bash -c su - Clean Linux temp files sudo rm -rf /var/log/* Clean Linux temp files cursor and processes 1. sudo lsof | grep delete 2. sudo kill * MacOS kill process using specific port 1. lsof -i tcp:8443 2. kill 86166 Clean Linux swap and move into memory then restart and modify threshold 1. sudo swapoff -a && sudo swapon -a 2. sudo sysctl vm.swappiness=10 3. sudo vi /etc/sysctl.conf -> vm.swappiness=10","title":"System basic commands"},{"location":"devops/important-linux-commands/#file-commands","text":"Scenarios Commands Find a file with the given name under current path find . -name \"*\" Find a archive file containing the given xml file find . -name \"*.jar\" | xargs grep \"*.xml\" Find a file containing the given content under current path 1. grep -s -r \"*\" ./ 2. find . -name \"*.xml\" | xargs grep \"*\" Find a file containing the given content under current path and only print the file name to the output file find . -name \"*.*\" | xargs grep -ri \"APXMTMRR\" -l > grep_APXMTMRR.log Find the top size files 1. du -a . | sort -n -r | head -n 10 2. find . -type f -size +20000k -exec ls -lh {} \\; | awk '{ print $9 \": \" $5 }' List the folders' size in current folder du -h --max-depth=1 . List the latest changed files under current folder ls -lrth Find the files under specific folder and append the timestamp find /var -maxdepth 2 -type d -exec stat -c \"%n %y\" {} \\; Paste text with # in the VIM and keep the format :set paste Zip folder to a file sudo tar -zvcf /data/bak.tar.gz /data/db Unzip file to a folder sudo tar -zvxf /data/bak.tar.gz Copy file to remote by scp scp agriculture-platform/rebuild.sh ec2-user@130.220.209.90:/home/ec2-user/agriculture-platform/ rebuild.sh Copy Folder to remote by scp scp -r agriculture-platform ec2-user@130.220.209.90:/home/ec2-user Copy file from remote to local by scp 1. scp -i sshkey googlecloud@test.com:/home/googlecloud/test/keystore.p12 . 2. scp -i \"~/sshkey.pem\" -r ec2-user@test.com:/mnt/data data-test Clean the content in a file sed -i \"d\" Dockerfile","title":"File commands"},{"location":"devops/important-linux-commands/#software-commands","text":"Scenarios Commands Install software by yum 1. sudo yum -y install docker 2. sudo yum install java-1.8.0-openjdk.x86_64 Uninstall software by yum sudo yum -y remove docker List installed software by yum 1. yum list installed | grep docker 2. yum -y list docker* Search software by yum yum search java | grep 'java-' Install software by apt-get 1. apt-get update 2. apt-get install vim List installed software by RPM rpm -qa | grep docker","title":"Software commands"},{"location":"devops/important-linux-commands/#service-commands","text":"Scenarios Commands Restart vsftpd systemctl restart vsftpd Restart nginx /usr/nginx/sbin/nginx -s reload Check nginx configuration /usr/nginx/sbin/nginx -t","title":"Service commands"},{"location":"devops/important-linux-commands/#jvm-commands","text":"Scenarios Commands Inspect JVM default heap flag java -XX:+PrintFlagsFinal -version | grep HeapSize Inspect the java process arguments jinfo -flags 1 Inspect the java process GC information jmap -heap 1 List java process jps List the basic class memory information by pid jmap -histo 1 | head List the class loaders memory information by pid jmap -clstats 1 Dump the java process heap information by pid jcmd 1 GC.heap_dump heap_dump.hprof","title":"JVM commands"},{"location":"devops/important-linux-commands/#scenarios","text":"","title":"Scenarios"},{"location":"devops/important-linux-commands/#maven-and-springboot-commands","text":"#Generate project mvn archetype:generate \\ -DgroupId = com.alibaba.test \\ -DartifactId = tutorial1 \\ -Dversion = 1 .0-SNAPSHOT \\ -Dpackage = com.alibaba.test.tutorial1 \\ -DarchetypeArtifactId = archetype-test-quickstart \\ -DarchetypeGroupId = com.alibaba.test.sample \\ -DarchetypeVersion = 1 .0 \\ -DinteractiveMode = false #Build project without testing mvn clean package -Dmaven.test.skip = true #Run SpringBoot with specific profile java -Dspring.profiles.active = dev -Xms256m -Xmx1024m -jar calculate-1.0.jar mvn spring-boot:run -Drun.profiles = dev mvn spring-boot:run -Drun.jvmArguments = \"-Dspring.profiles.active=dev\" #Run in debug mode java -agentlib:jdwp = transport = dt_socket,server = y,address = 5050 ,suspend = y -jar calculate-1.0.jar mvn spring-boot:run -Drun.jvmArguments = \"-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5005\u201d mvn spring-boot:run -Drun.jvmArguments=\" -Xdebug -Xrunjdwp:transport = dt_socket,server = y,suspend = n,address = 5005 -Dspring.profiles.active = dev \" #Create SpringBoot project using start.spring.io curl https://start.spring.io/starter.zip -d dependencies=web,data-jpa,devtools,h2 -d groupId=au.com.frankie -d artifactId=example -d name=example -d description=\" Spring Boot Example Application \" -d baseDir=example -o myapp.zip && unzip myapp.zip && rm -f myapp.zip","title":"Maven and SpringBoot commands"},{"location":"devops/important-linux-commands/#ssh-from-server1-to-server2-without-password","text":"#Generate private/public key in server1, and copy the public key ssh-keygen -t rsa sudo cat ~/.ssh/id_rsa.pub #Append the public key to authorized keys in server2 vi ~/.ssh/authorized_keys #SSH from server1 to server2: ssh ec2-user@130.220.209.90 #Allow or deny IPs: (block the ssh request or not) sudo vi /etc/hosts.deny #(remove the client IP) sudo systemctl restart sshd.service","title":"SSH from server1 to server2 without password"},{"location":"devops/important-linux-commands/#change-timezoneubuntu","text":"date -R sudo timedatectl set-timezone Australia/Brisbane timedatectl sudo timedatectl set-local-rtc 1 sudo timedatectl set-local-rtc 0","title":"Change Timezone(Ubuntu)"},{"location":"devops/important-linux-commands/#modify-the-fstab-system-file-to-automatically-mount-a-volume-after-rebooting","text":"sudo vi /etc/fstab # modify the content as bellow /dev/vdb /mnt/data auto defaults,nofail,comment = cloudconfig 0 2 #reboot the instance","title":"Modify the fstab system file to automatically mount a volume after rebooting"},{"location":"devops/important-linux-commands/#establish-the-tunnel-from-local-port-to-online-website-by-ngrok-the-header-setting-is-because-of-angular-app-invalid-host-header-issue","text":"ngrok http 4200 -host-header = \"localhost:4200\" ngrok http --host-header = rewrite 4200","title":"Establish the tunnel from local port to online website by ngrok (the header setting is because of angular app Invalid Host Header issue)"},{"location":"devops/important-linux-commands/#pandoc-usage","text":"pandoc -s README.md -o README.docx -M title:architecture #(markdown -> docx) pandoc --pdf-engine = xelatex README.md -o README.pdf #(markdown -> pdf)","title":"Pandoc usage"},{"location":"devops/important-linux-commands/#recover-rm-rf-files","text":"#Install extundelete sudo yum search extundelete sudo yum install extundelete.* #Find filesystem and type(support ext3/ext4) to recover df -T #Find nodes and node to recover: sudo extundelete --inode 2 /dev/vda1 sudo extundelete --inode 393217 /dev/vda1 #Recover: sudo extundelete --restore-inode 542480 /dev/vda1 #Recover all deleted after time sudo yum search extundelete sudo yum install extundelete.* df -T sudo umount /dev/vdc date -d \"2018-06-02 23:00:00\" +%s sudo extundelete /dev/vdc --after 1527980400 --restore-all sudo cp -R /data . sudo mount /dev/vdc /data -t auto sudo cp -R ./data/* /data/","title":"Recover rm -rf files"},{"location":"devops/important-linux-commands/#https-certificate","text":"#Generate key keytool -genkey -alias tomcat -storetype PKCS12 -keyalg RSA -keysize 2048 -keystore keystore.p12 -validity 3650 #Install certbot and certbot-auto git clone https://github.com/certbot/certbot cd certbot ./certbot-auto ./certbot-auto --help #Generate certificates and a private key #Remember to stop springboot process first sudo ./certbot-auto certonly -a standalone -d test.com -d www.test.com #Convert PEM files to PKCS12 files sudo -s cd /etc/letsencrypt/live/test.com openssl pkcs12 -export -in fullchain.pem -inkey privkey.pem -out keystore.p12 -name tomcat -CAfile chain.pem -caname root #copy keystore.p12 file to ~/agriculture-platform folder, exit su, then start springboot process #Update HTTPS key(test.com) cd ~/certbot docker stop agriculture sudo ./certbot-auto certonly -a standalone -d test.com sudo -s cd /etc/letsencrypt/live/test.com openssl pkcs12 -export -in fullchain.pem -inkey privkey.pem -out keystore.p12 -name tomcat -CAfile chain.pem -caname root cp keystore.p12 /home/ec2-user/agriculture-platform/ exit cd ~/agriculture-platform/ vi Dockerfile #modify the date to recopy the key . rebuild.sh #Generate generic HTTPS key(*.test.com) ./certbot-auto certonly -d *.test.com --manual --preferred-challenges dns --server https://acme-v02.api.letsencrypt.org/directory ./certbot-auto certonly -d *.cloud.lava.xin --manual --preferred-challenges dns --server https://acme-v02.api.letsencrypt.org/directory #create txt record in dns #Generate p12 by crt and key openssl pkcs12 -export -name alpha -in alpha_v2.crt -inkey alpha.key -out alpha.p12","title":"HTTPS certificate"},{"location":"devops/important-linux-commands/#aws-volume","text":"#Extend volume lsblk #Check if the volume need to extent in Linux df -h sudo growpart /dev/xvda 1 #xvda1 in lsblk result means change the partition 1 here lsblk sudo resize2fs /dev/xvda1 df -h #Mount/Unmount volume lsblk df -h sudo mount /dev/xvdf1 /data sudo umount /dev/xvdf1 df -h","title":"AWS volume"},{"location":"devops/important-linux-commands/#nectarcloud-volume","text":"#ttach and mount volume(/dev/vdc) sudo fdisk -l sudo mkfs.ext4 /dev/vdc sudo mount /dev/vdc /data -t auto sudo mount /dev/vdd /var/lib/docker -t auto sudo chmod -R 777 /data sudo umount /dev/vdd #Increase the volume size(/dev/vdc) sudo umount /dev/vdc sudo e2fsck -f /dev/vdb sudo resize2fs /dev/vdc sudo mount /dev/vdc /data -t auto","title":"NectarCloud volume"},{"location":"devops/important-linux-commands/#singularity-in-hpc","text":"#MongoDB singularity pull docker://mongo:3.4 singularity shell --bind data:/data mongo_3.4.sif singularity instance start mongo_3.4.sif mongodb mongod & mongo db","title":"Singularity in HPC"},{"location":"devops/important-linux-commands/#lvm-management","text":"#Install lvextend yum whatprovides */lvextend sudo yum install lvm2 #Enlarge the / disk df -h sudo lvextend -L +50G /dev/vda1","title":"LVM management"},{"location":"devops/important-linux-commands/#openstack-api","text":"#Install openstack client in Ubuntu sudo apt update sudo apt-get install python-pip python-dev sudo apt install python-openstackclient #Replace the queue with Queue #... ##import queue #import Queue as queue #... vi /home/ubuntu/.local/lib/python2.7/site-packages/openstack/utils.py vi /home/ubuntu/.local/lib/python2.7/site-packages/openstack/cloud/openstackcloud.py openstack server list","title":"Openstack API"},{"location":"devops/important-linux-commands/#mongodb-operation","text":"#Authentication mongo --port 27017 -u \"database\" -p \"password\" --authenticationDatabase \"admin\" use admin db.auth ( 'database' , 'password' ) #Clear plan cache db.StandardCases.getPlanCache () .clear () #Inspect database/collection size db.stats () db.BackupDatas.stat () #Check aggregation plan db.StandardCases.aggregate ([ { $match : { datasetId: \"5a6fddf188fba650b83b94c9\" , validated: true, \"timestamp.minuteStr\" : { $lte : \"2018-09-09 00:00\" , $gte : \"2017-12-31 00:00\" } } } , { $project : { date: \" $timestamp .minuteStr\" , toStat: 1 } } , { $group : { _id: \" $date \" , toStat: { $push : \" $toStat \" } } } , { $sort : { _id: 1 } } ] , { cursor: {} , allowDiskUse: true, explain: true }) #Check aggregation execution plan db.StandardCases.explain ( \"executionStats\" ) .aggregate ([ { $match : { datasetId: \"5a6fddf188fba650b83b94c9\" , validated: true, \"timestamp.minuteStr\" : { $lte : \"2018-09-09 00:00\" , $gte : \"2017-12-31 00:00\" } , \"filter.Tunnels_to_survey~Plants_to_survey~Variety\" : { $in : [ \"Eureka\" ] } } } , { $project : { date: \" $timestamp .minuteStr\" , toStat: 1 } } , { $group : { _id: \" $date \" , toStat: { $push : \" $toStat \" } } } , { $sort : { _id: 1 } } ])","title":"MongoDB operation"},{"location":"devops/important-linux-commands/#crontab-service","text":"#Start/stop service sudo /sbin/service crond start sudo /sbin/service crond stop sudo /sbin/service crond restart sudo /sbin/service crond reload #Current services crontab -l #Edit services crontab -e #Delete services crontab -r","title":"Crontab service"},{"location":"devops/important-linux-commands/#less-commands","text":"#less generate min.css lessc --clean-css AdminLTE.less ../../dist/css/AdminLTE.min.css","title":"Less commands"},{"location":"devops/important-linux-commands/#git-commands","text":"#Git clone git clone https://hustakin@github.com/hustakin/***.git #Configure new git remote url and push git remote add origin https://hustakin@github.com/hustakin/***.git git push --set-upstream origin master #Modify git remote url git remote set-url origin https://hustakin@github.com/hustakin/***.git git remote -v #Find the size of git repository git count-objects -v #Prune all of the reflog references from this point back (unless you\u2019re explicitly only operating on one branch) and repack the repository git -c gc.auto = 1 -c gc.autodetach = false -c gc.autopacklimit = 1 -c gc.garbageexpire = now -c gc.reflogexpireunreachable = now gc --prune = all #Push all your changes back to the Bitbucket repository git push --all --force && git push --tags --force #Force push the local to remote git push -u origin master -f","title":"Git commands"},{"location":"devops/important-linux-commands/#mongodb-commands","text":"#Find by id in mongoldb compass { \"_id\" : { \" $oid \" : \"5973048f0b30d6ed2104ad9d\" }} #start/shutdown commands: mongod -f /etc/mongodb.conf mongod --shutdown -f /etc/mongodb.conf #MongoDB on mac #The databases are stored in the /usr/local/var/mongodb/ or /usr/local/opt/mongodb/ directory #The mongod.conf file is here: /usr/local/etc/mongod.conf #The mongo logs can be found at /usr/local/var/log/mongodb/ #The mongo binaries are here: /usr/local/Cellar/mongodb/[version]/bin","title":"MongoDB commands"},{"location":"devops/important-linux-commands/#install-tools","text":"","title":"Install tools"},{"location":"devops/important-linux-commands/#maven","text":"wget http://www.strategylions.com.au/mirror/maven/maven-3/3.5.4/binaries/apache-maven-3.5.4-bin.tar.gz tar xvf apache-maven-3.5.4-bin.tar.gz sudo mv apache-maven-3.5.4 /usr/local/apache-maven # Add the env variables to your ~/.bashrc file export M2_HOME = /usr/local/apache-maven export M2 = $M2_HOME /bin export PATH = $M2 : $PATH source ~/.bashrc mvn -version rm -rf apache-maven-3.5.4-bin.tar.gz","title":"Maven"},{"location":"devops/important-linux-commands/#ping-and-telnet","text":"apt-get update yes | apt-get install iputils-ping yes | apt-get install telnet","title":"Ping and telnet"},{"location":"devops/important-linux-commands/#grunt","text":"#Install plugin to grunt and update the package.json dependency npm install grunt --save-dev ( for testing framework, like grunt.. ) npm install grunt --save ( for production purpose. )","title":"Grunt"},{"location":"devops/things-todo-after-installing-ubuntu/","text":"System tools sudo apt-get update Chromium The open source Chrome in Ubuntu. VI sudo apt-get remove vim-common sudo apt-get install vim Input method sudo apt-get install fcitx fcitx-bin fcitx-googlepinyin fcitx-config-gtk3 Flameshot sudo apt install flameshot Go to \"Settings-Keyboard Shortcuts\" of Ubuntu and add a shortcut for taking screenshots by the command: /usr/bin/flameshot gui GNOME Shell Extensions sudo apt install gnome-tweaks gnome-shell --version sudo apt install gnome-shell-extensions sudo apt-get install chrome-gnome-shell Reboot the Ubuntu and press Super key to search Extensions. Have a work around settings and remember to toggle the \"User themes\" Install extensions from the website . You should install the \"GNOME Shell integration\" from the website first. Recommend extensions to install: OpenWeather Rambox Pro sudo snap install ramboxpro wget -O- https://deepin-wine.i-m.dev/setup.sh | sh Manage packages by dpkg sudo dpkg -i *.deb dpkg -l | grep ( name ) sudo dpkg -r ( package ) Media decoder sudo apt install ubuntu-restricted-extras Flatpak sudo apt install flatpak Pinta sudo apt install pinta EasySSH sudo flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo sudo flatpak install flathub com.github.muriloventuroso.easyssh flatpak run com.github.muriloventuroso.easyssh DropBox Download DropBox for Ubuntu here . Setting the selective sync folders after installed and linked with you account because Dropbox doesn't support smart sync. Microsoft Teams Download Teams from here . Wine & WeChat sudo apt install wine64 sudo apt install winetricks winetricks #Download Windows programes .exe file wine *.exe winetricks riched20 sudo apt install libjpeg62:i386 #Download WeChat .exe file from its homepage and wine run it to install Zoom sudo apt install gdebi Download the Zoom from here FileZilla Download the FileZilla from here Development environment Git sudo apt-get install git Maven sudo apt install maven python3 & pip3 sudo apt update sudo apt install software-properties-common sudo add-apt-repository ppa:deadsnakes/ppa sudo apt update sudo apt install python3.8 python3 --version sudo apt install python3-pip NodeJS & NPM & Yarn & Gulp #Install NodeJS sudo apt-get install --reinstall nodejs-legacy sudo apt-get purge nodejs --auto-remove sudo apt-get purge npm --auto-remove whereis node #Then remove all the versions of node sudo apt-get install nodejs node --version nodejs --version sudo apt-get install npm npm --version sudo npm install -g npm npm i -D typescript@3.4.5 #Install yarn sudo apt install cmdtest #Install Gulp sudo apt install gulp Spyder & Anaconda Download the Spyder with Anaconda from here bash *.sh Intellij Idea Ultimate sudo snap install intellij-idea-ultimate --classic #start the IDE intellij-idea-ultimate mkdocs pip3 install pymdown-extensions mkdocs mkdocs-material Flutter sudo snap install flutter --classic npm & angular-cli sudo apt install npm sudo npm install -g @angular/cli AWS CLI curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip sudo ./aws/install aws configure #Input the aws credentials QGIS sudo apt install gnupg software-properties-common wget -qO - https://qgis.org/downloads/qgis-2020.gpg.key | sudo gpg --no-default-keyring --keyring gnupg-ring:/etc/apt/trusted.gpg.d/qgis-archive.gpg --import sudo chmod a+r /etc/apt/trusted.gpg.d/qgis-archive.gpg sudo add-apt-repository \"deb https://qgis.org/debian `lsb_release -c -s` main\" sudo apt update sudo apt install qgis qgis-plugin-grass DevOps Clean cache sudo apt autoremove Add customized programs to favorite #Take EasySSH for example sudo vi /usr/share/applications/easy-ssh.desktop The content of easy-ssh.desktop: #Take EasySSH for example [Desktop Entry] Name = EasySSH GenericName = SSH Client Comment = SSH to remote servers Exec = flatpak run com.github.muriloventuroso.easyssh Terminal = false Type = Application Icon = easyssh.png StartupNotify = false Download the EasySSH png file and save it as ~/.icons/easyssh.png. Press Super key and find the EasySSH program and right click to add it to favorite.","title":"Things to do after installing Ubuntu 20.04.1 LTS"},{"location":"devops/things-todo-after-installing-ubuntu/#system-tools","text":"sudo apt-get update","title":"System tools"},{"location":"devops/things-todo-after-installing-ubuntu/#chromium","text":"The open source Chrome in Ubuntu.","title":"Chromium"},{"location":"devops/things-todo-after-installing-ubuntu/#vi","text":"sudo apt-get remove vim-common sudo apt-get install vim","title":"VI"},{"location":"devops/things-todo-after-installing-ubuntu/#input-method","text":"sudo apt-get install fcitx fcitx-bin fcitx-googlepinyin fcitx-config-gtk3","title":"Input method"},{"location":"devops/things-todo-after-installing-ubuntu/#flameshot","text":"sudo apt install flameshot Go to \"Settings-Keyboard Shortcuts\" of Ubuntu and add a shortcut for taking screenshots by the command: /usr/bin/flameshot gui","title":"Flameshot"},{"location":"devops/things-todo-after-installing-ubuntu/#gnome-shell-extensions","text":"sudo apt install gnome-tweaks gnome-shell --version sudo apt install gnome-shell-extensions sudo apt-get install chrome-gnome-shell Reboot the Ubuntu and press Super key to search Extensions. Have a work around settings and remember to toggle the \"User themes\" Install extensions from the website . You should install the \"GNOME Shell integration\" from the website first. Recommend extensions to install: OpenWeather","title":"GNOME Shell Extensions"},{"location":"devops/things-todo-after-installing-ubuntu/#rambox-pro","text":"sudo snap install ramboxpro wget -O- https://deepin-wine.i-m.dev/setup.sh | sh Manage packages by dpkg sudo dpkg -i *.deb dpkg -l | grep ( name ) sudo dpkg -r ( package )","title":"Rambox Pro"},{"location":"devops/things-todo-after-installing-ubuntu/#media-decoder","text":"sudo apt install ubuntu-restricted-extras","title":"Media decoder"},{"location":"devops/things-todo-after-installing-ubuntu/#flatpak","text":"sudo apt install flatpak","title":"Flatpak"},{"location":"devops/things-todo-after-installing-ubuntu/#pinta","text":"sudo apt install pinta","title":"Pinta"},{"location":"devops/things-todo-after-installing-ubuntu/#easyssh","text":"sudo flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo sudo flatpak install flathub com.github.muriloventuroso.easyssh flatpak run com.github.muriloventuroso.easyssh","title":"EasySSH"},{"location":"devops/things-todo-after-installing-ubuntu/#dropbox","text":"Download DropBox for Ubuntu here . Setting the selective sync folders after installed and linked with you account because Dropbox doesn't support smart sync.","title":"DropBox"},{"location":"devops/things-todo-after-installing-ubuntu/#microsoft-teams","text":"Download Teams from here .","title":"Microsoft Teams"},{"location":"devops/things-todo-after-installing-ubuntu/#wine-wechat","text":"sudo apt install wine64 sudo apt install winetricks winetricks #Download Windows programes .exe file wine *.exe winetricks riched20 sudo apt install libjpeg62:i386 #Download WeChat .exe file from its homepage and wine run it to install","title":"Wine &amp; WeChat"},{"location":"devops/things-todo-after-installing-ubuntu/#zoom","text":"sudo apt install gdebi Download the Zoom from here","title":"Zoom"},{"location":"devops/things-todo-after-installing-ubuntu/#filezilla","text":"Download the FileZilla from here","title":"FileZilla"},{"location":"devops/things-todo-after-installing-ubuntu/#development-environment","text":"","title":"Development environment"},{"location":"devops/things-todo-after-installing-ubuntu/#git","text":"sudo apt-get install git","title":"Git"},{"location":"devops/things-todo-after-installing-ubuntu/#maven","text":"sudo apt install maven","title":"Maven"},{"location":"devops/things-todo-after-installing-ubuntu/#python3-pip3","text":"sudo apt update sudo apt install software-properties-common sudo add-apt-repository ppa:deadsnakes/ppa sudo apt update sudo apt install python3.8 python3 --version sudo apt install python3-pip","title":"python3 &amp; pip3"},{"location":"devops/things-todo-after-installing-ubuntu/#nodejs-npm-yarn-gulp","text":"#Install NodeJS sudo apt-get install --reinstall nodejs-legacy sudo apt-get purge nodejs --auto-remove sudo apt-get purge npm --auto-remove whereis node #Then remove all the versions of node sudo apt-get install nodejs node --version nodejs --version sudo apt-get install npm npm --version sudo npm install -g npm npm i -D typescript@3.4.5 #Install yarn sudo apt install cmdtest #Install Gulp sudo apt install gulp","title":"NodeJS &amp; NPM &amp; Yarn &amp; Gulp"},{"location":"devops/things-todo-after-installing-ubuntu/#spyder-anaconda","text":"Download the Spyder with Anaconda from here bash *.sh","title":"Spyder &amp; Anaconda"},{"location":"devops/things-todo-after-installing-ubuntu/#intellij-idea-ultimate","text":"sudo snap install intellij-idea-ultimate --classic #start the IDE intellij-idea-ultimate","title":"Intellij Idea Ultimate"},{"location":"devops/things-todo-after-installing-ubuntu/#mkdocs","text":"pip3 install pymdown-extensions mkdocs mkdocs-material","title":"mkdocs"},{"location":"devops/things-todo-after-installing-ubuntu/#flutter","text":"sudo snap install flutter --classic","title":"Flutter"},{"location":"devops/things-todo-after-installing-ubuntu/#npm-angular-cli","text":"sudo apt install npm sudo npm install -g @angular/cli","title":"npm &amp; angular-cli"},{"location":"devops/things-todo-after-installing-ubuntu/#aws-cli","text":"curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip sudo ./aws/install aws configure #Input the aws credentials","title":"AWS CLI"},{"location":"devops/things-todo-after-installing-ubuntu/#qgis","text":"sudo apt install gnupg software-properties-common wget -qO - https://qgis.org/downloads/qgis-2020.gpg.key | sudo gpg --no-default-keyring --keyring gnupg-ring:/etc/apt/trusted.gpg.d/qgis-archive.gpg --import sudo chmod a+r /etc/apt/trusted.gpg.d/qgis-archive.gpg sudo add-apt-repository \"deb https://qgis.org/debian `lsb_release -c -s` main\" sudo apt update sudo apt install qgis qgis-plugin-grass","title":"QGIS"},{"location":"devops/things-todo-after-installing-ubuntu/#devops","text":"","title":"DevOps"},{"location":"devops/things-todo-after-installing-ubuntu/#clean-cache","text":"sudo apt autoremove","title":"Clean cache"},{"location":"devops/things-todo-after-installing-ubuntu/#add-customized-programs-to-favorite","text":"#Take EasySSH for example sudo vi /usr/share/applications/easy-ssh.desktop The content of easy-ssh.desktop: #Take EasySSH for example [Desktop Entry] Name = EasySSH GenericName = SSH Client Comment = SSH to remote servers Exec = flatpak run com.github.muriloventuroso.easyssh Terminal = false Type = Application Icon = easyssh.png StartupNotify = false Download the EasySSH png file and save it as ~/.icons/easyssh.png. Press Super key and find the EasySSH program and right click to add it to favorite.","title":"Add customized programs to favorite"},{"location":"flutter/how-to-develop-and-publish-a-dart-plugin-package/","text":"A dart package enables the creation of modular code that can be shared easily. Here I introduce the steps to create and publish an open-source dart plugin package. After all instructions everyone else would be able to install it by adding the plugin package into their pubspec.yaml/dependencies and use this widget in their development. There are two kinds of Dart packages: General packages and Plugin packages. To create a Flutter package, use the --template=package flag with flutter create: flutter create --template=package monthly_heatmap_list Open the generated project by Intellij Idea, you will see the minimal package includes pubspec.yaml and basic dart file under lib directory. Image Develop the Dart plugin package and test. Test the package by dependencies either from local relative path or GitHub url. dependencies: plugin1: path: ../plugin1/ dependencies: plugin1: git: url: git://github.com/flutter/plugin1.git dependencies: package1: git: url: git://github.com/flutter/packages.git path: packages/package1 Once you have implemented a package, you can publish it on pub.dev, so that other developers can easily use it. Next, run the publish command in dry-run mode to see if everything passes analysis: The next step is publishing to pub.dev, but be sure that you are ready because publishing is forever:","title":"How to develop and publish a Dart plugin package for Flutter"},{"location":"life/a-detail-list-for-updating-address-when-moving/","text":"We have configured the home address in a lot of websites, so it's important to update all of them when we are going to move. Service Belong : get started the \"Move service\" to move the nbn to the new address Ergon : get started the \"Manage account-Moving home\" to move the electricity to the new address Apple Developer Google Play Console AWS Console AWS Training and Certification Membership IEEE Bank card and credit card Commonwealth Bank : update the address in \"Settings-My contact details-Address\" CommSec : update the address in \"View or Edit details\" AMEX : update the address in \"Account Management-Personal Details-View or Edit Contact Details-Contact Details\" ING : update the address in \"My profile\" WestUnion Driver license QLD portal : update the address in \"My details\" Mobile plan TPG : update the address in \"My Account-Update Contact & Payment Details\" Exetel : update the address in \"Account Details\" ALDImobile : update the address in \"Manage account-Account details-Address-Update Address\" Government ATO online : update the address in \"My profile-My contact details\" myGov : update the address in \"Account Settings-Update your details-Update your address\" USI : update the address in \"UPDATE CONTACT DETAILS\" UniSuper UniSuper online : update the address in \"Profile-Personal details\" Medibank Medibank online : update the address in \"Me-Login & contact details-Addresses\" Car insurance Allianz Car Insurance : update the address in \"My Details-Update my details\" Allianz Roadside Assistance : update the address in \"My Account\" Shopping Flybuys : update the address in \"Settings-My Account-Account Details\" Woolworths Rewards : update the address in \"MY ACCOUNT-My details\" DanMurphy's : update the address in \"View account-My account-Delivery address\" Living Edge Scorptec Travel Translink gocard : update the address in \"My Details\" E-way tag : update the address in \"My Details-PERSONAL INFO-ADDRESS\" QueenslandRail Travel : update the address in \"My Account-My Profile\" Qantas : update the address in \"Your profile-Personal information-Contact details\" Virgin : update the address in \"My Profile-My Details\"","title":"A detailed list for updating address when moving"},{"location":"life/a-detail-list-for-updating-address-when-moving/#service","text":"Belong : get started the \"Move service\" to move the nbn to the new address Ergon : get started the \"Manage account-Moving home\" to move the electricity to the new address Apple Developer Google Play Console AWS Console AWS Training and Certification","title":"Service"},{"location":"life/a-detail-list-for-updating-address-when-moving/#membership","text":"IEEE","title":"Membership"},{"location":"life/a-detail-list-for-updating-address-when-moving/#bank-card-and-credit-card","text":"Commonwealth Bank : update the address in \"Settings-My contact details-Address\" CommSec : update the address in \"View or Edit details\" AMEX : update the address in \"Account Management-Personal Details-View or Edit Contact Details-Contact Details\" ING : update the address in \"My profile\" WestUnion","title":"Bank card and credit card"},{"location":"life/a-detail-list-for-updating-address-when-moving/#driver-license","text":"QLD portal : update the address in \"My details\"","title":"Driver license"},{"location":"life/a-detail-list-for-updating-address-when-moving/#mobile-plan","text":"TPG : update the address in \"My Account-Update Contact & Payment Details\" Exetel : update the address in \"Account Details\" ALDImobile : update the address in \"Manage account-Account details-Address-Update Address\"","title":"Mobile plan"},{"location":"life/a-detail-list-for-updating-address-when-moving/#government","text":"ATO online : update the address in \"My profile-My contact details\" myGov : update the address in \"Account Settings-Update your details-Update your address\" USI : update the address in \"UPDATE CONTACT DETAILS\"","title":"Government"},{"location":"life/a-detail-list-for-updating-address-when-moving/#unisuper","text":"UniSuper online : update the address in \"Profile-Personal details\"","title":"UniSuper"},{"location":"life/a-detail-list-for-updating-address-when-moving/#medibank","text":"Medibank online : update the address in \"Me-Login & contact details-Addresses\"","title":"Medibank"},{"location":"life/a-detail-list-for-updating-address-when-moving/#car-insurance","text":"Allianz Car Insurance : update the address in \"My Details-Update my details\" Allianz Roadside Assistance : update the address in \"My Account\"","title":"Car insurance"},{"location":"life/a-detail-list-for-updating-address-when-moving/#shopping","text":"Flybuys : update the address in \"Settings-My Account-Account Details\" Woolworths Rewards : update the address in \"MY ACCOUNT-My details\" DanMurphy's : update the address in \"View account-My account-Delivery address\" Living Edge Scorptec","title":"Shopping"},{"location":"life/a-detail-list-for-updating-address-when-moving/#travel","text":"Translink gocard : update the address in \"My Details\" E-way tag : update the address in \"My Details-PERSONAL INFO-ADDRESS\" QueenslandRail Travel : update the address in \"My Account-My Profile\" Qantas : update the address in \"Your profile-Personal information-Contact details\" Virgin : update the address in \"My Profile-My Details\"","title":"Travel"},{"location":"life/how-to-rent-a-house-in-australia/","text":"Renting a house is no rocket science in Australia, but it's not child's play either. Arriving to the country for the first time, you can't expect to own a house in just a few weeks or months. Even those who have been here for quite a while still choose to rent. Only seventy percent of the population owns their homes or on mortgage. The rest choose to rent. Here are some simple steps on landing your first apartment or flat in the Lucky Country. Learn the local lingo The first step to renting property in Australia is to get a handle on the local lingo that residents and agents use to describe their humble homes or magnificent mansions. In Australia, properties are either referred to as flats or houses. A flat is a local term for an apartment. Houses are typically larger than flats and come with an outdoor space; thus it's more likely that a two-bedroom flat will cost less than a two-bedroom house, but it's not always the case. Flats with just one room are called studios. Expats may also come across the word \"unit\" used to describe a property. Units are larger flats, often with split levels like a house, but built in blocks like flats. Useful websites PRD ANP Raine&Horne FOURWALLS REALTY Realestate Useful APP TenantApp : This should be the best APP for rental inspection. It helps you arrange inspections on a calendar view. Realestateview : There are not a lot information on this APP, but you can have a look. Domain : There are not a lot information on this APP, but you can have a look. Inspection Once a suitable property has been found that meets the requirements, it's time to arrange an inspection. It's important to note that in Australia most agents will not rent a property without the tenant having viewed it first. Some agents hold opening viewings or open houses, where anyone can view. These can be competitive, so turn up early and be prepared. Bring all the papers necessary to put in an application on the spot. That would be a smart way for you to well prepare the application form before the inspection if you really want to win and take the property. Application Real estate agents can take more than one application for a property at a time, so you should make sure when submitting that they include all the correct information. This can often be the difference between securing a property and losing out to someone else who is better prepared. Typical applications require: Proof of identity (passport/drivers license) Bank statement References - one of the most important parts of the application. This will include the applicant's current employer and friends and, possibly, a previous landlord Credit card Registration certificate Proof of income, latest three payslips Recent rent receipt Cover letter - It's a good way to show honest, especially for expats when there are too many competitors Once references have been checked by the estate agent, the whole application will go to the owner of the property for final approval. Signing When renting property in Australia, there is no standard for how much rent has to be paid in advance. However, when coming to sign the lease and to pay the first instalment of rent, the new tenant will also need to pay a bond, usually for the amount of a month to six weeks' rent. The bond, similar to the idea of a security deposit, protects the owner against any damage done to the property or any bills left unpaid by the tenant. The bond is held by an independent government-owned body. As the tenant is bound to the bond it's important to inspect the property thoroughly for damage before moving in. If existing damage is found, be sure to bring it to the attention of the managing agent or landlord. In the case of a furnished property, an inventory should be kept. At the lease's conclusion, the cost of any items not accounted for on the inventory are deducted from the bond. Broadband Find an broadband company for your property. For example, Belong is a good choice for its price. Electricity Find a electricity company for your property. For example, Ergon is the choice in Bundaberg.","title":"How to rent a house in Australia"},{"location":"life/how-to-rent-a-house-in-australia/#learn-the-local-lingo","text":"The first step to renting property in Australia is to get a handle on the local lingo that residents and agents use to describe their humble homes or magnificent mansions. In Australia, properties are either referred to as flats or houses. A flat is a local term for an apartment. Houses are typically larger than flats and come with an outdoor space; thus it's more likely that a two-bedroom flat will cost less than a two-bedroom house, but it's not always the case. Flats with just one room are called studios. Expats may also come across the word \"unit\" used to describe a property. Units are larger flats, often with split levels like a house, but built in blocks like flats.","title":"Learn the local lingo"},{"location":"life/how-to-rent-a-house-in-australia/#useful-websites","text":"PRD ANP Raine&Horne FOURWALLS REALTY Realestate","title":"Useful websites"},{"location":"life/how-to-rent-a-house-in-australia/#useful-app","text":"TenantApp : This should be the best APP for rental inspection. It helps you arrange inspections on a calendar view. Realestateview : There are not a lot information on this APP, but you can have a look. Domain : There are not a lot information on this APP, but you can have a look.","title":"Useful APP"},{"location":"life/how-to-rent-a-house-in-australia/#inspection","text":"Once a suitable property has been found that meets the requirements, it's time to arrange an inspection. It's important to note that in Australia most agents will not rent a property without the tenant having viewed it first. Some agents hold opening viewings or open houses, where anyone can view. These can be competitive, so turn up early and be prepared. Bring all the papers necessary to put in an application on the spot. That would be a smart way for you to well prepare the application form before the inspection if you really want to win and take the property.","title":"Inspection"},{"location":"life/how-to-rent-a-house-in-australia/#application","text":"Real estate agents can take more than one application for a property at a time, so you should make sure when submitting that they include all the correct information. This can often be the difference between securing a property and losing out to someone else who is better prepared. Typical applications require: Proof of identity (passport/drivers license) Bank statement References - one of the most important parts of the application. This will include the applicant's current employer and friends and, possibly, a previous landlord Credit card Registration certificate Proof of income, latest three payslips Recent rent receipt Cover letter - It's a good way to show honest, especially for expats when there are too many competitors Once references have been checked by the estate agent, the whole application will go to the owner of the property for final approval.","title":"Application"},{"location":"life/how-to-rent-a-house-in-australia/#signing","text":"When renting property in Australia, there is no standard for how much rent has to be paid in advance. However, when coming to sign the lease and to pay the first instalment of rent, the new tenant will also need to pay a bond, usually for the amount of a month to six weeks' rent. The bond, similar to the idea of a security deposit, protects the owner against any damage done to the property or any bills left unpaid by the tenant. The bond is held by an independent government-owned body. As the tenant is bound to the bond it's important to inspect the property thoroughly for damage before moving in. If existing damage is found, be sure to bring it to the attention of the managing agent or landlord. In the case of a furnished property, an inventory should be kept. At the lease's conclusion, the cost of any items not accounted for on the inventory are deducted from the bond.","title":"Signing"},{"location":"life/how-to-rent-a-house-in-australia/#broadband","text":"Find an broadband company for your property. For example, Belong is a good choice for its price.","title":"Broadband"},{"location":"life/how-to-rent-a-house-in-australia/#electricity","text":"Find a electricity company for your property. For example, Ergon is the choice in Bundaberg.","title":"Electricity"},{"location":"life/international-money-transfer-from-commanwealth-bank-to-china/","text":"Send in foreign currency using NetBank or the CommBank app to pay a lower transfer fee and lock in the exchange rate. The best thing for choosing this way is that you can send money to yourself which is not available by using WestUnion. Swift/BIC Code We could search the swift code of the recipient's bank at here: Swift The BIC code for banks in China are as bellow Bank BIC \u4e2d\u56fd\u94f6\u884c BKCHCNBJ \u4e2d\u56fd\u5de5\u5546\u94f6\u884c ICBKCNBJ \u4e2d\u56fd\u519c\u4e1a\u94f6\u884c ABOCCNBJ \u4e2d\u56fd\u5efa\u8bbe\u94f6\u884c PCBCCNBJ \u62db\u5546\u94f6\u884c CMBCCNBS Input the BIC and city and country, then search the result and choose the branch. You will see the Swift code for the branch. Chinese Telegraphic Transfer Code (CTC) We could search the CTC code of the recipient's name at here: CTC Online transfer Login CBA website to transfer is the best choice because we can choose an existing recipient to transfer. APP transfer We could also transfer on CBA APP. Select \"Products & Offers\" and enter \"International & travel\", then send money now. Enter the swift code, CTC getting from previous steps, and transfer.","title":"International money transfer from CommonWealth bank to China"},{"location":"life/international-money-transfer-from-commanwealth-bank-to-china/#swiftbic-code","text":"We could search the swift code of the recipient's bank at here: Swift The BIC code for banks in China are as bellow Bank BIC \u4e2d\u56fd\u94f6\u884c BKCHCNBJ \u4e2d\u56fd\u5de5\u5546\u94f6\u884c ICBKCNBJ \u4e2d\u56fd\u519c\u4e1a\u94f6\u884c ABOCCNBJ \u4e2d\u56fd\u5efa\u8bbe\u94f6\u884c PCBCCNBJ \u62db\u5546\u94f6\u884c CMBCCNBS Input the BIC and city and country, then search the result and choose the branch. You will see the Swift code for the branch.","title":"Swift/BIC Code"},{"location":"life/international-money-transfer-from-commanwealth-bank-to-china/#chinese-telegraphic-transfer-code-ctc","text":"We could search the CTC code of the recipient's name at here: CTC","title":"Chinese Telegraphic Transfer Code (CTC)"},{"location":"life/international-money-transfer-from-commanwealth-bank-to-china/#online-transfer","text":"Login CBA website to transfer is the best choice because we can choose an existing recipient to transfer.","title":"Online transfer"},{"location":"life/international-money-transfer-from-commanwealth-bank-to-china/#app-transfer","text":"We could also transfer on CBA APP. Select \"Products & Offers\" and enter \"International & travel\", then send money now. Enter the swift code, CTC getting from previous steps, and transfer.","title":"APP transfer"},{"location":"tools/getting-started-with-mitmproxy/","text":"mitmproxy is a free and open source interactive HTTPS proxy The mitmproxy project's tools are a set of front-ends that expose common underlying functionality. * mitmproxy is an interactive, SSL-capable intercepting proxy with a console interface. * mitmdump is the command-line version of mitmproxy. Think tcpdump for HTTP. * mitmweb is a web-based interface for mitmproxy. * pathoc and pathod are perverse HTTP client and server applications designed to let you craft almost any conceivable HTTP request, including ones that creatively violate the standards. Development setup Install python3 (Windows) Start Windows PowerShell with the \"Run as Administrator\" option. Only members of the Administrators group on the computer can change the execution policy. (Windows) Enable running unsigned scripts by entering: set-executionpolicy remotesigned Install mitmproxy from source (Windows) powershell . \\d ev.ps1 (Others) ./dev.sh The dev script will create a virtualenv environment in a directory called \"venv\" and install all mandatory and optional dependencies into it. The primary mitmproxy components - mitmproxy and pathod - are installed as \"editable\", so any changes to the source in the repository will be reflected live in the virtualenv. The main executables for the project - mitmdump, mitmproxy, mitmweb, pathod, and pathoc - are all created within the virtualenv. After activating the virtualenv, they will be on your $PATH, and you can run them like any other command: (Windows) venv \\S cripts \\a ctivate mitmdump --version (Others) . venv/bin/activate mitmdump --version Running mitmweb mitmweb --set block_global = false Set a lot of parameters if needed mitmweb --set block_global = false --set ignore-hosts = '^(?!example\\.com)(?!mitmproxy\\.org)' --set showhost = true --ssl-insecure The certificate files locate at ~/.mitmproxy/. Apple/Android/Other could use .pem, Windows could use .p12 Set the proxy in WIFI configuration on the mobile with the IP of mitmproxy and port 8080","title":"Getting started on mitmproxy"},{"location":"tools/getting-started-with-mitmproxy/#development-setup","text":"Install python3 (Windows) Start Windows PowerShell with the \"Run as Administrator\" option. Only members of the Administrators group on the computer can change the execution policy. (Windows) Enable running unsigned scripts by entering: set-executionpolicy remotesigned Install mitmproxy from source (Windows) powershell . \\d ev.ps1 (Others) ./dev.sh The dev script will create a virtualenv environment in a directory called \"venv\" and install all mandatory and optional dependencies into it. The primary mitmproxy components - mitmproxy and pathod - are installed as \"editable\", so any changes to the source in the repository will be reflected live in the virtualenv. The main executables for the project - mitmdump, mitmproxy, mitmweb, pathod, and pathoc - are all created within the virtualenv. After activating the virtualenv, they will be on your $PATH, and you can run them like any other command: (Windows) venv \\S cripts \\a ctivate mitmdump --version (Others) . venv/bin/activate mitmdump --version Running mitmweb mitmweb --set block_global = false Set a lot of parameters if needed mitmweb --set block_global = false --set ignore-hosts = '^(?!example\\.com)(?!mitmproxy\\.org)' --set showhost = true --ssl-insecure The certificate files locate at ~/.mitmproxy/. Apple/Android/Other could use .pem, Windows could use .p12 Set the proxy in WIFI configuration on the mobile with the IP of mitmproxy and port 8080","title":"Development setup"},{"location":"tools/google-search-console/","text":"Search Console tools and reports help you measure your site's Search traffic and performance, fix issues, and make your site shine in Google Search results After you've developed your website and created your domain to host your website, you will look forward to improving your website shine in google search results. Go the Google Search Console to add a property. Input your domain or url prefix to add your property. Click the Continue button in this page. You will see the page to ask you verify domain ownership via DNS record. Please copy the TXT record in the page first. You should go to your domain provider website console like GoDaddy/Route53/etc, then you go to the DNS management page and create the TXT record in your DNS configuration. After you've created the TXT record, you may need to wait for a while to successfully verify your domain. Go to your property after it's successfully verified. After you enter the property, you could see the overview of your website. You could see detailed insight of your website such as different devices data, different pages data and so on. This should be really helpful for your marketing and SEO activities. If your website is online for days, users are potentially able to see your website by searching some keywords in Google. The result ranking strategy depends on Google's crawler. Sometimes you are not happy to let your website being crawled by Google and displayed in the Google Search result, then you could submit a removal request in Google Search Console to forbid being displayed in Google Search results. At the same time, you should add a meta data in your related html files to let Google know about the it.","title":"Manage your website in Google Search Console"},{"location":"tools/hexo-get-started/","text":"Hexo is a fast, simple and powerful blog framework. You write posts in Markdown (or other languages) and Hexo generates static files with a beautiful theme in seconds. Install hexo sudo npm install -g hexo-cli hexo -v Create a project by hexo hexo init ***.github.io cd ***.github.io npm install Add Github Page deploy into the hexo project Add the bellow content in the _config.yml file deploy : type : git repo : https://github.com/***/***.github.io.git branch : master message : #leave this blank Add local assets support in the hexo project Edit the bellow property to true in the _config.yml file post_asset_folder : true Create a folder with the same name of the md file under source/_posts folder, and put images into the folder Insert the bellow image link into the md file ![<image title>](<folder name>/***.png) Run the hexo application hexo serve Create a new page hexo new post \"hello world\" Edit an existing page cd source/_posts # Rename or delete any file or modify the title property in it Generate static files hexo generate Deploy the hexo application to GitHub Page # Remove the .deploy_git folder if needed hexo clean hexo deploy","title":"Hexo get started"},{"location":"tools/hexo-get-started/#install-hexo","text":"sudo npm install -g hexo-cli hexo -v","title":"Install hexo"},{"location":"tools/hexo-get-started/#create-a-project-by-hexo","text":"hexo init ***.github.io cd ***.github.io npm install","title":"Create a project by hexo"},{"location":"tools/hexo-get-started/#add-github-page-deploy-into-the-hexo-project","text":"Add the bellow content in the _config.yml file deploy : type : git repo : https://github.com/***/***.github.io.git branch : master message : #leave this blank","title":"Add Github Page deploy into the hexo project"},{"location":"tools/hexo-get-started/#add-local-assets-support-in-the-hexo-project","text":"Edit the bellow property to true in the _config.yml file post_asset_folder : true Create a folder with the same name of the md file under source/_posts folder, and put images into the folder Insert the bellow image link into the md file ![<image title>](<folder name>/***.png)","title":"Add local assets support in the hexo project"},{"location":"tools/hexo-get-started/#run-the-hexo-application","text":"hexo serve","title":"Run the hexo application"},{"location":"tools/hexo-get-started/#create-a-new-page","text":"hexo new post \"hello world\"","title":"Create a new page"},{"location":"tools/hexo-get-started/#edit-an-existing-page","text":"cd source/_posts # Rename or delete any file or modify the title property in it","title":"Edit an existing page"},{"location":"tools/hexo-get-started/#generate-static-files","text":"hexo generate","title":"Generate static files"},{"location":"tools/hexo-get-started/#deploy-the-hexo-application-to-github-page","text":"# Remove the .deploy_git folder if needed hexo clean hexo deploy","title":"Deploy the hexo application to GitHub Page"},{"location":"tools/setup-cloud9-dev-env/","text":"In the traditional coding era, we always install a lot of IDE softwares such as Intellij Idea/Visual Studio/Atom/etc.. on local machines, and develop on the local IDE software. Even though it's fast, Create environments in AWS Cloud9 Go to AWS Cloud9 and create a new environment. Create a repository or clone existing repositories from GitHub Normally we clone an existing repository from our Github account as bellow. See Cloud9 GitHub Sample for details. #Configure git information git --version git config --global user.name \"Frankie Fan\" git config --global user.email hustakin@gmail.com #Clone your Angular repository from Github git clone https://github.com/<username>/<repos>.git Install Angular Cli and modules npm install -g @angular/cli #Install modules cd <repos> npm install Cache the Github username and password After running this command, the first time you pull or push from the remote repository, you'll get asked about the username and password. Afterwards, for consequent communications with the remote repository you don't have to provide the username and password. The storage file is ~/.git-credentials in plain text. git config --global credential.helper store Coding and push changes to Github git status git add . git commit -m \"<this is a commit>\" git push #Pushing to other branches git branch -r git branch -avv git push -u origin < local branch:remote branch> Enjoy the smart tip for your app(Angular/Java/Dart/etc..) No matter which language you are coding in, the Cloud9 will provide with smart tips support which is great. Run Angular app We could run the bellow script to run the Angular app on port 8080 or add the script into our package.json file and run \"npm run cloud9\" instead. ng serve --host 0 .0.0.0 --port 8080 --disableHostCheck Preview the web page Select \"Preview - Preview Running Application\" menu item to see the web page. Please be noted that AWS Cloud9 only support to preview in https mode, you should copy the address in a local browser tab and replace the https with http to run in http mode. Resize the Amazon EBS volume The Cloud9 environment instances start with 8 GB of space. Should resize the EBS volume size if needed. In the AWS Cloud9 IDE for the environment, create a file with the following contents, and then save the file as resize.sh #!/bin/bash # Specify the desired volume size in GiB as a command-line argument. If not specified, default to 20 GiB. SIZE = ${ 1 :- 20 } # Get the ID of the environment host Amazon EC2 instance. INSTANCEID = $( curl http://169.254.169.254/latest/meta-data/instance-id ) # Get the ID of the Amazon EBS volume associated with the instance. VOLUMEID = $( aws ec2 describe-instances \\ --instance-id $INSTANCEID \\ --query \"Reservations[0].Instances[0].BlockDeviceMappings[0].Ebs.VolumeId\" \\ --output text ) # Resize the EBS volume. aws ec2 modify-volume --volume-id $VOLUMEID --size $SIZE # Wait for the resize to finish. while [ \\ \" $( aws ec2 describe-volumes-modifications \\ --volume-id $VOLUMEID \\ --filters Name = modification-state,Values = \"optimizing\" , \"completed\" \\ --query \"length(VolumesModifications)\" \\ --output text ) \" ! = \"1\" ] ; do sleep 1 done #Check if we're on an NVMe filesystem if [ $( readlink -f /dev/xvda ) = \"/dev/xvda\" ] then # Rewrite the partition table so that the partition takes up all the space that it can. sudo growpart /dev/xvda 1 # Expand the size of the file system. # Check if we are on AL2 STR = $( cat /etc/os-release ) SUB = \"VERSION_ID=\\\"2\\\"\" if [[ \" $STR \" == * \" $SUB \" * ]] then sudo xfs_growfs -d / else sudo resize2fs /dev/xvda1 fi else # Rewrite the partition table so that the partition takes up all the space that it can. sudo growpart /dev/nvme0n1 1 # Expand the size of the file system. # Check if we're on AL2 STR = $( cat /etc/os-release ) SUB = \"VERSION_ID=\\\"2\\\"\" if [[ \" $STR \" == * \" $SUB \" * ]] then sudo xfs_growfs -d / else sudo resize2fs /dev/nvme0n1p1 fi fi Run the following command to resize the volume to 20 GB for example. sh resize.sh 20 Install Maven sudo yum install -y maven mvn --version Install Amplify-cli npm install -g @aws-amplify/cli # Install Amplify libraries for Angular npm install --save aws-amplify @aws-amplify/ui-angular","title":"Setup the development environment on AWS Cloud9 for coding and testing"},{"location":"tools/setup-cloud9-dev-env/#create-environments-in-aws-cloud9","text":"Go to AWS Cloud9 and create a new environment.","title":"Create environments in AWS Cloud9"},{"location":"tools/setup-cloud9-dev-env/#create-a-repository-or-clone-existing-repositories-from-github","text":"Normally we clone an existing repository from our Github account as bellow. See Cloud9 GitHub Sample for details. #Configure git information git --version git config --global user.name \"Frankie Fan\" git config --global user.email hustakin@gmail.com #Clone your Angular repository from Github git clone https://github.com/<username>/<repos>.git","title":"Create a repository or clone existing repositories from GitHub"},{"location":"tools/setup-cloud9-dev-env/#install-angular-cli-and-modules","text":"npm install -g @angular/cli #Install modules cd <repos> npm install","title":"Install Angular Cli and modules"},{"location":"tools/setup-cloud9-dev-env/#cache-the-github-username-and-password","text":"After running this command, the first time you pull or push from the remote repository, you'll get asked about the username and password. Afterwards, for consequent communications with the remote repository you don't have to provide the username and password. The storage file is ~/.git-credentials in plain text. git config --global credential.helper store","title":"Cache the Github username and password"},{"location":"tools/setup-cloud9-dev-env/#coding-and-push-changes-to-github","text":"git status git add . git commit -m \"<this is a commit>\" git push #Pushing to other branches git branch -r git branch -avv git push -u origin < local branch:remote branch>","title":"Coding and push changes to Github"},{"location":"tools/setup-cloud9-dev-env/#enjoy-the-smart-tip-for-your-appangularjavadartetc","text":"No matter which language you are coding in, the Cloud9 will provide with smart tips support which is great.","title":"Enjoy the smart tip for your app(Angular/Java/Dart/etc..)"},{"location":"tools/setup-cloud9-dev-env/#run-angular-app","text":"We could run the bellow script to run the Angular app on port 8080 or add the script into our package.json file and run \"npm run cloud9\" instead. ng serve --host 0 .0.0.0 --port 8080 --disableHostCheck","title":"Run Angular app"},{"location":"tools/setup-cloud9-dev-env/#preview-the-web-page","text":"Select \"Preview - Preview Running Application\" menu item to see the web page. Please be noted that AWS Cloud9 only support to preview in https mode, you should copy the address in a local browser tab and replace the https with http to run in http mode.","title":"Preview the web page"},{"location":"tools/setup-cloud9-dev-env/#resize-the-amazon-ebs-volume","text":"The Cloud9 environment instances start with 8 GB of space. Should resize the EBS volume size if needed. In the AWS Cloud9 IDE for the environment, create a file with the following contents, and then save the file as resize.sh #!/bin/bash # Specify the desired volume size in GiB as a command-line argument. If not specified, default to 20 GiB. SIZE = ${ 1 :- 20 } # Get the ID of the environment host Amazon EC2 instance. INSTANCEID = $( curl http://169.254.169.254/latest/meta-data/instance-id ) # Get the ID of the Amazon EBS volume associated with the instance. VOLUMEID = $( aws ec2 describe-instances \\ --instance-id $INSTANCEID \\ --query \"Reservations[0].Instances[0].BlockDeviceMappings[0].Ebs.VolumeId\" \\ --output text ) # Resize the EBS volume. aws ec2 modify-volume --volume-id $VOLUMEID --size $SIZE # Wait for the resize to finish. while [ \\ \" $( aws ec2 describe-volumes-modifications \\ --volume-id $VOLUMEID \\ --filters Name = modification-state,Values = \"optimizing\" , \"completed\" \\ --query \"length(VolumesModifications)\" \\ --output text ) \" ! = \"1\" ] ; do sleep 1 done #Check if we're on an NVMe filesystem if [ $( readlink -f /dev/xvda ) = \"/dev/xvda\" ] then # Rewrite the partition table so that the partition takes up all the space that it can. sudo growpart /dev/xvda 1 # Expand the size of the file system. # Check if we are on AL2 STR = $( cat /etc/os-release ) SUB = \"VERSION_ID=\\\"2\\\"\" if [[ \" $STR \" == * \" $SUB \" * ]] then sudo xfs_growfs -d / else sudo resize2fs /dev/xvda1 fi else # Rewrite the partition table so that the partition takes up all the space that it can. sudo growpart /dev/nvme0n1 1 # Expand the size of the file system. # Check if we're on AL2 STR = $( cat /etc/os-release ) SUB = \"VERSION_ID=\\\"2\\\"\" if [[ \" $STR \" == * \" $SUB \" * ]] then sudo xfs_growfs -d / else sudo resize2fs /dev/nvme0n1p1 fi fi Run the following command to resize the volume to 20 GB for example. sh resize.sh 20","title":"Resize the Amazon EBS volume"},{"location":"tools/setup-cloud9-dev-env/#install-maven","text":"sudo yum install -y maven mvn --version","title":"Install Maven"},{"location":"tools/setup-cloud9-dev-env/#install-amplify-cli","text":"npm install -g @aws-amplify/cli # Install Amplify libraries for Angular npm install --save aws-amplify @aws-amplify/ui-angular","title":"Install Amplify-cli"}]}